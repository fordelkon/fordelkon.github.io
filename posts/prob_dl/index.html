<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>概率视角中的深度学习 | DL Kong</title><meta name=keywords content="DL,Probability"><meta name=description content="我们可以从概率的角度去探讨深度学习任务，假设我们已有数据集$ \mathcal{D}=\lbrace(\mathbf{x}_{i}, y_{i})\rbrace_{i=1}^{N} $或$ \mathcal{D}=\lbrace\mathbf{x}_{i}\rbrace_{i=1}^{N} $，主要区分于有标签和无标签的情况。那么我们可以将常见深度学习任务中模型要建模的概率进行如下区分

有监督判别：模型根据输入预测真实标签的概率分布$ p_{\boldsymbol{\theta}}(y\mid\mathbf{x}) $
自监督判别：模型根据输入预测伪标签的概率分布$ p_{\boldsymbol{\theta}}(\hat{y}\mid\mathbf{x}) $
有监督生成：模型根据真实标签预测与标签对应的数据集的空间分布$ p_{\boldsymbol{\theta}}(\mathbf{x}\mid y) $
无监督生成：模型预测数据集的空间分布$ p_{\boldsymbol{\theta}}(\mathbf{x}) $
其中$ \mathbf{x} $和$ y $分别表示输入和标签的随机张量，$ \boldsymbol{\theta} $表示模型中可学习的参数。从概率角度探讨深度学习任务之前，我们应当明确如下假设：输入到模型的数据满足独立同分布(independent and identically distributed)。


  

不同深度学习任务所学习的概率分布总结"><meta name=author content="DL Kong"><link rel=canonical href=https://fordelkon.github.io/posts/prob_dl/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.c7a0847263ef81d155d535eb3508757a49b1a3680807f60ed1f64e9d4a686070.css integrity="sha256-x6CEcmPvgdFV1TXrNQh1ekmxo2gIB/YO0fZOnUpoYHA=" rel="preload stylesheet" as=style><link rel=icon href=https://fordelkon.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://fordelkon.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://fordelkon.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://fordelkon.github.io/apple-touch-icon.png><link rel=mask-icon href=https://fordelkon.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://fordelkon.github.io/posts/prob_dl/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><style>@media screen and (min-width:769px){.post-content input[type=checkbox]:checked~label>img{transform:scale(1.6);cursor:zoom-out;position:relative;z-index:999}.post-content img.zoomCheck{transition:transform .15s ease;z-index:999;cursor:zoom-in}}</style><link rel=stylesheet href=/css/extended/xcode.css media="(prefers-color-scheme: light)"><link rel=stylesheet href=/css/extended/monokai.css media="(prefers-color-scheme: dark)"><script async src="https://www.googletagmanager.com/gtag/js?id=G-Q603T56FWT"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-Q603T56FWT")}</script><meta property="og:url" content="https://fordelkon.github.io/posts/prob_dl/"><meta property="og:site_name" content="DL Kong"><meta property="og:title" content="概率视角中的深度学习"><meta property="og:description" content="我们可以从概率的角度去探讨深度学习任务，假设我们已有数据集$ \mathcal{D}=\lbrace(\mathbf{x}_{i}, y_{i})\rbrace_{i=1}^{N} $或$ \mathcal{D}=\lbrace\mathbf{x}_{i}\rbrace_{i=1}^{N} $，主要区分于有标签和无标签的情况。那么我们可以将常见深度学习任务中模型要建模的概率进行如下区分
有监督判别：模型根据输入预测真实标签的概率分布$ p_{\boldsymbol{\theta}}(y\mid\mathbf{x}) $ 自监督判别：模型根据输入预测伪标签的概率分布$ p_{\boldsymbol{\theta}}(\hat{y}\mid\mathbf{x}) $ 有监督生成：模型根据真实标签预测与标签对应的数据集的空间分布$ p_{\boldsymbol{\theta}}(\mathbf{x}\mid y) $ 无监督生成：模型预测数据集的空间分布$ p_{\boldsymbol{\theta}}(\mathbf{x}) $ 其中$ \mathbf{x} $和$ y $分别表示输入和标签的随机张量，$ \boldsymbol{\theta} $表示模型中可学习的参数。从概率角度探讨深度学习任务之前，我们应当明确如下假设：输入到模型的数据满足独立同分布(independent and identically distributed)。 不同深度学习任务所学习的概率分布总结"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-23T10:36:33+09:00"><meta property="article:modified_time" content="2025-08-23T10:36:33+09:00"><meta property="article:tag" content="DL"><meta property="article:tag" content="Probability"><meta property="og:image" content="https://fordelkon.github.io/img/prob_dl_summary.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://fordelkon.github.io/img/prob_dl_summary.png"><meta name=twitter:title content="概率视角中的深度学习"><meta name=twitter:description content="我们可以从概率的角度去探讨深度学习任务，假设我们已有数据集$ \mathcal{D}=\lbrace(\mathbf{x}_{i}, y_{i})\rbrace_{i=1}^{N} $或$ \mathcal{D}=\lbrace\mathbf{x}_{i}\rbrace_{i=1}^{N} $，主要区分于有标签和无标签的情况。那么我们可以将常见深度学习任务中模型要建模的概率进行如下区分

有监督判别：模型根据输入预测真实标签的概率分布$ p_{\boldsymbol{\theta}}(y\mid\mathbf{x}) $
自监督判别：模型根据输入预测伪标签的概率分布$ p_{\boldsymbol{\theta}}(\hat{y}\mid\mathbf{x}) $
有监督生成：模型根据真实标签预测与标签对应的数据集的空间分布$ p_{\boldsymbol{\theta}}(\mathbf{x}\mid y) $
无监督生成：模型预测数据集的空间分布$ p_{\boldsymbol{\theta}}(\mathbf{x}) $
其中$ \mathbf{x} $和$ y $分别表示输入和标签的随机张量，$ \boldsymbol{\theta} $表示模型中可学习的参数。从概率角度探讨深度学习任务之前，我们应当明确如下假设：输入到模型的数据满足独立同分布(independent and identically distributed)。


  

不同深度学习任务所学习的概率分布总结"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://fordelkon.github.io/posts/"},{"@type":"ListItem","position":2,"name":"概率视角中的深度学习","item":"https://fordelkon.github.io/posts/prob_dl/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"概率视角中的深度学习","name":"概率视角中的深度学习","description":"我们可以从概率的角度去探讨深度学习任务，假设我们已有数据集$ \\mathcal{D}=\\lbrace(\\mathbf{x}_{i}, y_{i})\\rbrace_{i=1}^{N} $或$ \\mathcal{D}=\\lbrace\\mathbf{x}_{i}\\rbrace_{i=1}^{N} $，主要区分于有标签和无标签的情况。那么我们可以将常见深度学习任务中模型要建模的概率进行如下区分\n有监督判别：模型根据输入预测真实标签的概率分布$ p_{\\boldsymbol{\\theta}}(y\\mid\\mathbf{x}) $ 自监督判别：模型根据输入预测伪标签的概率分布$ p_{\\boldsymbol{\\theta}}(\\hat{y}\\mid\\mathbf{x}) $ 有监督生成：模型根据真实标签预测与标签对应的数据集的空间分布$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid y) $ 无监督生成：模型预测数据集的空间分布$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}) $ 其中$ \\mathbf{x} $和$ y $分别表示输入和标签的随机张量，$ \\boldsymbol{\\theta} $表示模型中可学习的参数。从概率角度探讨深度学习任务之前，我们应当明确如下假设：输入到模型的数据满足独立同分布(independent and identically distributed)。 不同深度学习任务所学习的概率分布总结","keywords":["DL","Probability"],"articleBody":"我们可以从概率的角度去探讨深度学习任务，假设我们已有数据集$ \\mathcal{D}=\\lbrace(\\mathbf{x}_{i}, y_{i})\\rbrace_{i=1}^{N} $或$ \\mathcal{D}=\\lbrace\\mathbf{x}_{i}\\rbrace_{i=1}^{N} $，主要区分于有标签和无标签的情况。那么我们可以将常见深度学习任务中模型要建模的概率进行如下区分\n有监督判别：模型根据输入预测真实标签的概率分布$ p_{\\boldsymbol{\\theta}}(y\\mid\\mathbf{x}) $ 自监督判别：模型根据输入预测伪标签的概率分布$ p_{\\boldsymbol{\\theta}}(\\hat{y}\\mid\\mathbf{x}) $ 有监督生成：模型根据真实标签预测与标签对应的数据集的空间分布$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid y) $ 无监督生成：模型预测数据集的空间分布$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}) $ 其中$ \\mathbf{x} $和$ y $分别表示输入和标签的随机张量，$ \\boldsymbol{\\theta} $表示模型中可学习的参数。从概率角度探讨深度学习任务之前，我们应当明确如下假设：输入到模型的数据满足独立同分布(independent and identically distributed)。 不同深度学习任务所学习的概率分布总结 有监督判别 已有数据集$ \\mathcal{D}=\\lbrace(\\mathbf{x}_{i}, y_{i})\\rbrace_{i=1}^{N} $，我们应该使得数据集$ \\mathcal{D} $被观测到的概率尽可能大，也就是说给定输入$ \\mathbf{x}_{i} $，经过模型$ f(\\mathbf{x}, \\boldsymbol{\\theta}) $处理之后得到潜在空间$ \\mathbf{z}_{i} $或$ z_{i} $，其中$ \\mathbf{z}_{i}=f(\\mathbf{x}_{i}, \\boldsymbol{\\theta})\\in \\mathbb{R}^{K} $，在这个潜在空间中我们有最大的把握预测出$ y_{i} $。上述描述用数学形式表达如下：\n$$ \\begin{align} \\boldsymbol{\\theta}_{ML} \u0026= \\arg\\max_{\\boldsymbol{\\theta}} p_{\\boldsymbol{\\theta}}(\\mathcal{D}) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}} p_{\\boldsymbol{\\theta}}(y_{1}, y_{2}, \\dots, y_{N}\\mid\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\dots, \\mathbf{x}_{N}) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}} \\prod_{i=1}^{N} p_{\\boldsymbol{\\theta}}(y_{i}\\mid\\mathbf{x}_{i})\\quad (i.i.d.) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}} \\prod_{i=1}^{N}p(y_{i}\\mid\\mathbf{z}_{i}) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}}\\sum_{i=1}^{N}\\log p(y_{i}\\mid\\mathbf{z}_{i}) \\\\ \u0026= \\arg\\min_{\\boldsymbol{\\theta}}-\\sum_{i=1}^{N}\\log p(y_{i}\\mid\\mathbf{z}_{i}) \\end{align} $$ 常使用的$ y $分布有$ y\\sim \\mathcal{N}(z, \\sigma^2) $（回归问题），$ y\\sim \\mathrm{Bernoulli}(\\mathrm{sigmoid}(z)) $（二分类问题，使用$ \\mathrm{sigmoid} $函数使得最终的输出区间为$ [0, 1] $），$ p(y\\mid\\mathbf{z})=\\mathrm{softmax}_{y}(\\mathbf{z})=\\frac{\\exp[z_{y}]}{\\sum_{y'=1}^{K}\\exp[z_{y'}]} $（多分类问题，$ y\\in\\lbrace 1, 2, \\dots, K\\rbrace $，$ \\mathbf{z}=[z_{1}, z_{2}, \\dots, z_{K}] $）。更多相关的概率分布可以参见常用概率分布。\n无监督生成 已有数据集$ \\mathcal{D}=\\lbrace{\\mathbf{x}_{i}}\\rbrace_{i=1}^{N} $，无监督生成的任务就是使用模型学习出数据集的空间分布$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}) $。\n$ \\mathrm{GAN(Generative\\:Adversarial\\:Networks)} $ $ \\mathrm{GAN} $的思路是训练出一个生成器$ \\hat{\\mathbf{x}} = f_{g}(\\mathbf{v}, \\boldsymbol{\\theta}^{g}):\\mathcal{V}\\to \\mathcal{X} $将潜在空间$ \\mathcal{V} $很好地映射到样本空间$ \\mathcal{X} $。要训练出这样的生成器，$ \\mathrm{GAN} $额外训练了一个判别器$ z = f_{d}(\\mathbf{x}, \\boldsymbol{\\theta}^{d}):\\mathcal{X}\\to \\mathbb{R} $对生成的图像和真实的图像进行区分。对于生成器输入是潜在空间$ \\mathcal{V} $的采样，而对于判别器，我们就拥有数据集$ \\mathcal{D}_{union} = \\lbrace\\mathbf{x}_{i}, 1\\rbrace_{i=1}^N\\cup{\\lbrace\\hat{\\mathbf{x}}_{i}, 0\\rbrace}_{i=1}^{M} = \\lbrace\\tilde{\\mathbf{x}}_{i}, y_{i}\\rbrace_{i=1}^{N+M} $。在训练的过程中，针对生成器，我们要使其生成的图像更加真实（使得判别器判定高概率为真），针对判别器，我们要使判别器能够很好的区分生成器生成的伪造图像和真实图像。上面说法的数学形式如下\n对于生成器：\n$$ \\begin{align} \\boldsymbol{\\theta}_{ML}^{g} \u0026= \\arg\\max_{\\boldsymbol{\\theta}^g} p(y=1\\mid \\hat{z}) \\\\ \u0026= \\arg\\min_{\\boldsymbol{\\theta}^g}\\log p(y=0\\mid \\hat{z})\\quad(\\hat{z} = f_{d}(\\hat{\\mathbf{x}}, \\boldsymbol{\\theta}^d)) \\end{align} $$ 对于判别器\n$$ \\begin{align} \\boldsymbol{\\theta}_{ML}^{d} \u0026= \\arg\\max_{\\boldsymbol{\\theta}^d} p(y\\mid \\tilde{z}) \\\\ \u0026= \\arg\\min_{\\boldsymbol{\\theta}^d}-\\log p(y\\mid \\tilde{z})\\quad(\\tilde{z} = f_{d}(\\tilde{\\mathbf{x}}, \\boldsymbol{\\theta}^d))) \\end{align} $$ $ \\mathrm{VAE(Varitional\\:AutoEncoders)} $ $ \\mathrm{VAE} $的思路是也是训练一个解码器$ \\hat{\\mathbf{x}} = f_{d}(\\mathbf{v}, \\boldsymbol{\\theta}^{d}): \\mathcal{V}\\to \\mathcal{X} $将潜在空间$ \\mathcal{V} $中很好映射到样本空间$ \\mathcal{X} $。但是$ \\mathrm{VAE} $是通过最大化建模得到的$ p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}) $来实现训练该解码器的。表示成数学形式如下：\n$$ \\begin{align} \\boldsymbol{\\theta}_{ML}^d \u0026= \\arg\\max_{\\boldsymbol{\\theta}^d} p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}^d} \\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}, \\mathbf{v})d\\mathbf{v} \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}^d} \\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid \\mathbf{v})p(\\mathbf{v})d\\mathbf{v} \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}^d} \\log\\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid \\mathbf{v})p(\\mathbf{v})d\\mathbf{v}\\quad \\bigotimes \\quad ( not \\: intractable) \\end{align} $$ 由上式可知，直接求解$ \\boldsymbol{\\theta}^d $使得$ \\log\\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid \\mathbf{v})p(\\mathbf{v})d\\mathbf{v} $最大化往往不可能，我们应该找到$ \\log\\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid \\mathbf{v})p(\\mathbf{v})d\\mathbf{v} $的一个便于求解$ \\boldsymbol{\\theta}^d $的下界$ \\mathrm{ELBO}(\\boldsymbol{\\theta}^d)\\mathrm{\\:Evidence \\:Lower\\:BOund} $，使得更新$ \\boldsymbol{\\theta}^d $让下界$ \\mathrm{ELBO}(\\boldsymbol{\\theta}^d) $变大的同时，能够间接地使得$ \\log\\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid \\mathbf{v})p(\\mathbf{v})d\\mathbf{v} $增大。\n$$ \\begin{align} \\log p_{\\boldsymbol{\\theta}^d}(\\mathbf{x})\u0026=\\log\\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}, \\mathbf{v})d\\mathbf{v} \\\\ \u0026= \\log \\int q(\\mathbf{v})\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}, \\mathbf{v})}{q(\\mathbf{v})}d\\mathbf{v} \\\\ \u0026\\geq \\int q(\\mathbf{v})\\log\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}, \\mathbf{v})}{q(\\mathbf{v})}d\\mathbf{v} \\quad (\\mathrm{Jensen's\\:inequality}) \\end{align} $$ 因此，我们可以取下界为\n$$ \\mathrm{ELBO}(\\boldsymbol{\\theta}^d) = \\int q(\\mathbf{v})\\log\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}, \\mathbf{v})}{q(\\mathbf{v})}d\\mathbf{v} $$ 实际操作中$ \\mathbf{v} $的概率分布$ q(\\mathbf{v}) $通常也是由编码器模型生成，也就是说下界$ \\mathrm{ELBO}(\\boldsymbol{\\theta}^d) $更为规范的写法为$ \\mathrm{ELBO}(\\boldsymbol{\\theta}^e, \\boldsymbol{\\theta}^d) $\n$$ \\begin{align} \\mathrm{ELBO}(\\boldsymbol{\\theta}^e, \\boldsymbol{\\theta}^d) \u0026= \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}, \\mathbf{v})}{q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})}d\\mathbf{v} \\\\ \u0026= \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{v}\\mid\\mathbf{x})p_{\\boldsymbol{\\theta}^d}(\\mathbf{x})}{q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})}d\\mathbf{v} \\\\ \u0026= \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log p_{\\boldsymbol{\\theta}^d}(\\mathbf{x})d\\mathbf{v} + \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{v}\\mid\\mathbf{x})}{q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})}d\\mathbf{v} \\quad (one\\:perspective) \\\\ \u0026= \\log p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}) - \\mathrm{D}_{\\mathrm{KL}}\\Big[q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})||p_{\\boldsymbol{\\theta}^d}(\\mathbf{v}\\mid\\mathbf{x})\\Big] \\\\ \\\\ \u0026= \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid\\mathbf{v})p(\\mathbf{v})}{q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})}d\\mathbf{v} \\\\ \u0026= \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid\\mathbf{v})d\\mathbf{v} + \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log\\frac{p(\\mathbf{v})}{q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})}d\\mathbf{v}\\quad (another\\:perspective) \\\\ \u0026= \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid\\mathbf{v})d\\mathbf{v} - \\mathrm{D}_{\\mathrm{KL}}\\Big[q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})||p(\\mathbf{v})\\Big] \\\\ \u0026\\approx \\log p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid\\mathbf{v}^*) - \\mathrm{D}_{\\mathrm{KL}}\\Big[q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})||p(\\mathbf{v})\\Big] \\quad (Monte\\:Carlo\\:estimate) \\end{align} $$ 上述公式中$ q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\approx q_{\\boldsymbol{\\theta}^e}(\\mathbf{v}\\mid \\mathbf{x})=\\mathcal{N}(\\mathbf{v}\\mid f_{e}^{\\boldsymbol{\\mu}}(\\mathbf{x}, \\boldsymbol{\\theta}^e), f_{e}^{\\boldsymbol{\\Sigma}}(\\mathbf{x}, \\boldsymbol{\\theta}^e)) $，$ p(\\mathbf{v})=\\mathcal{N}(\\mathbf{v}|0, 1) $，$ \\mathbf{v}^* $也是从分布中$ q_{\\boldsymbol{\\theta}^e}(\\mathbf{v}\\mid \\mathbf{x}) $抽样得到。之后我们就可以通过最大化$ \\mathrm{ELBO}(\\boldsymbol{\\theta}^e, \\boldsymbol{\\theta}^d) $来进行优化模型从而对$ p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}) $进行建模。\n$ \\mathrm{Diffusion\\:Models} $ $ \\mathrm{Diffusion\\:Models} $的目标也是训练出一个解码器$ \\hat{\\mathbf{x}} = f_{d}(\\mathbf{v}, \\boldsymbol{\\theta}): \\mathcal{V}\\to \\mathcal{X} $将潜在空间$ \\mathcal{V} $中很好映射到样本空间$ \\mathcal{X} $。和$ \\mathrm{VAE} $一样，$ \\mathrm{Diffusion\\:Models} $的目标也是最大化$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}) $来实现训练该解码器的，但是$ \\mathrm{Diffusion\\:Models} $的潜在变量$ \\mathbf{v} $通常是通过原始输入$ \\mathbf{x} $逐渐加噪得到的，而解码器学习从潜在变量$ \\mathbf{v} $一步步生成逼真的样本。这一过程的形式化表示如下所示，为了方便推导公式简化，令$ \\mathbf{v} = \\mathbf{z}_{T} $\n$$ \\mathrm{forward\\:process}: \\mathbf{x}\\to \\mathbf{z}_{1}\\to \\mathbf{z}_{2}\\to\\dots\\to \\mathbf{z}_{T-1}\\to\\mathbf{z}_{T}\\quad(\\mathbf{v}) $$ $$ \\mathrm{reverse\\:process}: (\\mathbf{v})\\quad\\mathbf{z}_{T}\\to \\mathbf{z}_{T-1}\\to \\mathbf{z}_{T-2}\\to\\dots\\to \\mathbf{z}_{1}\\to\\mathbf{x} $$ 根据上述框架，我们可以对$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}) $最大化求解$ \\boldsymbol{\\theta} $\n$$ \\begin{align} \\boldsymbol{\\theta}_{ML} \u0026= \\arg\\max_{\\boldsymbol{\\theta}}p_{\\boldsymbol{\\theta}}(\\mathbf{x}) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}}\\int p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})d\\mathbf{z}_{1\\dots T} \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}}\\log \\int p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})d\\mathbf{z}_{1\\dots T} \\quad \\bigotimes \\quad ( not \\: intractable) \\end{align} $$ 和$ \\mathrm{VAE} $一样，我们寻找$ \\log \\int p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1}, \\mathbf{z}_{2}, \\dots, \\mathbf{z}_{T-1}, \\mathbf{v})d\\mathbf{z}_{1}d\\mathbf{z}_{2}\\dots d\\mathbf{z}_{T-1}d\\mathbf{v} $的一个便于优化的下界$ \\mathrm{ELBO}(\\boldsymbol{\\theta})\\mathrm{\\:Evidence \\:Lower\\:BOund} $来对$ \\boldsymbol{\\theta} $进行优化求解\n$$ \\begin{align} \\log p_{\\boldsymbol{\\theta}}(\\mathbf{x}) \u0026= \\log \\int p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})d\\mathbf{z}_{1\\dots T}\\\\ \u0026= \\log\\left[ \\int q(\\mathbf{z}_{1\\dots T}\\mid \\mathbf{x}) \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})}{q(\\mathbf{z}_{1\\dots T}\\mid \\mathbf{x})}d\\mathbf{z}_{1\\dots T}\\right] \\\\ \u0026\\geq \\int q(\\mathbf{z}_{1\\dots T}\\mid \\mathbf{x}) \\log \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})}{q(\\mathbf{z}_{1\\dots T} \\mid \\mathbf{x})}d\\mathbf{z}_{1\\dots T} \\quad (\\mathrm{Jensen's\\:inequality}) \\end{align} $$ 也就是说我们可以取证据下界\n$$ \\mathrm{ELBO}(\\boldsymbol{\\theta}) = \\int q(\\mathbf{z}_{1\\dots T}\\mid \\mathbf{x}) \\log \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})}{q(\\mathbf{z}_{1\\dots T} \\mid \\mathbf{x})}d\\mathbf{z}_{1\\dots T} $$ 在$ \\mathrm{VAE} $中，编码器通过参数来学习给定输入下潜在变量的后验概率分布$ q_{\\boldsymbol{\\theta}^e}(\\mathbf{v}\\mid \\mathbf{x}) $，但是在$ \\mathrm{Diffusion\\:Models} $中的编码器是没有参数的，因此解码器的参数在更新时应当考虑使得无参数编码器尽可能近似后验概率分布$ p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{1}, \\mathbf{z}_{2}, \\dots, \\mathbf{z}_{T-1}, \\mathbf{v}\\mid \\mathbf{x}) $。\n下面对$ \\mathrm{ELBO}(\\boldsymbol{\\theta}) $中的$ \\log $项进行进一步的分析简化，\n$$ \\begin{align} \\log \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})}{q(\\mathbf{z}_{1\\dots T} \\mid \\mathbf{x})} \u0026= \\log\\left[ \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})\\prod_{t=2}^Tp_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})\\cdot p(\\mathbf{z}_{T})}{q(\\mathbf{z}_{1}\\mid\\mathbf{x})\\prod_{t=2}^Tq(\\mathbf{z}_{t}\\mid \\mathbf{z}_{t-1})} \\right]\\\\ \u0026= \\log\\left[ \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})}{q(\\mathbf{z}_{1}\\mid \\mathbf{x})} \\right] + \\log\\left[ \\frac{\\prod_{t=2}^Tp_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})}{\\prod_{t=2}^Tq(\\mathbf{z}_{t}\\mid \\mathbf{z}_{t-1})} \\right] + \\log[p(\\mathbf{z}_{T})] \\\\ \u0026= \\log\\left[ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})\\right] + \\log\\left[ \\frac{\\prod_{t=2}^Tp_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})}{\\prod_{t=2}^Tq(\\mathbf{z}_{t - 1}\\mid \\mathbf{z}_{t}, \\mathbf{x})} \\right] + \\log\\left[ \\frac{p(\\mathbf{z}_{T})}{q(\\mathbf{z}_{T}\\mid \\mathbf{x})} \\right]\\quad (Bayes'\\:rule) \\\\ \u0026\\approx \\log\\left[ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})\\right] + \\sum_{t=2}^{T}\\log\\left[ \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})}{q(\\mathbf{z}_{t - 1}\\mid \\mathbf{z}_{t}, \\mathbf{x})} \\right] \\end{align} $$ 所以$ \\mathrm{ELBO}(\\boldsymbol{\\theta}) $可以转变为\n$$ \\begin{align} \\mathrm{ELBO}(\\boldsymbol{\\theta}) \u0026= \\int q(\\mathbf{z}_{1\\dots T}\\mid \\mathbf{x}) \\log \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})}{q(\\mathbf{z}_{1\\dots T} \\mid \\mathbf{x})}d\\mathbf{z}_{1\\dots T} \\\\ \u0026\\approx \\int q(\\mathbf{z}_{1\\dots T}\\mid \\mathbf{x})\\left(\\log\\left[ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})\\right] + \\sum_{t=2}^{T}\\log\\left[ \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})}{q(\\mathbf{z}_{t - 1}\\mid \\mathbf{z}_{t}, \\mathbf{x})} \\right]\\right)d\\mathbf{z}_{1\\dots T} \\\\ \u0026= \\int q(\\mathbf{z}_{1}\\mid \\mathbf{x})\\log\\left[ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})\\right]d\\mathbf{z}_{1} + \\sum_{t=2}^{T}\\int q(\\mathbf{z}_{t-1}, \\mathbf{z}_{t}\\mid \\mathbf{x})\\log\\left[ \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})}{q(\\mathbf{z}_{t - 1}\\mid \\mathbf{z}_{t}, \\mathbf{x})} \\right]d\\mathbf{z}_{t-1}d\\mathbf{z}_{t} \\\\ \u0026= \\int q(\\mathbf{z}_{1}\\mid \\mathbf{x})\\log\\left[ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})\\right]d\\mathbf{z}_{1} + \\sum_{t=2}^{T}\\int q(\\mathbf{z}_{t}\\mid\\mathbf{x})q(\\mathbf{z}_{t-1}\\mid \\mathbf{z}_{t}, \\mathbf{x})\\log\\left[ \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})}{q(\\mathbf{z}_{t - 1}\\mid \\mathbf{z}_{t}, \\mathbf{x})} \\right]d\\mathbf{z}_{t-1}d\\mathbf{z}_{t} \\quad (Bayes'\\:rule) \\\\ \u0026= \\int \\textcolor{blue}{q(\\mathbf{z}_{1}\\mid \\mathbf{x})}\\log\\left[ \\textcolor{green}{p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})}\\right]d\\mathbf{z}_{1} - \\sum_{t=2}^{T}\\int \\textcolor{red}{q(\\mathbf{z}_{t}\\mid\\mathbf{x})}\\mathrm{D}_{\\mathrm{KL}}(\\textcolor{purple}{q(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t}, \\mathbf{x})}||\\textcolor{pink}{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})})d\\mathbf{z}_{t} \\end{align} $$ 上述$ \\mathrm{ELBO}(\\boldsymbol{\\theta}) $的所有标明颜色的概率分布都可以通过正态分布建模出来\n$$ \\textcolor{green}{p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})} = \\mathcal{N}\\left(\\mathbf{x}\\mid f_{d}(\\mathbf{z}_{1}, \\boldsymbol{\\theta}), \\sigma_{1}^2\\mathbf{I}\\right) $$ $$ \\textcolor{pink}{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})} = \\mathcal{N}\\left(\\mathbf{z}_{t-1}\\mid f_{d}(\\mathbf{z}_{t}, \\boldsymbol{\\theta}), \\sigma_{t}^2\\mathbf{I}\\right) $$ 前向过程($ \\mathrm{Forward\\:Process} $) $$ \\mathbf{z}_{1} = \\sqrt{ 1-\\beta_{1} }\\mathbf{x} + \\sqrt{ \\beta_{1} }\\boldsymbol{\\epsilon}_{1} $$ $$ \\mathbf{z}_{t} = \\sqrt{ 1-\\beta_{t} }\\mathbf{z}_{t-1} + \\sqrt{ \\beta_{t} }\\boldsymbol{\\epsilon}_{t}\\quad\\quad \\forall t\\in 2, \\dots, T $$ 其中$ \\boldsymbol{\\epsilon}_{t} $是从标准正态分布中抽取的噪声($ \\boldsymbol{\\epsilon}_{t}\\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}) $)，前向过程的第一项衰减了数据以及至今添加的任何噪声，第二项增加了更多的噪声。超参数$ \\beta_{t} $则决定了噪声的混合速度。方程形式转化成概率形式如下\n$$ \\textcolor{blue}{q(\\mathbf{z}_{1}\\mid\\mathbf{x})} = \\mathcal{N}(\\mathbf{z}_{1}|\\sqrt{ 1-\\beta_{1} }\\mathbf{x}, \\beta_{1}\\mathbf{I}) $$ $$ q(\\mathbf{z}_{t}\\mid\\mathbf{z}_{t-1}) = \\mathcal{N}(\\mathbf{z}_{t}|\\sqrt{ 1 - \\beta_{t} }\\mathbf{z}_{t-1}, \\beta_{t}\\mathbf{I}) $$ 上述过程形成了一个$ Markov $链，当$ T $足够大时，$ q(\\mathbf{z}_{T}|\\mathbf{x})=q(\\mathbf{z}_{T}) $就会成为标准正态分布。已知以上概率分布我们可以很方便地推导出$ \\textcolor{purple}{q(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t}, \\mathbf{x})} $\n$$ \\textcolor{purple}{q(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t}, \\mathbf{x})} = \\mathcal{N}\\left( \\mathbf{z}_{t-1}\\mid \\frac{1-\\alpha_{t-1}}{1-\\alpha_{t}}\\sqrt{ 1-\\beta_{t} }\\mathbf{z}_{t} + \\frac{\\sqrt{ \\alpha_{t-1} }\\beta_{t}}{1 - \\alpha_{t}}\\mathbf{x}, \\frac{\\beta_{t}(1 - \\alpha_{t-1})}{1 - \\alpha_{t}}\\mathbf{I} \\right) $$ 其中$ \\alpha_{t} = \\prod_{s=1}^{t}1 - \\beta_{s} $。\n扩散损失 原始扩散损失 经过正态分布建模后，原始扩散损失为\n$$ \\begin{align} -\\mathrm{ELBO}(\\boldsymbol{\\theta}) \u0026= \\sum_{n=1}^N\\Big( -\\log[\\mathcal{N}(\\mathbf{x}_{n}\\mid f_{d}(\\mathbf{z}_{n1}, \\boldsymbol{\\theta}), \\sigma_{1}^2\\mathbf{I})] \\\\ \u0026\\quad\\quad+ \\frac{1}{2\\sigma^2}\\sum_{t=2}^T\\Big\\lvert\\Big\\lvert \\frac{1 - \\alpha_{t-1}}{1 - \\alpha_{t}}\\sqrt{ 1 - \\beta_{t} } \\mathbf{z}_{nt} + \\frac{\\sqrt{ \\alpha_{t - 1} }\\beta_{t}}{1 - \\alpha_{t}}\\mathbf{x}_{n} - f_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta})\\Big\\rvert\\Big\\rvert^2 \\Big) \\end{align} $$ 重参数化扩散损失 由前向过程我们可以推导得到\n$$ \\mathbf{z}_{t} = \\sqrt{ \\alpha_{t} }\\cdot \\mathbf{x} + \\sqrt{ 1 - \\alpha_{t} }\\boldsymbol{\\epsilon} $$ $$ \\mathbf{x} = \\frac{1}{\\sqrt{ \\alpha_{t} }}\\cdot \\mathbf{z}_{t} - \\frac{\\sqrt{ 1 - \\alpha_{t} }}{\\sqrt{ \\alpha_{t} }}\\cdot\\boldsymbol{\\epsilon} $$ 将原始扩散损失中的$ \\mathbf{x} $替换成$ \\mathbf{z}_{t} $\n$$ \\begin{align} -\\mathrm{ELBO}(\\boldsymbol{\\theta}) \u0026= \\sum_{n=1}^N\\Big( -\\log[\\mathcal{N}(\\mathbf{x}_{n}\\mid f_{d}(\\mathbf{z}_{n1}, \\boldsymbol{\\theta}), \\sigma_{1}^2\\mathbf{I})] \\\\ \u0026\\quad\\quad+ \\sum_{t=2}^T\\frac{1}{2\\sigma_{t}^2}\\Big\\lvert \\Big\\lvert \\frac{1}{\\sqrt{ 1 - \\beta_{t} }} \\mathbf{z}_{nt} - \\frac{\\beta_{t}}{\\sqrt{ 1-\\alpha_{t} }\\sqrt{ 1-\\beta_{t} }}\\boldsymbol{\\epsilon}_{nt} - f_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta})\\Big\\rvert\\Big\\rvert^2 \\Big) \\\\ \u0026= \\sum_{n=1}^N \\Big(\\frac{1}{2\\sigma_{1}^2}\\Big\\lvert \\Big\\lvert \\mathbf{x}_{n} - f_{d}(\\mathbf{z}_{n1}, \\boldsymbol{\\theta})\\Big\\rvert\\Big\\rvert^2 + \\sum_{t=2}^T\\frac{\\beta_{t}^2}{(1 - \\alpha_{t})(1 - \\beta_{t})2\\sigma_{t}^2}\\Big\\lvert \\Big\\lvert g_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta}) - \\boldsymbol{\\epsilon}_{nt}\\Big\\rvert\\Big\\rvert^2 + C_{n}\\Big)\\quad(Reparameterization\\:of\\:network) \\\\ \\\\ \u0026= \\sum_{n=1}^N\\sum_{t=1}^T\\frac{\\beta_{t}^2}{(1 - \\alpha_{t})(1 - \\beta_{t})2\\sigma_{t}^2}\\Big\\lvert \\Big\\lvert g_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta}) - \\boldsymbol{\\epsilon}_{nt}\\Big\\rvert\\Big\\rvert^2 + C_{n} \\end{align} $$ 其中网络重参数化使用如下公式$ f_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta}) = \\frac{1}{\\sqrt{ 1 - \\beta_{t} }} \\mathbf{z}_{nt} - \\frac{\\beta_{t}}{\\sqrt{ 1-\\alpha_{t} }\\sqrt{ 1-\\beta_{t} }}g_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta}) $。有了上面的简约形式我们可以进一步对损失进行简化\n$$ \\begin{align} \\mathcal{L}(\\boldsymbol{\\theta}) \u0026= \\sum_{n=1}^N\\sum_{t=1}^T\\Big\\lvert \\Big\\lvert g_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta}) - \\boldsymbol{\\epsilon}_{nt}\\Big\\rvert\\Big\\rvert^2 \\\\ \u0026= \\sum_{n=1}^N\\sum_{t=1}^T\\Big\\lvert \\Big\\lvert g_{d}(\\sqrt{ \\alpha_{t} }\\mathbf{x}_{n} + \\sqrt{ 1-\\alpha_{t} }\\boldsymbol{\\epsilon}_{nt}, \\boldsymbol{\\theta}) - \\boldsymbol{\\epsilon}_{nt}\\Big\\rvert\\Big\\rvert^2 \\end{align} $$ 反向过程($ \\mathrm{Reverse\\:(Sampling)\\: Process} $) 由式子$ \\textcolor{pink}{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})} = \\mathcal{N}\\left(\\mathbf{z}_{t-1}\\mid f_{d}(\\mathbf{z}_{t}, \\boldsymbol{\\theta}), \\sigma_{t}^2\\mathbf{I}\\right) $可以将概率形式转化成如下方程形式\n$$ \\begin{align} \\mathbf{z}_{t-1} \u0026= f_{d}(\\mathbf{z}_{t}, \\boldsymbol{\\theta}) + \\sigma_{t}\\boldsymbol{\\epsilon}_{t} \\\\ \u0026= \\frac{1}{\\sqrt{ 1 - \\beta_{t} }} \\mathbf{z}_{t} - \\frac{\\beta_{t}}{\\sqrt{ 1-\\alpha_{t} }\\sqrt{ 1-\\beta_{t} }}g_{d}(\\mathbf{z}_{t}, \\boldsymbol{\\theta}) + \\sigma_{t}\\boldsymbol{\\epsilon}_{t} \\\\ \\end{align} $$ 再由式子$ \\textcolor{purple}{q(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t}, \\mathbf{x})} = \\mathcal{N}\\left( \\mathbf{z}_{t-1}\\mid \\frac{1-\\alpha_{t-1}}{1-\\alpha_{t}}\\sqrt{ 1-\\beta_{t} }\\mathbf{z}_{t} + \\frac{\\sqrt{ \\alpha_{t-1} }\\beta_{t}}{1 - \\alpha_{t}}\\mathbf{x}, \\frac{\\beta_{t}(1 - \\alpha_{t-1})}{1 - \\alpha_{t}}\\mathbf{I} \\right) $，可以估计$ \\sigma_{t}^2\\approx\\frac{\\beta_{t}(1 - \\alpha_{t-1})}{1 - \\alpha_{t}}\\approx \\beta_{t} $，那么反向过程可以求得。\n自监督学习 已有数据集$ \\mathcal{D}=\\lbrace{\\mathbf{x}_{i}}\\rbrace_{i=1}^{N} $，通过数据集$ \\mathcal{D} $自身生成“伪标签”我们组成了新的带有伪标签的数据集$ \\mathcal{D}_{fake}=\\lbrace{\\mathbf{x}_{i}}, \\hat{y}_{i}\\rbrace_{i=1}^{N} $或$ \\mathcal{D}_{fake}=\\lbrace{\\mathbf{x}_{i}}, \\hat{\\mathbf{y}}_{i}\\rbrace_{i=1}^{N} $。自监督学习的思路是让学习过的模型$ \\mathbf{z} = f(\\mathbf{x}, \\boldsymbol{\\theta}) $将原始输入空间$ \\mathcal{X} $映射到潜在空间$ \\mathcal{Z} $，在该潜在空间上各个伪标签的区分度尽可能大。从这一方面来说，自监督学习可以看作在数据集$ D_{fake} $上进行有监督学习。但是伪标签毕竟不是真实标签，自监督学习主要是让模型通过学习$ p(\\hat{y}\\mid\\mathbf{x}) $或$ p(\\hat{\\mathbf{y}}\\mid\\mathbf{x}) $建立原始输入$ \\mathbf{x}_{i} $的潜在表示$ \\mathbf{z}_{i} $，然后再应用到一系列具有真实标签的下游任务。\n对比学习 对比学习作为当前自监督学习领域的热门研究方向，其目标是让模型不依赖人工标签自动学习到有区分力的特征表示。核心思想就是使得相似的样本经过模型映射后的特征尽可能靠近，不同的样本经过模型映射后的特征尽可能分开。\n也就是说，我们模型$ f(\\mathbf{x}, \\mathbf{x}^{'}, \\boldsymbol{\\theta}) $需要学习概率分布$ p(y\\mid \\mathbf{x}, \\mathcal{X}^{'}) $使之最大化，其中$ \\mathcal{X}^{'} = \\lbrace\\mathbf{x}_{1}^{'}, \\dots, \\mathbf{x}_{M}^{'}\\rbrace $，$ y $的定义为正样本的索引$ y = \\lbrace 1, \\dots, M\\rbrace $。由贝叶斯准则可知，$ p(y\\mid \\mathbf{x}, \\mathcal{X}^{'}) \\propto p(\\mathcal{X}^{'}\\mid\\mathbf{x}, y)p(y) $。假设正样本来自真实的条件分布$ p_{data}(\\mathbf{x}^{'}\\mid \\mathbf{x}) $，负样本来自噪声分布$ q(\\mathbf{x}^{'}) $，有条件独立性假设可得$ p(\\mathcal{X}^{'}\\mid\\mathbf{x}, y) = p_{data}(\\mathbf{x}^{'}_{y}\\mid\\mathbf{x})\\prod_{j\\neq y}q(\\mathbf{x}_{j}^{'}) $。那么经过归一化之后$ p(y\\mid \\mathbf{x}, \\mathcal{X}^{'}) = \\dfrac{\\frac{p_{data}(\\mathbf{x}^{'}_{y}\\mid\\mathbf{x})}{q(\\mathbf{x}_{y}^{'})}}{\\sum_{k=1}^{M}\\dfrac{p_{data}(\\mathbf{x}^{'}_{k}\\mid\\mathbf{x})}{q(\\mathbf{x}_{k}^{'})}} $。由上述公式的形式，我们可以直接参数化密度比$ f(\\mathbf{x}, \\mathbf{x}^{'}, \\boldsymbol{\\theta})\\approx\\frac{p_{data}(\\mathbf{x}^{'}\\mid\\mathbf{x})}{q(\\mathbf{x}^{'})} $，所以$ p_{\\boldsymbol{\\theta}}(y\\mid \\mathbf{x}, \\mathcal{X}^{'})=\\frac{f(\\mathbf{x}, \\mathbf{x}_{y}^{'}, \\boldsymbol{\\theta})}{\\sum_{k=1}^Mf(\\mathbf{x}, \\mathbf{x}_{k}^{'}, \\boldsymbol{\\theta})} $。\n上述表述的数学形式如下\n$$ \\begin{align} \\boldsymbol{\\theta}_{ML} \u0026= \\arg\\max_{\\boldsymbol{\\theta}} \\prod_{i=1}^{N} p_{\\boldsymbol{\\theta}}(y_{i}\\mid\\mathbf{x}_{i}, \\mathcal{X}^{'})\\quad (i.i.d.) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}}\\sum_{i=1}^{N}\\log p_{\\boldsymbol{\\theta}}(y_{i}\\mid\\mathbf{x}_{i}, \\mathcal{X}^{'}) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}}\\sum_{i=1}^{N}\\log \\frac{f(\\mathbf{x}_{i}, \\mathbf{x}_{y_{i}}^{'}, \\boldsymbol{\\theta})}{\\sum_{k=1}^Mf(\\mathbf{x}_{i}, \\mathbf{x}_{k}^{'}, \\boldsymbol{\\theta})} \\\\ \u0026= \\arg\\min_{\\boldsymbol{\\theta}}-\\frac{1}{N}\\sum_{i=1}^{N}\\log \\frac{f(\\mathbf{x}_{i}, \\mathbf{x}_{y_{i}}^{'}, \\boldsymbol{\\theta})}{\\sum_{k=1}^Mf(\\mathbf{x}_{i}, \\mathbf{x}_{k}^{'}, \\boldsymbol{\\theta})} \\\\ \u0026= \\arg\\min_{\\boldsymbol{\\theta}}\\frac{1}{N}\\sum_{i=1}^N\\log\\left[ 1 + \\frac{\\sum_{k\\neq y_{i}}f(\\mathbf{x}_{i}, \\mathbf{x}_{k}', \\boldsymbol{\\theta})}{f(\\mathbf{x}_{i}, \\mathbf{x}_{y_{i}}',\\boldsymbol{\\theta})} \\right] \\\\ \u0026= \\arg\\min \\mathbb{E}_{\\mathbf{x}}\\left[\\log\\left[1 + \\frac{q(\\mathbf{x}_{y_{i}}^{'})}{p_{data}(\\mathbf{x}_{y_{i}}^{'}\\mid\\mathbf{x})}\\sum_{k\\neq y_{i}}\\frac{p_{data}(\\mathbf{x}_{k}^{'}\\mid\\mathbf{x})}{q(\\mathbf{x}_{k}^{'})}\\right]\\right] \\\\ \u0026\\approx \\arg\\min \\mathbb{E}_{\\mathbf{x}}\\left[\\log\\left[1 + \\frac{q(\\mathbf{x}_{y_{i}}^{'})}{p_{data}(\\mathbf{x}_{y_{i}}^{'}\\mid\\mathbf{x})}(M-1)\\sum_{k\\neq y_{i}}q(\\mathbf{x}_{k}')\\frac{p_{data}(\\mathbf{x}_{k}^{'}\\mid\\mathbf{x})}{q(\\mathbf{x}_{k}^{'})}\\right]\\right] \\\\ \u0026= \\arg\\min \\mathbb{E}_{\\mathbf{x}}\\left[\\log\\left[1 + \\frac{q(\\mathbf{x}_{y_{i}}^{'})}{p_{data}(\\mathbf{x}_{y_{i}}^{'}\\mid\\mathbf{x})}(M-1)\\right]\\right] \\\\ \u0026\\geq \\arg\\min \\mathbb{E}_{\\mathbf{x}}\\left[\\log \\left[\\frac{q(\\mathbf{x}_{y_{i}}^{'})}{p_{data}(\\mathbf{x}_{y_{i}}^{'}\\mid\\mathbf{x})}M\\right]\\right] \\\\ \u0026= \\arg\\min \\mathbb{E}_{\\mathbf{x}} \\left[\\log \\left[\\frac{q(\\mathbf{x}_{y_{i}}^{'})}{p_{data}(\\mathbf{x}_{y_{i}}^{'}\\mid\\mathbf{x})}M\\right]\\right] \\\\ \u0026= \\arg\\min -I(\\mathcal{X}', \\mathbf{x}) + \\log M \\end{align} $$ 也就是说，最大化$ p(y\\mid \\mathbf{x}, \\mathcal{X}^{'}) $同时也等价于最大化$ \\mathcal{X}' $和$ \\mathbf{x} $的互信息，在优化损失函数的过程中使得随机变量$ \\mathbf{x} $和对应的正样本$ \\mathcal{X}' $的耦合程度尽可能大，也就是尽可能保持正样本对齐。\n","wordCount":"1272","inLanguage":"en","image":"https://fordelkon.github.io/img/prob_dl_summary.png","datePublished":"2025-08-23T10:36:33+09:00","dateModified":"2025-08-23T10:36:33+09:00","author":{"@type":"Person","name":"DL Kong"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://fordelkon.github.io/posts/prob_dl/"},"publisher":{"@type":"Organization","name":"DL Kong","logo":{"@type":"ImageObject","url":"https://fordelkon.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://fordelkon.github.io/ accesskey=h title="DL Kong (Alt + H)"><img src=https://fordelkon.github.io/logo_filled_outlined_6.png alt="Site icon in header" aria-label=logo height=35>DL Kong</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><button id=menu-trigger aria-haspopup=menu aria-label="Menu Button">
<svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><ul class="menu hidden"><li><a href=https://fordelkon.github.io/about/ title=About><span>About</span></a></li><li><a href=https://fordelkon.github.io/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://fordelkon.github.io/teaching/ title=Teaching><span>Teaching</span></a></li><li><a href=https://fordelkon.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://fordelkon.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://fordelkon.github.io/posts/>Posts</a></div><h1 class=post-title>概率视角中的深度学习</h1><div class=post-meta><span title='2025-08-23 10:36:33 +0900 +0900'>August 8, 23033</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;DL Kong</div></header><div class="toc side left"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#有监督判别>有监督判别</a></li><li><a href=#无监督生成>无监督生成</a><ul><li><a href=#-mathrmgangenerativeadversarialnetworks-><code>$ \mathrm{GAN(Generative\:Adversarial\:Networks)} $</code></a></li><li><a href=#-mathrmvaevaritionalautoencoders-><code>$ \mathrm{VAE(Varitional\:AutoEncoders)} $</code></a></li><li><a href=#-mathrmdiffusionmodels-><code>$ \mathrm{Diffusion\:Models} $</code></a><ul><li><a href=#前向过程-mathrmforwardprocess->前向过程(<code>$ \mathrm{Forward\:Process} $</code>)</a></li><li><a href=#扩散损失>扩散损失</a><ul><li><a href=#原始扩散损失>原始扩散损失</a></li><li><a href=#重参数化扩散损失>重参数化扩散损失</a></li></ul></li><li><a href=#反向过程-mathrmreversesampling-process->反向过程(<code>$ \mathrm{Reverse\:(Sampling)\: Process} $</code>)</a></li></ul></li></ul></li><li><a href=#自监督学习>自监督学习</a><ul><li><a href=#对比学习>对比学习</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p>我们可以从概率的角度去探讨深度学习任务，假设我们已有数据集<code>$ \mathcal{D}=\lbrace(\mathbf{x}_{i}, y_{i})\rbrace_{i=1}^{N} $</code>或<code>$ \mathcal{D}=\lbrace\mathbf{x}_{i}\rbrace_{i=1}^{N} $</code>，主要区分于有标签和无标签的情况。那么我们可以将常见深度学习任务中模型要建模的概率进行如下区分</p><ul><li>有监督判别：模型根据输入预测真实标签的概率分布<code>$ p_{\boldsymbol{\theta}}(y\mid\mathbf{x}) $</code></li><li>自监督判别：模型根据输入预测伪标签的概率分布<code>$ p_{\boldsymbol{\theta}}(\hat{y}\mid\mathbf{x}) $</code></li><li>有监督生成：模型根据真实标签预测与标签对应的数据集的空间分布<code>$ p_{\boldsymbol{\theta}}(\mathbf{x}\mid y) $</code></li><li>无监督生成：模型预测数据集的空间分布<code>$ p_{\boldsymbol{\theta}}(\mathbf{x}) $</code>
其中<code>$ \mathbf{x} $</code>和<code>$ y $</code>分别表示输入和标签的随机张量，<code>$ \boldsymbol{\theta} $</code>表示模型中可学习的参数。从概率角度探讨深度学习任务之前，我们应当明确如下假设：<font color=#c00000>输入到模型的数据满足独立同分布(independent and identically distributed)</font>。</li></ul><center><img src=./img/prob_dl_summary.png alt=图片1 width=400></center><center><strong>不同深度学习任务所学习的概率分布总结</strong></center><h2 id=有监督判别>有监督判别<a hidden class=anchor aria-hidden=true href=#有监督判别>#</a></h2><p>已有数据集<code>$ \mathcal{D}=\lbrace(\mathbf{x}_{i}, y_{i})\rbrace_{i=1}^{N} $</code>，我们应该使得数据集<code>$ \mathcal{D} $</code>被观测到的概率尽可能大，也就是说给定输入<code>$ \mathbf{x}_{i} $</code>，经过模型<code>$ f(\mathbf{x}, \boldsymbol{\theta}) $</code>处理之后得到潜在空间<code>$ \mathbf{z}_{i} $</code>或<code>$ z_{i} $</code>，其中<code>$ \mathbf{z}_{i}=f(\mathbf{x}_{i}, \boldsymbol{\theta})\in \mathbb{R}^{K} $</code>，在这个潜在空间中我们有最大的把握预测出<code>$ y_{i} $</code>。上述描述用数学形式表达如下：</p><div>$$
\begin{align}
\boldsymbol{\theta}_{ML} &= \arg\max_{\boldsymbol{\theta}} p_{\boldsymbol{\theta}}(\mathcal{D}) \\
&= \arg\max_{\boldsymbol{\theta}} p_{\boldsymbol{\theta}}(y_{1}, y_{2}, \dots, y_{N}\mid\mathbf{x}_{1}, \mathbf{x}_{2}, \dots, \mathbf{x}_{N}) \\
&= \arg\max_{\boldsymbol{\theta}} \prod_{i=1}^{N} p_{\boldsymbol{\theta}}(y_{i}\mid\mathbf{x}_{i})\quad (i.i.d.) \\
&= \arg\max_{\boldsymbol{\theta}} \prod_{i=1}^{N}p(y_{i}\mid\mathbf{z}_{i}) \\
&= \arg\max_{\boldsymbol{\theta}}\sum_{i=1}^{N}\log p(y_{i}\mid\mathbf{z}_{i}) \\
&= \arg\min_{\boldsymbol{\theta}}-\sum_{i=1}^{N}\log p(y_{i}\mid\mathbf{z}_{i})
\end{align}
$$</div><p>常使用的<code>$ y $</code>分布有<code>$ y\sim \mathcal{N}(z, \sigma^2) $</code>（回归问题），<code>$ y\sim \mathrm{Bernoulli}(\mathrm{sigmoid}(z)) $</code>（二分类问题，使用<code>$ \mathrm{sigmoid} $</code>函数使得最终的输出区间为<code>$ [0, 1] $</code>），<code>$ p(y\mid\mathbf{z})=\mathrm{softmax}_{y}(\mathbf{z})=\frac{\exp[z_{y}]}{\sum_{y'=1}^{K}\exp[z_{y'}]} $</code>（多分类问题，<code>$ y\in\lbrace 1, 2, \dots, K\rbrace $</code>，<code>$ \mathbf{z}=[z_{1}, z_{2}, \dots, z_{K}] $</code>）。更多相关的概率分布可以参见<a href=/teaching/probdis/>常用概率分布</a>。</p><center><img src=./img/labeldis.png alt=图片1 width=600></center><h2 id=无监督生成>无监督生成<a hidden class=anchor aria-hidden=true href=#无监督生成>#</a></h2><p>已有数据集<code>$ \mathcal{D}=\lbrace{\mathbf{x}_{i}}\rbrace_{i=1}^{N} $</code>，无监督生成的任务就是使用模型学习出数据集的空间分布<code>$ p_{\boldsymbol{\theta}}(\mathbf{x}) $</code>。</p><h3 id=-mathrmgangenerativeadversarialnetworks-><code>$ \mathrm{GAN(Generative\:Adversarial\:Networks)} $</code><a hidden class=anchor aria-hidden=true href=#-mathrmgangenerativeadversarialnetworks->#</a></h3><p><code>$ \mathrm{GAN} $</code>的思路是训练出一个生成器<code>$ \hat{\mathbf{x}} = f_{g}(\mathbf{v}, \boldsymbol{\theta}^{g}):\mathcal{V}\to \mathcal{X} $</code>将潜在空间<code>$ \mathcal{V} $</code>很好地映射到样本空间<code>$ \mathcal{X} $</code>。要训练出这样的生成器，<code>$ \mathrm{GAN} $</code>额外训练了一个判别器<code>$ z = f_{d}(\mathbf{x}, \boldsymbol{\theta}^{d}):\mathcal{X}\to \mathbb{R} $</code>对生成的图像和真实的图像进行区分。对于生成器输入是潜在空间<code>$ \mathcal{V} $</code>的采样，而对于判别器，我们就拥有数据集<code>$ \mathcal{D}_{union} = \lbrace\mathbf{x}_{i}, 1\rbrace_{i=1}^N\cup{\lbrace\hat{\mathbf{x}}_{i}, 0\rbrace}_{i=1}^{M} = \lbrace\tilde{\mathbf{x}}_{i}, y_{i}\rbrace_{i=1}^{N+M} $</code>。在训练的过程中，针对生成器，我们要使其生成的图像更加真实（使得判别器判定高概率为真），针对判别器，我们要使判别器能够很好的区分生成器生成的伪造图像和真实图像。上面说法的数学形式如下</p><p>对于生成器：</p><div>$$
\begin{align}
\boldsymbol{\theta}_{ML}^{g} &= \arg\max_{\boldsymbol{\theta}^g} p(y=1\mid \hat{z}) \\
&= \arg\min_{\boldsymbol{\theta}^g}\log p(y=0\mid \hat{z})\quad(\hat{z} = f_{d}(\hat{\mathbf{x}}, \boldsymbol{\theta}^d))
\end{align}
$$</div><p>对于判别器</p><div>$$
\begin{align}
\boldsymbol{\theta}_{ML}^{d} &= \arg\max_{\boldsymbol{\theta}^d} p(y\mid \tilde{z}) \\
&= \arg\min_{\boldsymbol{\theta}^d}-\log p(y\mid \tilde{z})\quad(\tilde{z} = f_{d}(\tilde{\mathbf{x}}, \boldsymbol{\theta}^d)))
\end{align}
$$</div><h3 id=-mathrmvaevaritionalautoencoders-><code>$ \mathrm{VAE(Varitional\:AutoEncoders)} $</code><a hidden class=anchor aria-hidden=true href=#-mathrmvaevaritionalautoencoders->#</a></h3><p><code>$ \mathrm{VAE} $</code>的思路是也是训练一个解码器<code>$ \hat{\mathbf{x}} = f_{d}(\mathbf{v}, \boldsymbol{\theta}^{d}): \mathcal{V}\to \mathcal{X} $</code>将潜在空间<code>$ \mathcal{V} $</code>中很好映射到样本空间<code>$ \mathcal{X} $</code>。但是<code>$ \mathrm{VAE} $</code>是通过最大化建模得到的<code>$ p_{\boldsymbol{\theta}^d}(\mathbf{x}) $</code>来实现训练该解码器的。表示成数学形式如下：</p><div>$$
\begin{align}
\boldsymbol{\theta}_{ML}^d &= \arg\max_{\boldsymbol{\theta}^d} p_{\boldsymbol{\theta}^d}(\mathbf{x}) \\
&= \arg\max_{\boldsymbol{\theta}^d} \int p_{\boldsymbol{\theta}^d}(\mathbf{x}, \mathbf{v})d\mathbf{v} \\
&= \arg\max_{\boldsymbol{\theta}^d} \int p_{\boldsymbol{\theta}^d}(\mathbf{x}\mid \mathbf{v})p(\mathbf{v})d\mathbf{v} \\
&= \arg\max_{\boldsymbol{\theta}^d} \log\int p_{\boldsymbol{\theta}^d}(\mathbf{x}\mid \mathbf{v})p(\mathbf{v})d\mathbf{v}\quad \bigotimes \quad ( not \: intractable)
\end{align}
$$</div><p>由上式可知，直接求解<code>$ \boldsymbol{\theta}^d $</code>使得<code>$ \log\int p_{\boldsymbol{\theta}^d}(\mathbf{x}\mid \mathbf{v})p(\mathbf{v})d\mathbf{v} $</code>最大化往往不可能，我们应该找到<code>$ \log\int p_{\boldsymbol{\theta}^d}(\mathbf{x}\mid \mathbf{v})p(\mathbf{v})d\mathbf{v} $</code>的一个便于求解<code>$ \boldsymbol{\theta}^d $</code>的下界<code>$ \mathrm{ELBO}(\boldsymbol{\theta}^d)\mathrm{\:Evidence \:Lower\:BOund} $</code>，使得更新<code>$ \boldsymbol{\theta}^d $</code>让下界<code>$ \mathrm{ELBO}(\boldsymbol{\theta}^d) $</code>变大的同时，能够间接地使得<code>$ \log\int p_{\boldsymbol{\theta}^d}(\mathbf{x}\mid \mathbf{v})p(\mathbf{v})d\mathbf{v} $</code>增大。</p><div>$$
\begin{align}
\log p_{\boldsymbol{\theta}^d}(\mathbf{x})&=\log\int p_{\boldsymbol{\theta}^d}(\mathbf{x}, \mathbf{v})d\mathbf{v} \\
&= \log \int q(\mathbf{v})\frac{p_{\boldsymbol{\theta}^d}(\mathbf{x}, \mathbf{v})}{q(\mathbf{v})}d\mathbf{v} \\
&\geq \int q(\mathbf{v})\log\frac{p_{\boldsymbol{\theta}^d}(\mathbf{x}, \mathbf{v})}{q(\mathbf{v})}d\mathbf{v} \quad (\mathrm{Jensen's\:inequality})
\end{align}
$$</div><p>因此，我们可以取下界为</p><div>$$
\mathrm{ELBO}(\boldsymbol{\theta}^d) = \int q(\mathbf{v})\log\frac{p_{\boldsymbol{\theta}^d}(\mathbf{x}, \mathbf{v})}{q(\mathbf{v})}d\mathbf{v}
$$</div><p>实际操作中<code>$ \mathbf{v} $</code>的概率分布<code>$ q(\mathbf{v}) $</code>通常也是由编码器模型生成，也就是说下界<code>$ \mathrm{ELBO}(\boldsymbol{\theta}^d) $</code>更为规范的写法为<code>$ \mathrm{ELBO}(\boldsymbol{\theta}^e, \boldsymbol{\theta}^d) $</code></p><div>$$
\begin{align}
\mathrm{ELBO}(\boldsymbol{\theta}^e, \boldsymbol{\theta}^d) &= \int q_{\boldsymbol{\theta}^e}(\mathbf{v})\log\frac{p_{\boldsymbol{\theta}^d}(\mathbf{x}, \mathbf{v})}{q_{\boldsymbol{\theta}^e}(\mathbf{v})}d\mathbf{v} \\
&= \int q_{\boldsymbol{\theta}^e}(\mathbf{v})\log\frac{p_{\boldsymbol{\theta}^d}(\mathbf{v}\mid\mathbf{x})p_{\boldsymbol{\theta}^d}(\mathbf{x})}{q_{\boldsymbol{\theta}^e}(\mathbf{v})}d\mathbf{v} \\
&= \int q_{\boldsymbol{\theta}^e}(\mathbf{v})\log p_{\boldsymbol{\theta}^d}(\mathbf{x})d\mathbf{v} + \int q_{\boldsymbol{\theta}^e}(\mathbf{v})\log\frac{p_{\boldsymbol{\theta}^d}(\mathbf{v}\mid\mathbf{x})}{q_{\boldsymbol{\theta}^e}(\mathbf{v})}d\mathbf{v} \quad (one\:perspective) \\
&= \log p_{\boldsymbol{\theta}^d}(\mathbf{x}) - \mathrm{D}_{\mathrm{KL}}\Big[q_{\boldsymbol{\theta}^e}(\mathbf{v})||p_{\boldsymbol{\theta}^d}(\mathbf{v}\mid\mathbf{x})\Big] \\ \\
&= \int q_{\boldsymbol{\theta}^e}(\mathbf{v})\log\frac{p_{\boldsymbol{\theta}^d}(\mathbf{x}\mid\mathbf{v})p(\mathbf{v})}{q_{\boldsymbol{\theta}^e}(\mathbf{v})}d\mathbf{v} \\
&= \int q_{\boldsymbol{\theta}^e}(\mathbf{v})\log p_{\boldsymbol{\theta}^d}(\mathbf{x}\mid\mathbf{v})d\mathbf{v} + \int q_{\boldsymbol{\theta}^e}(\mathbf{v})\log\frac{p(\mathbf{v})}{q_{\boldsymbol{\theta}^e}(\mathbf{v})}d\mathbf{v}\quad (another\:perspective) \\
&= \int q_{\boldsymbol{\theta}^e}(\mathbf{v})\log p_{\boldsymbol{\theta}^d}(\mathbf{x}\mid\mathbf{v})d\mathbf{v} - \mathrm{D}_{\mathrm{KL}}\Big[q_{\boldsymbol{\theta}^e}(\mathbf{v})||p(\mathbf{v})\Big] \\
&\approx \log p_{\boldsymbol{\theta}^d}(\mathbf{x}\mid\mathbf{v}^*) - \mathrm{D}_{\mathrm{KL}}\Big[q_{\boldsymbol{\theta}^e}(\mathbf{v})||p(\mathbf{v})\Big] \quad (Monte\:Carlo\:estimate)
\end{align}
$$</div><p>上述公式中<code>$ q_{\boldsymbol{\theta}^e}(\mathbf{v})\approx q_{\boldsymbol{\theta}^e}(\mathbf{v}\mid \mathbf{x})=\mathcal{N}(\mathbf{v}\mid f_{e}^{\boldsymbol{\mu}}(\mathbf{x}, \boldsymbol{\theta}^e), f_{e}^{\boldsymbol{\Sigma}}(\mathbf{x}, \boldsymbol{\theta}^e)) $</code>，<code>$ p(\mathbf{v})=\mathcal{N}(\mathbf{v}|0, 1) $</code>，<code>$ \mathbf{v}^* $</code>也是从分布中<code>$ q_{\boldsymbol{\theta}^e}(\mathbf{v}\mid \mathbf{x}) $</code>抽样得到。之后我们就可以通过最大化<code>$ \mathrm{ELBO}(\boldsymbol{\theta}^e, \boldsymbol{\theta}^d) $</code>来进行优化模型从而对<code>$ p_{\boldsymbol{\theta}^d}(\mathbf{x}) $</code>进行建模。</p><h3 id=-mathrmdiffusionmodels-><code>$ \mathrm{Diffusion\:Models} $</code><a hidden class=anchor aria-hidden=true href=#-mathrmdiffusionmodels->#</a></h3><p><code>$ \mathrm{Diffusion\:Models} $</code>的目标也是训练出一个解码器<code>$ \hat{\mathbf{x}} = f_{d}(\mathbf{v}, \boldsymbol{\theta}): \mathcal{V}\to \mathcal{X} $</code>将潜在空间<code>$ \mathcal{V} $</code>中很好映射到样本空间<code>$ \mathcal{X} $</code>。和<code>$ \mathrm{VAE} $</code>一样，<code>$ \mathrm{Diffusion\:Models} $</code>的目标也是最大化<code>$ p_{\boldsymbol{\theta}}(\mathbf{x}) $</code>来实现训练该解码器的，但是<code>$ \mathrm{Diffusion\:Models} $</code>的潜在变量<code>$ \mathbf{v} $</code>通常是通过原始输入<code>$ \mathbf{x} $</code>逐渐加噪得到的，而解码器学习从潜在变量<code>$ \mathbf{v} $</code>一步步生成逼真的样本。这一过程的形式化表示如下所示，为了方便推导公式简化，令<code>$ \mathbf{v} = \mathbf{z}_{T} $</code></p><div>$$
\mathrm{forward\:process}: \mathbf{x}\to \mathbf{z}_{1}\to \mathbf{z}_{2}\to\dots\to \mathbf{z}_{T-1}\to\mathbf{z}_{T}\quad(\mathbf{v})
$$</div><div>$$
\mathrm{reverse\:process}: (\mathbf{v})\quad\mathbf{z}_{T}\to \mathbf{z}_{T-1}\to \mathbf{z}_{T-2}\to\dots\to \mathbf{z}_{1}\to\mathbf{x}
$$</div><p>根据上述框架，我们可以对<code>$ p_{\boldsymbol{\theta}}(\mathbf{x}) $</code>最大化求解<code>$ \boldsymbol{\theta} $</code></p><div>$$
\begin{align}
\boldsymbol{\theta}_{ML} &= \arg\max_{\boldsymbol{\theta}}p_{\boldsymbol{\theta}}(\mathbf{x}) \\
&= \arg\max_{\boldsymbol{\theta}}\int p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z}_{1\dots T})d\mathbf{z}_{1\dots T} \\
&= \arg\max_{\boldsymbol{\theta}}\log \int p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z}_{1\dots T})d\mathbf{z}_{1\dots T} \quad \bigotimes \quad ( not \: intractable)
\end{align}
$$</div><p>和<code>$ \mathrm{VAE} $</code>一样，我们寻找<code>$ \log \int p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z}_{1}, \mathbf{z}_{2}, \dots, \mathbf{z}_{T-1}, \mathbf{v})d\mathbf{z}_{1}d\mathbf{z}_{2}\dots d\mathbf{z}_{T-1}d\mathbf{v} $</code>的一个便于优化的下界<code>$ \mathrm{ELBO}(\boldsymbol{\theta})\mathrm{\:Evidence \:Lower\:BOund} $</code>来对<code>$ \boldsymbol{\theta} $</code>进行优化求解</p><div>$$
\begin{align}
\log p_{\boldsymbol{\theta}}(\mathbf{x}) &= \log \int p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z}_{1\dots T})d\mathbf{z}_{1\dots T}\\
&= \log\left[ \int q(\mathbf{z}_{1\dots T}\mid \mathbf{x}) \frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z}_{1\dots T})}{q(\mathbf{z}_{1\dots T}\mid \mathbf{x})}d\mathbf{z}_{1\dots T}\right] \\
&\geq \int q(\mathbf{z}_{1\dots T}\mid \mathbf{x}) \log \frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z}_{1\dots T})}{q(\mathbf{z}_{1\dots T} \mid \mathbf{x})}d\mathbf{z}_{1\dots T} \quad (\mathrm{Jensen's\:inequality})
\end{align}
$$</div><p>也就是说我们可以取证据下界</p><div>$$
\mathrm{ELBO}(\boldsymbol{\theta}) = \int q(\mathbf{z}_{1\dots T}\mid \mathbf{x}) \log \frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z}_{1\dots T})}{q(\mathbf{z}_{1\dots T} \mid \mathbf{x})}d\mathbf{z}_{1\dots T}
$$</div><p>在<code>$ \mathrm{VAE} $</code>中，编码器通过参数来学习给定输入下潜在变量的后验概率分布<code>$ q_{\boldsymbol{\theta}^e}(\mathbf{v}\mid \mathbf{x}) $</code>，但是在<code>$ \mathrm{Diffusion\:Models} $</code>中的编码器是没有参数的，因此解码器的参数在更新时应当考虑使得无参数编码器尽可能近似后验概率分布<code>$ p_{\boldsymbol{\theta}}(\mathbf{z}_{1}, \mathbf{z}_{2}, \dots, \mathbf{z}_{T-1}, \mathbf{v}\mid \mathbf{x}) $</code>。</p><p>下面对<code>$ \mathrm{ELBO}(\boldsymbol{\theta}) $</code>中的<code>$ \log $</code>项进行进一步的分析简化，</p><div>$$
\begin{align}
\log \frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z}_{1\dots T})}{q(\mathbf{z}_{1\dots T} \mid \mathbf{x})} &= \log\left[ \frac{p_{\boldsymbol{\theta}}(\mathbf{x}\mid\mathbf{z}_{1})\prod_{t=2}^Tp_{\boldsymbol{\theta}}(\mathbf{z}_{t-1}\mid\mathbf{z}_{t})\cdot p(\mathbf{z}_{T})}{q(\mathbf{z}_{1}\mid\mathbf{x})\prod_{t=2}^Tq(\mathbf{z}_{t}\mid \mathbf{z}_{t-1})} \right]\\
&= \log\left[ \frac{p_{\boldsymbol{\theta}}(\mathbf{x}\mid\mathbf{z}_{1})}{q(\mathbf{z}_{1}\mid \mathbf{x})} \right] + \log\left[ \frac{\prod_{t=2}^Tp_{\boldsymbol{\theta}}(\mathbf{z}_{t-1}\mid\mathbf{z}_{t})}{\prod_{t=2}^Tq(\mathbf{z}_{t}\mid \mathbf{z}_{t-1})} \right] + \log[p(\mathbf{z}_{T})] \\
&= \log\left[ p_{\boldsymbol{\theta}}(\mathbf{x}\mid\mathbf{z}_{1})\right] + \log\left[ \frac{\prod_{t=2}^Tp_{\boldsymbol{\theta}}(\mathbf{z}_{t-1}\mid\mathbf{z}_{t})}{\prod_{t=2}^Tq(\mathbf{z}_{t - 1}\mid \mathbf{z}_{t}, \mathbf{x})} \right] + \log\left[ \frac{p(\mathbf{z}_{T})}{q(\mathbf{z}_{T}\mid \mathbf{x})} \right]\quad (Bayes'\:rule) \\
&\approx \log\left[ p_{\boldsymbol{\theta}}(\mathbf{x}\mid\mathbf{z}_{1})\right] + \sum_{t=2}^{T}\log\left[ \frac{p_{\boldsymbol{\theta}}(\mathbf{z}_{t-1}\mid\mathbf{z}_{t})}{q(\mathbf{z}_{t - 1}\mid \mathbf{z}_{t}, \mathbf{x})} \right]
\end{align}
$$</div><p>所以<code>$ \mathrm{ELBO}(\boldsymbol{\theta}) $</code>可以转变为</p><div>$$
\begin{align}
\mathrm{ELBO}(\boldsymbol{\theta}) &= \int q(\mathbf{z}_{1\dots T}\mid \mathbf{x}) \log \frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z}_{1\dots T})}{q(\mathbf{z}_{1\dots T} \mid \mathbf{x})}d\mathbf{z}_{1\dots T} \\
&\approx \int q(\mathbf{z}_{1\dots T}\mid \mathbf{x})\left(\log\left[ p_{\boldsymbol{\theta}}(\mathbf{x}\mid\mathbf{z}_{1})\right] + \sum_{t=2}^{T}\log\left[ \frac{p_{\boldsymbol{\theta}}(\mathbf{z}_{t-1}\mid\mathbf{z}_{t})}{q(\mathbf{z}_{t - 1}\mid \mathbf{z}_{t}, \mathbf{x})} \right]\right)d\mathbf{z}_{1\dots T} \\
&= \int q(\mathbf{z}_{1}\mid \mathbf{x})\log\left[ p_{\boldsymbol{\theta}}(\mathbf{x}\mid\mathbf{z}_{1})\right]d\mathbf{z}_{1} + \sum_{t=2}^{T}\int q(\mathbf{z}_{t-1}, \mathbf{z}_{t}\mid \mathbf{x})\log\left[ \frac{p_{\boldsymbol{\theta}}(\mathbf{z}_{t-1}\mid\mathbf{z}_{t})}{q(\mathbf{z}_{t - 1}\mid \mathbf{z}_{t}, \mathbf{x})} \right]d\mathbf{z}_{t-1}d\mathbf{z}_{t} \\
&= \int q(\mathbf{z}_{1}\mid \mathbf{x})\log\left[ p_{\boldsymbol{\theta}}(\mathbf{x}\mid\mathbf{z}_{1})\right]d\mathbf{z}_{1} + \sum_{t=2}^{T}\int q(\mathbf{z}_{t}\mid\mathbf{x})q(\mathbf{z}_{t-1}\mid \mathbf{z}_{t}, \mathbf{x})\log\left[ \frac{p_{\boldsymbol{\theta}}(\mathbf{z}_{t-1}\mid\mathbf{z}_{t})}{q(\mathbf{z}_{t - 1}\mid \mathbf{z}_{t}, \mathbf{x})} \right]d\mathbf{z}_{t-1}d\mathbf{z}_{t} \quad (Bayes'\:rule) \\
&= \int \textcolor{blue}{q(\mathbf{z}_{1}\mid \mathbf{x})}\log\left[ \textcolor{green}{p_{\boldsymbol{\theta}}(\mathbf{x}\mid\mathbf{z}_{1})}\right]d\mathbf{z}_{1} - \sum_{t=2}^{T}\int \textcolor{red}{q(\mathbf{z}_{t}\mid\mathbf{x})}\mathrm{D}_{\mathrm{KL}}(\textcolor{purple}{q(\mathbf{z}_{t-1}\mid\mathbf{z}_{t}, \mathbf{x})}||\textcolor{pink}{p_{\boldsymbol{\theta}}(\mathbf{z}_{t-1}\mid\mathbf{z}_{t})})d\mathbf{z}_{t}
\end{align}
$$</div><p>上述<code>$ \mathrm{ELBO}(\boldsymbol{\theta}) $</code>的所有标明颜色的概率分布都可以通过正态分布建模出来</p><div>$$
\textcolor{green}{p_{\boldsymbol{\theta}}(\mathbf{x}\mid\mathbf{z}_{1})} = \mathcal{N}\left(\mathbf{x}\mid f_{d}(\mathbf{z}_{1}, \boldsymbol{\theta}), \sigma_{1}^2\mathbf{I}\right)
$$</div><div>$$
\textcolor{pink}{p_{\boldsymbol{\theta}}(\mathbf{z}_{t-1}\mid\mathbf{z}_{t})} = \mathcal{N}\left(\mathbf{z}_{t-1}\mid f_{d}(\mathbf{z}_{t}, \boldsymbol{\theta}), \sigma_{t}^2\mathbf{I}\right)
$$</div><h4 id=前向过程-mathrmforwardprocess->前向过程(<code>$ \mathrm{Forward\:Process} $</code>)<a hidden class=anchor aria-hidden=true href=#前向过程-mathrmforwardprocess->#</a></h4><div>$$
\mathbf{z}_{1} = \sqrt{ 1-\beta_{1} }\mathbf{x} + \sqrt{ \beta_{1} }\boldsymbol{\epsilon}_{1}
$$</div><div>$$
\mathbf{z}_{t} = \sqrt{ 1-\beta_{t} }\mathbf{z}_{t-1} + \sqrt{ \beta_{t} }\boldsymbol{\epsilon}_{t}\quad\quad \forall t\in 2, \dots, T
$$</div><p>其中<code>$ \boldsymbol{\epsilon}_{t} $</code>是从标准正态分布中抽取的噪声(<code>$ \boldsymbol{\epsilon}_{t}\sim \mathcal{N}(\mathbf{0}, \mathbf{I}) $</code>)，前向过程的第一项衰减了数据以及至今添加的任何噪声，第二项增加了更多的噪声。超参数<code>$ \beta_{t} $</code>则决定了噪声的混合速度。方程形式转化成概率形式如下</p><div>$$
\textcolor{blue}{q(\mathbf{z}_{1}\mid\mathbf{x})} = \mathcal{N}(\mathbf{z}_{1}|\sqrt{ 1-\beta_{1} }\mathbf{x}, \beta_{1}\mathbf{I})
$$</div><div>$$
q(\mathbf{z}_{t}\mid\mathbf{z}_{t-1}) = \mathcal{N}(\mathbf{z}_{t}|\sqrt{ 1 - \beta_{t} }\mathbf{z}_{t-1}, \beta_{t}\mathbf{I})
$$</div><p>上述过程形成了一个<code>$ Markov $</code>链，当<code>$ T $</code>足够大时，<code>$ q(\mathbf{z}_{T}|\mathbf{x})=q(\mathbf{z}_{T}) $</code>就会成为标准正态分布。已知以上概率分布我们可以很方便地推导出<code>$ \textcolor{purple}{q(\mathbf{z}_{t-1}\mid\mathbf{z}_{t}, \mathbf{x})} $</code></p><div>$$
\textcolor{purple}{q(\mathbf{z}_{t-1}\mid\mathbf{z}_{t}, \mathbf{x})} = \mathcal{N}\left( \mathbf{z}_{t-1}\mid \frac{1-\alpha_{t-1}}{1-\alpha_{t}}\sqrt{ 1-\beta_{t} }\mathbf{z}_{t} + \frac{\sqrt{ \alpha_{t-1} }\beta_{t}}{1 - \alpha_{t}}\mathbf{x}, \frac{\beta_{t}(1 - \alpha_{t-1})}{1 - \alpha_{t}}\mathbf{I} \right)
$$</div><p>其中<code>$ \alpha_{t} = \prod_{s=1}^{t}1 - \beta_{s} $</code>。</p><h4 id=扩散损失>扩散损失<a hidden class=anchor aria-hidden=true href=#扩散损失>#</a></h4><h5 id=原始扩散损失>原始扩散损失<a hidden class=anchor aria-hidden=true href=#原始扩散损失>#</a></h5><p>经过正态分布建模后，原始扩散损失为</p><div>$$
\begin{align}
-\mathrm{ELBO}(\boldsymbol{\theta}) &= \sum_{n=1}^N\Big( -\log[\mathcal{N}(\mathbf{x}_{n}\mid f_{d}(\mathbf{z}_{n1}, \boldsymbol{\theta}), \sigma_{1}^2\mathbf{I})] \\
&\quad\quad+ \frac{1}{2\sigma^2}\sum_{t=2}^T\Big\lvert\Big\lvert \frac{1 - \alpha_{t-1}}{1 - \alpha_{t}}\sqrt{ 1 - \beta_{t} } \mathbf{z}_{nt} + \frac{\sqrt{ \alpha_{t - 1} }\beta_{t}}{1 - \alpha_{t}}\mathbf{x}_{n} - f_{d}(\mathbf{z}_{nt}, \boldsymbol{\theta})\Big\rvert\Big\rvert^2 \Big)
\end{align}
$$</div><h5 id=重参数化扩散损失>重参数化扩散损失<a hidden class=anchor aria-hidden=true href=#重参数化扩散损失>#</a></h5><p>由前向过程我们可以推导得到</p><div>$$
\mathbf{z}_{t} = \sqrt{ \alpha_{t} }\cdot \mathbf{x} + \sqrt{ 1 - \alpha_{t} }\boldsymbol{\epsilon}
$$</div><div>$$
\mathbf{x} = \frac{1}{\sqrt{ \alpha_{t} }}\cdot \mathbf{z}_{t} - \frac{\sqrt{ 1 - \alpha_{t} }}{\sqrt{ \alpha_{t} }}\cdot\boldsymbol{\epsilon}
$$</div><p>将原始扩散损失中的<code>$ \mathbf{x} $</code>替换成<code>$ \mathbf{z}_{t} $</code></p><div>$$
\begin{align}
-\mathrm{ELBO}(\boldsymbol{\theta}) &= \sum_{n=1}^N\Big( -\log[\mathcal{N}(\mathbf{x}_{n}\mid f_{d}(\mathbf{z}_{n1}, \boldsymbol{\theta}), \sigma_{1}^2\mathbf{I})] \\
&\quad\quad+ \sum_{t=2}^T\frac{1}{2\sigma_{t}^2}\Big\lvert \Big\lvert \frac{1}{\sqrt{ 1 - \beta_{t} }} \mathbf{z}_{nt} - \frac{\beta_{t}}{\sqrt{ 1-\alpha_{t} }\sqrt{ 1-\beta_{t} }}\boldsymbol{\epsilon}_{nt} - f_{d}(\mathbf{z}_{nt}, \boldsymbol{\theta})\Big\rvert\Big\rvert^2 \Big) \\
&= \sum_{n=1}^N \Big(\frac{1}{2\sigma_{1}^2}\Big\lvert \Big\lvert \mathbf{x}_{n} - f_{d}(\mathbf{z}_{n1}, \boldsymbol{\theta})\Big\rvert\Big\rvert^2 + \sum_{t=2}^T\frac{\beta_{t}^2}{(1 - \alpha_{t})(1 - \beta_{t})2\sigma_{t}^2}\Big\lvert \Big\lvert g_{d}(\mathbf{z}_{nt}, \boldsymbol{\theta}) - \boldsymbol{\epsilon}_{nt}\Big\rvert\Big\rvert^2 + C_{n}\Big)\quad(Reparameterization\:of\:network) \\ \\
&= \sum_{n=1}^N\sum_{t=1}^T\frac{\beta_{t}^2}{(1 - \alpha_{t})(1 - \beta_{t})2\sigma_{t}^2}\Big\lvert \Big\lvert g_{d}(\mathbf{z}_{nt}, \boldsymbol{\theta}) - \boldsymbol{\epsilon}_{nt}\Big\rvert\Big\rvert^2 + C_{n}
\end{align}
$$</div><p>其中网络重参数化使用如下公式<code>$ f_{d}(\mathbf{z}_{nt}, \boldsymbol{\theta}) = \frac{1}{\sqrt{ 1 - \beta_{t} }} \mathbf{z}_{nt} - \frac{\beta_{t}}{\sqrt{ 1-\alpha_{t} }\sqrt{ 1-\beta_{t} }}g_{d}(\mathbf{z}_{nt}, \boldsymbol{\theta}) $</code>。有了上面的简约形式我们可以进一步对损失进行简化</p><div>$$
\begin{align}
\mathcal{L}(\boldsymbol{\theta}) &= \sum_{n=1}^N\sum_{t=1}^T\Big\lvert \Big\lvert g_{d}(\mathbf{z}_{nt}, \boldsymbol{\theta}) - \boldsymbol{\epsilon}_{nt}\Big\rvert\Big\rvert^2 \\
&= \sum_{n=1}^N\sum_{t=1}^T\Big\lvert \Big\lvert g_{d}(\sqrt{ \alpha_{t} }\mathbf{x}_{n} + \sqrt{ 1-\alpha_{t} }\boldsymbol{\epsilon}_{nt}, \boldsymbol{\theta}) - \boldsymbol{\epsilon}_{nt}\Big\rvert\Big\rvert^2
\end{align}
$$</div><h4 id=反向过程-mathrmreversesampling-process->反向过程(<code>$ \mathrm{Reverse\:(Sampling)\: Process} $</code>)<a hidden class=anchor aria-hidden=true href=#反向过程-mathrmreversesampling-process->#</a></h4><p>由式子<code>$ \textcolor{pink}{p_{\boldsymbol{\theta}}(\mathbf{z}_{t-1}\mid\mathbf{z}_{t})} = \mathcal{N}\left(\mathbf{z}_{t-1}\mid f_{d}(\mathbf{z}_{t}, \boldsymbol{\theta}), \sigma_{t}^2\mathbf{I}\right) $</code>可以将概率形式转化成如下方程形式</p><div>$$
\begin{align}
\mathbf{z}_{t-1} &= f_{d}(\mathbf{z}_{t}, \boldsymbol{\theta}) + \sigma_{t}\boldsymbol{\epsilon}_{t} \\
&= \frac{1}{\sqrt{ 1 - \beta_{t} }} \mathbf{z}_{t} - \frac{\beta_{t}}{\sqrt{ 1-\alpha_{t} }\sqrt{ 1-\beta_{t} }}g_{d}(\mathbf{z}_{t}, \boldsymbol{\theta}) + \sigma_{t}\boldsymbol{\epsilon}_{t} \\
\end{align}
$$</div><p>再由式子<code>$ \textcolor{purple}{q(\mathbf{z}_{t-1}\mid\mathbf{z}_{t}, \mathbf{x})} = \mathcal{N}\left( \mathbf{z}_{t-1}\mid \frac{1-\alpha_{t-1}}{1-\alpha_{t}}\sqrt{ 1-\beta_{t} }\mathbf{z}_{t} + \frac{\sqrt{ \alpha_{t-1} }\beta_{t}}{1 - \alpha_{t}}\mathbf{x}, \frac{\beta_{t}(1 - \alpha_{t-1})}{1 - \alpha_{t}}\mathbf{I} \right) $</code>，可以估计<code>$ \sigma_{t}^2\approx\frac{\beta_{t}(1 - \alpha_{t-1})}{1 - \alpha_{t}}\approx \beta_{t} $</code>，那么反向过程可以求得。</p><h2 id=自监督学习>自监督学习<a hidden class=anchor aria-hidden=true href=#自监督学习>#</a></h2><p>已有数据集<code>$ \mathcal{D}=\lbrace{\mathbf{x}_{i}}\rbrace_{i=1}^{N} $</code>，通过数据集<code>$ \mathcal{D} $</code>自身生成“伪标签”我们组成了新的带有伪标签的数据集<code>$ \mathcal{D}_{fake}=\lbrace{\mathbf{x}_{i}}, \hat{y}_{i}\rbrace_{i=1}^{N} $</code>或<code>$ \mathcal{D}_{fake}=\lbrace{\mathbf{x}_{i}}, \hat{\mathbf{y}}_{i}\rbrace_{i=1}^{N} $</code>。自监督学习的思路是让学习过的模型<code>$ \mathbf{z} = f(\mathbf{x}, \boldsymbol{\theta}) $</code>将原始输入空间<code>$ \mathcal{X} $</code>映射到潜在空间<code>$ \mathcal{Z} $</code>，在该潜在空间上各个伪标签的区分度尽可能大。从这一方面来说，自监督学习可以看作在数据集<code>$ D_{fake} $</code>上进行有监督学习。但是伪标签毕竟不是真实标签，自监督学习主要是让模型通过学习<code>$ p(\hat{y}\mid\mathbf{x}) $</code>或<code>$ p(\hat{\mathbf{y}}\mid\mathbf{x}) $</code>建立原始输入<code>$ \mathbf{x}_{i} $</code>的潜在表示<code>$ \mathbf{z}_{i} $</code>，然后再应用到一系列具有真实标签的下游任务。</p><h3 id=对比学习>对比学习<a hidden class=anchor aria-hidden=true href=#对比学习>#</a></h3><p>对比学习作为当前自监督学习领域的热门研究方向，其目标是让模型不依赖人工标签自动学习到有区分力的特征表示。核心思想就是使得相似的样本经过模型映射后的特征尽可能靠近，不同的样本经过模型映射后的特征尽可能分开。</p><p>也就是说，我们模型<code>$ f(\mathbf{x}, \mathbf{x}^{'}, \boldsymbol{\theta}) $</code>需要学习概率分布<code>$ p(y\mid \mathbf{x}, \mathcal{X}^{'}) $</code>使之最大化，其中<code>$ \mathcal{X}^{'} = \lbrace\mathbf{x}_{1}^{'}, \dots, \mathbf{x}_{M}^{'}\rbrace $</code>，<code>$ y $</code>的定义为正样本的索引<code>$ y = \lbrace 1, \dots, M\rbrace $</code>。由贝叶斯准则可知，<code>$ p(y\mid \mathbf{x}, \mathcal{X}^{'}) \propto p(\mathcal{X}^{'}\mid\mathbf{x}, y)p(y) $</code>。假设正样本来自真实的条件分布<code>$ p_{data}(\mathbf{x}^{'}\mid \mathbf{x}) $</code>，负样本来自噪声分布<code>$ q(\mathbf{x}^{'}) $</code>，有条件独立性假设可得<code>$ p(\mathcal{X}^{'}\mid\mathbf{x}, y) = p_{data}(\mathbf{x}^{'}_{y}\mid\mathbf{x})\prod_{j\neq y}q(\mathbf{x}_{j}^{'}) $</code>。那么经过归一化之后<code>$ p(y\mid \mathbf{x}, \mathcal{X}^{'}) = \dfrac{\frac{p_{data}(\mathbf{x}^{'}_{y}\mid\mathbf{x})}{q(\mathbf{x}_{y}^{'})}}{\sum_{k=1}^{M}\dfrac{p_{data}(\mathbf{x}^{'}_{k}\mid\mathbf{x})}{q(\mathbf{x}_{k}^{'})}} $</code>。由上述公式的形式，我们可以直接参数化密度比<code>$ f(\mathbf{x}, \mathbf{x}^{'}, \boldsymbol{\theta})\approx\frac{p_{data}(\mathbf{x}^{'}\mid\mathbf{x})}{q(\mathbf{x}^{'})} $</code>，所以<code>$ p_{\boldsymbol{\theta}}(y\mid \mathbf{x}, \mathcal{X}^{'})=\frac{f(\mathbf{x}, \mathbf{x}_{y}^{'}, \boldsymbol{\theta})}{\sum_{k=1}^Mf(\mathbf{x}, \mathbf{x}_{k}^{'}, \boldsymbol{\theta})} $</code>。</p><p>上述表述的数学形式如下</p><div>$$
\begin{align}
\boldsymbol{\theta}_{ML}
&= \arg\max_{\boldsymbol{\theta}} \prod_{i=1}^{N} p_{\boldsymbol{\theta}}(y_{i}\mid\mathbf{x}_{i}, \mathcal{X}^{'})\quad (i.i.d.) \\
&= \arg\max_{\boldsymbol{\theta}}\sum_{i=1}^{N}\log p_{\boldsymbol{\theta}}(y_{i}\mid\mathbf{x}_{i}, \mathcal{X}^{'}) \\
&= \arg\max_{\boldsymbol{\theta}}\sum_{i=1}^{N}\log \frac{f(\mathbf{x}_{i}, \mathbf{x}_{y_{i}}^{'}, \boldsymbol{\theta})}{\sum_{k=1}^Mf(\mathbf{x}_{i}, \mathbf{x}_{k}^{'}, \boldsymbol{\theta})} \\
&= \arg\min_{\boldsymbol{\theta}}-\frac{1}{N}\sum_{i=1}^{N}\log \frac{f(\mathbf{x}_{i}, \mathbf{x}_{y_{i}}^{'}, \boldsymbol{\theta})}{\sum_{k=1}^Mf(\mathbf{x}_{i}, \mathbf{x}_{k}^{'}, \boldsymbol{\theta})} \\
&= \arg\min_{\boldsymbol{\theta}}\frac{1}{N}\sum_{i=1}^N\log\left[ 1 + \frac{\sum_{k\neq y_{i}}f(\mathbf{x}_{i}, \mathbf{x}_{k}', \boldsymbol{\theta})}{f(\mathbf{x}_{i}, \mathbf{x}_{y_{i}}',\boldsymbol{\theta})} \right] \\
&= \arg\min \mathbb{E}_{\mathbf{x}}\left[\log\left[1 + \frac{q(\mathbf{x}_{y_{i}}^{'})}{p_{data}(\mathbf{x}_{y_{i}}^{'}\mid\mathbf{x})}\sum_{k\neq y_{i}}\frac{p_{data}(\mathbf{x}_{k}^{'}\mid\mathbf{x})}{q(\mathbf{x}_{k}^{'})}\right]\right] \\
&\approx \arg\min \mathbb{E}_{\mathbf{x}}\left[\log\left[1 + \frac{q(\mathbf{x}_{y_{i}}^{'})}{p_{data}(\mathbf{x}_{y_{i}}^{'}\mid\mathbf{x})}(M-1)\sum_{k\neq y_{i}}q(\mathbf{x}_{k}')\frac{p_{data}(\mathbf{x}_{k}^{'}\mid\mathbf{x})}{q(\mathbf{x}_{k}^{'})}\right]\right] \\
&= \arg\min \mathbb{E}_{\mathbf{x}}\left[\log\left[1 + \frac{q(\mathbf{x}_{y_{i}}^{'})}{p_{data}(\mathbf{x}_{y_{i}}^{'}\mid\mathbf{x})}(M-1)\right]\right] \\
&\geq \arg\min \mathbb{E}_{\mathbf{x}}\left[\log \left[\frac{q(\mathbf{x}_{y_{i}}^{'})}{p_{data}(\mathbf{x}_{y_{i}}^{'}\mid\mathbf{x})}M\right]\right] \\
&= \arg\min \mathbb{E}_{\mathbf{x}} \left[\log \left[\frac{q(\mathbf{x}_{y_{i}}^{'})}{p_{data}(\mathbf{x}_{y_{i}}^{'}\mid\mathbf{x})}M\right]\right] \\
&= \arg\min -I(\mathcal{X}', \mathbf{x}) + \log M
\end{align}
$$</div><p>也就是说，最大化<code>$ p(y\mid \mathbf{x}, \mathcal{X}^{'}) $</code>同时也等价于最大化<code>$ \mathcal{X}' $</code>和<code>$ \mathbf{x} $</code>的互信息，在优化损失函数的过程中使得随机变量<code>$ \mathbf{x} $</code>和对应的正样本<code>$ \mathcal{X}' $</code>的耦合程度尽可能大，也就是尽可能保持正样本对齐。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://fordelkon.github.io/tags/dl/>DL</a></li><li><a href=https://fordelkon.github.io/tags/probability/>Probability</a></li></ul><nav class=paginav><a class=prev href=https://fordelkon.github.io/posts/cmake_intro_1/><span class=title>« Prev</span><br><span>使用CMake的艺术1</span></a></nav></footer><div class=giscus_comments><script src=https://giscus.app/client.js data-repo=jesse-wei/jessewei.dev-PaperMod data-repo-id=R_kgDOJhJgPg data-category=Comments data-category-id=DIC_kwDOJhJgPs4CWei3 data-mapping=pathname data-strict=1 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous async></script></div><script async>document.querySelector("div.giscus_comments > script").setAttribute("data-theme",localStorage.getItem("pref-theme")?localStorage.getItem("pref-theme"):window.matchMedia("(prefers-color-scheme: dark)").matches?"transparent_dark":"light"),document.querySelector("#theme-toggle").addEventListener("click",()=>{let e=document.querySelector("iframe.giscus-frame");e&&e.contentWindow.postMessage({giscus:{setConfig:{theme:localStorage.getItem("pref-theme")?localStorage.getItem("pref-theme")==="dark"?"light":"transparent_dark":document.body.className.includes("dark")?"light":"transparent_dark"}}},"https://giscus.app")})</script></article></main><footer class=footer style=padding-top:18px;padding-bottom:18px><div class=social-icons style=padding-bottom:0><a style=border-bottom:none href=https://github.com/fordelkon rel=me title=Github><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
</a><a style=border-bottom:none href=https://x.com/fordelkon rel=me title=Twitter><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg>
</a><a style=border-bottom:none href=mailto:dlkong201893@gmail.com rel=me title=Email><svg viewBox="0 0 24 21" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></div><span>&copy; 2025 <a href=https://fordelkon.github.io/>DL Kong</a></span>
<span>•
Powered by
<a href=https://gohugo.io/>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/>PaperMod</a>
</span><span>•
<a href=/privacy>Privacy Policy</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let b=document.querySelector("#menu-trigger"),m=document.querySelector(".menu");b.addEventListener("click",function(){m.classList.toggle("hidden")}),document.body.addEventListener("click",function(e){b.contains(e.target)||m.classList.add("hidden")})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Teaching on DL Kong</title>
    <link>https://fordelkon.github.io/teaching/</link>
    <description>Recent content in Teaching on DL Kong</description>
    <image>
      <title>DL Kong</title>
      <url>https://fordelkon.github.io/logo_outlined_6.png</url>
      <link>https://fordelkon.github.io/logo_outlined_6.png</link>
    </image>
    <generator>Hugo -- 0.148.2</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 24 Aug 2025 18:13:33 +0900</lastBuildDate>
    <atom:link href="https://fordelkon.github.io/teaching/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>深度学习中常用的概率分布总结</title>
      <link>https://fordelkon.github.io/teaching/probdis/</link>
      <pubDate>Sun, 24 Aug 2025 18:13:33 +0900</pubDate>
      <guid>https://fordelkon.github.io/teaching/probdis/</guid>
      <description>&lt;p&gt;在深度学习中我们通常使用具有良好数学性质的概率分布对已有数据分布进行建模，以便得到优美的损失函数形式方便模型进行反向传播，同时赋予模型实际的概率含义。在该章节中我们介绍深度学习中常用的概率分布以及不同概率分布之间的距离度量方法。假设我们已有数据集&lt;code&gt;$ \mathcal{D}=\lbrace(\mathbf{x}_{i}, y_{i})\rbrace_{i=1}^{N} $&lt;/code&gt;或&lt;code&gt;$ \mathcal{D}=\lbrace\mathbf{x}_{i}\rbrace_{i=1}^{N} $&lt;/code&gt;，主要区分于有标签和无标签的情况，&lt;code&gt;$ z $&lt;/code&gt;或&lt;code&gt;$ \mathbf{z}$ &lt;/code&gt;主要表示深度学习模型未经处理的输出。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>

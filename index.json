[{"content":"进行深度学习实践的过程中我们所需要做的不仅仅只是搭建好模型，如何通过一系列的技巧来训练出一个较为优秀的模型也是至关重要的。没有训练好的模型作为证明就算模型架构再好也无法说明提出的模型的优越性，这一篇博客主要介绍我们可以从哪些方面来优化模型的训练过程。\n优化器 优化器是模型训练过程中一个很重要的成分，使用不同种类的优化器有时会对训练的过程产生很大的影响，同时优化器中一些超参数的选择有时候也会对训练过程产生很大的影响。下面介绍一些常用的优化器以及其中的超参数介绍：\n介绍优化器之前，我们要先定义训练集$ \\mathcal{D}_{train} $\n$$ \\mathcal{D}_{train} = \\begin{cases} \\lbrace \\mathbf{x_{i}}\\rbrace_{i=1}^{N_{train}} \u0026 no\\:labels \\\\ \\lbrace (\\mathbf{x}_{i}, y_{i})\\rbrace_{i=1}^{N_{train}} \u0026 labels \\end{cases} $$ 然后从训练集中采集包含$ B_{s} $个样本的小批量$ \\lbrace\\mathbf{x}^{1}, \\mathbf{x}^2, \\dots, \\mathbf{x}^{B_{s}}\\rbrace $，下面在上面的设定下介绍各个优化器，为了适应有标签和无标签的情况最终所计算的损失我们统一记为$ \\mathcal{L}(\\mathbf{x}, \\boldsymbol{\\theta}) $。\nSGD优化器 $$ \\begin{array}{l} \\boldsymbol{g}_{t} = \\frac{1}{B_{s}}\\nabla_{\\boldsymbol{\\theta}}\\sum_{i=1}^{B_{s}}\\mathcal{L}(\\mathbf{x}^i, \\boldsymbol{\\theta}_{t})\\quad \u0026\\text{(compute gradient at the current position)} \\\\ \\boldsymbol{\\theta}_{t + 1} = \\boldsymbol{\\theta}_{t} - \\eta\\: \\boldsymbol{g}_{t}\\quad \u0026\\text{(update the parameters)} \\end{array} $$ 上述公式中$ \\eta $表示学习率，$ \\boldsymbol{\\theta}_{t} $表示第$ t $步时的模型参数，$ \\boldsymbol{\\theta}_{t+1} $表示在处理过小批量数据$ \\lbrace\\mathbf{x}^{1}, \\mathbf{x}^2, \\dots, \\mathbf{x}^{B_{s}}\\rbrace $之后第$ t+1 $步的模型参数。\n使用Nesterov动量的SGD优化器 $$ \\begin{array}{l} \\textcolor{red}{\\tilde{\\boldsymbol{\\theta}}_{t}} = \\boldsymbol{\\theta}_{t} + \\alpha\\textcolor{blue}{\\boldsymbol{v}_{t}} \\quad \u0026\\text{(look ahead to the future position)} \\\\ \\boldsymbol{g}_{t} = \\frac{1}{B_{s}}\\nabla_{\\boldsymbol{\\theta}}\\sum_{i=1}^{B_{s}}\\mathcal{L}(\\mathbf{x}^i, \\textcolor{red}{\\tilde{\\boldsymbol{\\theta}}_{t}})\\quad \u0026\\text{(compute gradient at the lookahead position)} \\\\ \\textcolor{blue}{\\boldsymbol{v}_{t+1}} = \\alpha\\textcolor{blue}{\\boldsymbol{v}_{t}} - \\eta\\boldsymbol{g}_{t} \\quad \u0026\\text{(update the velocity)} \\\\ \\boldsymbol{\\theta}_{t+1} = \\boldsymbol{\\theta}_{t} + \\textcolor{blue}{\\boldsymbol{v}_{t+1}}\\quad \u0026\\text{(update the parameters)} \\end{array} $$ 上述公式中$ \\eta $表示学习率，$ \\alpha $表示动量参数，$ \\boldsymbol{v}_{0}=\\mathbf{0} $表示初始速度。$ \\boldsymbol{\\theta}_{t} $表示第$ t $步时的模型参数，$ \\boldsymbol{\\theta}_{t+1} $表示在处理过小批量数据$ \\lbrace\\mathbf{x}^{1}, \\mathbf{x}^2, \\dots, \\mathbf{x}^{B_{s}}\\rbrace $之后第$ t+1 $步的模型参数。\nRMSProp优化器 $$ \\begin{array}{l} \\boldsymbol{g}_{t} = \\frac{1}{B_{s}}\\nabla_{\\boldsymbol{\\theta}}\\sum_{i=1}^{B_{s}}\\mathcal{L}(\\mathbf{x}^i, \\boldsymbol{\\theta}_{t})\\quad \u0026\\text{(compute gradient at the current position)} \\\\ \\boldsymbol{r}_{t+1} = \\rho\\boldsymbol{r}_{t} + (1 - \\rho)\\boldsymbol{g}_{t}\\circ\\boldsymbol{g}_{t} \\quad \u0026\\text{(update the running average of squared gradients)} \\\\ \\boldsymbol{\\theta}_{t+1} = \\boldsymbol{\\theta}_{t} - \\frac{\\eta}{\\sqrt{ \\delta + \\boldsymbol{r}_{t+1} }}\\circ \\boldsymbol{g}_{t} \\quad \u0026\\text{(update the parameters with the adaptive scaling)} \\end{array} $$ 上述公式中$ \\eta $表示学习率，$ \\delta $表示一个较小的常数，用于被小数除时的数值稳定，$ \\rho $表示衰减速率，$ \\boldsymbol{r}_{0}=\\mathbf{0} $表示初始累积梯度平方变量。$ \\boldsymbol{\\theta}_{t} $表示第$ t $步时的模型参数，$ \\boldsymbol{\\theta}_{t+1} $表示在处理过小批量数据$ \\lbrace\\mathbf{x}^{1}, \\mathbf{x}^2, \\dots, \\mathbf{x}^{B_{s}}\\rbrace $之后第$ t+1 $步的模型参数。\n使用Nesterov动量的RMSProp优化器 $$ \\begin{array}{l} \\textcolor{red}{\\tilde{\\boldsymbol{\\theta}}_{t}} = \\boldsymbol{\\theta}_{t} + \\alpha\\textcolor{blue}{\\boldsymbol{v}_{t}} \\quad \u0026\\text{(look ahead to the future position)} \\\\ \\boldsymbol{g}_{t} = \\frac{1}{B_{s}}\\nabla_{\\boldsymbol{\\theta}}\\sum_{i=1}^{B_{s}}\\mathcal{L}(\\mathbf{x}^i, \\textcolor{red}{\\tilde{\\boldsymbol{\\theta}}_{t}})\\quad \u0026\\text{(compute gradient at the lookahead position)} \\\\ \\textcolor{purple}{\\boldsymbol{r}_{t+1}} = \\rho\\textcolor{purple}{\\boldsymbol{r}_{t}} + (1 - \\rho)\\boldsymbol{g}_{t}\\circ\\boldsymbol{g}_{t} \\quad \u0026\\text{(update the running average of squared gradients)} \\\\ \\textcolor{blue}{\\boldsymbol{v}_{t+1}} = \\alpha\\textcolor{blue}{\\boldsymbol{v}_{t}} - \\frac{\\eta}{\\sqrt{ \\delta + \\textcolor{purple}{\\boldsymbol{r}_{t+1}} }}\\circ\\boldsymbol{g}_{t} \\quad \u0026\\text{(update the velocity with adaptive scaling)} \\\\ \\boldsymbol{\\theta}_{t+1} = \\boldsymbol{\\theta}_{t} + \\textcolor{blue}{\\boldsymbol{v}_{t+1}}\\quad \u0026\\text{(update the parameters)} \\end{array} $$ 上述公式中$ \\eta $表示学习率，$ \\delta $表示一个较小的常数，用于被小数除时的数值稳定，$ \\rho $表示衰减速率，$ \\alpha $表示动量参数，$ \\boldsymbol{r}_{0}=\\mathbf{0} $表示初始累积梯度平方变量，$ \\boldsymbol{v}_{0}=\\mathbf{0} $表示初始速度。$ \\boldsymbol{\\theta}_{t} $表示第$ t $步时的模型参数，$ \\boldsymbol{\\theta}_{t+1} $表示在处理过小批量数据$ \\lbrace\\mathbf{x}^{1}, \\mathbf{x}^2, \\dots, \\mathbf{x}^{B_{s}}\\rbrace $之后第$ t+1 $步的模型参数。\nAdam优化器 $$ \\begin{array}{l} \\boldsymbol{g}_{t} = \\frac{1}{B_{s}}\\nabla_{\\boldsymbol{\\theta}}\\sum_{i=1}^{B_{s}}\\mathcal{L}(\\mathbf{x}^i, \\boldsymbol{\\theta}_{t})\\quad \u0026\\text{(compute gradient at the current position)} \\\\ \\boldsymbol{s}_{t+1} = \\rho_{1}\\boldsymbol{s}_{t} + (1 - \\rho_{1})\\boldsymbol{g}_{t}\\quad\u0026\\text{(update the biased first momentum)} \\\\ \\boldsymbol{r}_{t+1} = \\rho_{2}\\boldsymbol{r}_{t} + (1 - \\rho_{2})\\boldsymbol{g}_{t}\\circ\\boldsymbol{g}_{t}\\quad\u0026\\text{(update the biased second momentum)} \\\\ \\hat{\\boldsymbol{s}}_{t+1}, \\hat{\\boldsymbol{r}}_{t+1} = \\frac{\\boldsymbol{s}_{t+1}}{1 - \\rho_{1}^{t + 1}}, \\frac{\\boldsymbol{r}_{t+1}}{1 - \\rho_{2}^{t + 1}}\\quad\u0026\\text{(bias correction of first momentum and second momentum)} \\\\ \\boldsymbol{\\theta}_{t+1} = \\boldsymbol{\\theta}_{t} - \\eta \\:\\cdot\\frac{\\hat{\\boldsymbol{s}}_{t+1}}{\\delta + \\sqrt{ \\hat{\\boldsymbol{r}}_{t+1} }} \\quad\u0026\\text{(update the parameters)} \\end{array} $$ 上述公式中$ \\eta $表示学习率，$ \\delta $表示一个较小的常数，用于被小数除时的数值稳定，$ \\rho_{1} $和$ \\rho_{2} $表示一阶矩估计和二阶矩估计的衰减速率，$ \\boldsymbol{s}_{0}=\\mathbf{0} $表示初始累积梯度变量，$ \\boldsymbol{r}_{0}=\\mathbf{0} $表示初始累积梯度平方变量。$ \\boldsymbol{\\theta}_{t} $表示第$ t $步时的模型参数，$ \\boldsymbol{\\theta}_{t+1} $表示在处理过小批量数据$ \\lbrace\\mathbf{x}^{1}, \\mathbf{x}^2, \\dots, \\mathbf{x}^{B_{s}}\\rbrace $之后第$ t+1 $步的模型参数。\n使用Nesterov动量的Adam优化器 $$ \\begin{array}{l} \\boldsymbol{g}_{t} = \\frac{1}{B_{s}}\\nabla_{\\boldsymbol{\\theta}}\\sum_{i=1}^{B_{s}}\\mathcal{L}(\\mathbf{x}^i, \\boldsymbol{\\theta}_{t})\\quad \u0026\\text{(compute gradient at the current position)} \\\\ \\boldsymbol{s}_{t+1} = \\rho_{1}\\boldsymbol{s}_{t} + (1 - \\rho_{1})\\boldsymbol{g}_{t}\\quad\u0026\\text{(update the biased first momentum)} \\\\ \\boldsymbol{r}_{t+1} = \\rho_{2}\\boldsymbol{r}_{t} + (1 - \\rho_{2})\\boldsymbol{g}_{t}\\circ\\boldsymbol{g}_{t}\\quad\u0026\\text{(update the biased second momentum)} \\\\ \\hat{\\boldsymbol{s}}_{t+1}, \\hat{\\boldsymbol{r}}_{t+1} = \\frac{\\boldsymbol{s}_{t+1}}{1 - \\rho_{1}^{t + 1}}, \\frac{\\boldsymbol{r}_{t+1}}{1 - \\rho_{2}^{t + 1}}\\quad\u0026\\text{(bias correction of first momentum and second momentum)} \\\\ \\textcolor{red}{\\tilde{\\boldsymbol{s}}_{t+1}}=\\rho_{1}\\hat{\\boldsymbol{s}}_{t+1}+\\frac{1-\\rho_{1}}{1-\\rho_{1}^{t+1}}\\boldsymbol{g}_{t}\\quad\u0026\\text{(lookahead adjustment of first momentum)} \\\\ \\boldsymbol{\\theta}_{t+1} = \\boldsymbol{\\theta}_{t} - \\eta \\:\\cdot\\frac{\\textcolor{red}{\\tilde{\\boldsymbol{s}}_{t+1}}}{\\delta + \\sqrt{ \\hat{\\boldsymbol{r}}_{t+1} }} \\quad\u0026\\text{(update the parameters)} \\end{array} $$ 同样上述公式中$ \\eta $表示学习率，$ \\delta $表示一个较小的常数，用于被小数除时的数值稳定，$ \\rho_{1} $和$ \\rho_{2} $表示一阶矩估计和二阶矩估计的衰减速率，$ \\boldsymbol{s}_{0}=\\mathbf{0} $表示初始累积梯度变量，$ \\boldsymbol{r}_{0}=\\mathbf{0} $表示初始累积梯度平方变量。$ \\boldsymbol{\\theta}_{t} $表示第$ t $步时的模型参数，$ \\boldsymbol{\\theta}_{t+1} $表示在处理过小批量数据$ \\lbrace\\mathbf{x}^{1}, \\mathbf{x}^2, \\dots, \\mathbf{x}^{B_{s}}\\rbrace $之后第$ t+1 $步的模型参数。使用Nesterov动量的Adam优化器与Adam的区别：提前预知一阶矩动量$ \\tilde{\\boldsymbol{s}}_{t+1} $。\nAdamax优化器 $$ \\begin{array}{l} \\boldsymbol{g}_{t} = \\frac{1}{B_{s}}\\nabla_{\\boldsymbol{\\theta}}\\sum_{i=1}^{B_{s}}\\mathcal{L}(\\mathbf{x}^i, \\boldsymbol{\\theta}_{t})\\quad \u0026\\text{(compute gradient at the current position)} \\\\ \\boldsymbol{s}_{t+1} = \\rho_{1}\\boldsymbol{s}_{t} + (1 - \\rho_{1})\\boldsymbol{g}_{t}\\quad\u0026\\text{(update the biased first momentum)} \\\\ \\boldsymbol{r}_{t+1} = \\max(\\rho_{2}\\boldsymbol{r}_{t}, \\lvert \\boldsymbol{g}_{t} \\rvert )\\quad\u0026\\text{(update exponentially weighted infinity norm)} \\\\ \\hat{\\boldsymbol{s}}_{t+1} = \\frac{\\boldsymbol{s}_{t+1}}{1 - \\rho_{1}^{t + 1}}\\quad\u0026\\text{(bias correction of the first momentum)} \\\\ \\boldsymbol{\\theta}_{t+1} = \\boldsymbol{\\theta}_{t} - \\eta \\:\\cdot\\frac{\\hat{\\boldsymbol{s}}_{t+1}}{\\delta + \\boldsymbol{r}_{t+1}} \\quad\u0026\\text{(update the parameters)} \\end{array} $$ 同样上述公式中$ \\eta $表示学习率，$ \\delta $表示一个较小的常数，用于被小数除时的数值稳定，$ \\rho_{1} $和$ \\rho_{2} $表示一阶矩估计和无穷范数的衰减速率，$ \\boldsymbol{s}_{0}=\\mathbf{0} $表示初始累积梯度变量，$ \\boldsymbol{r}_{0}=\\mathbf{0} $表示初始累积梯度无穷范数变量。$ \\boldsymbol{\\theta}_{t} $表示第$ t $步时的模型参数，$ \\boldsymbol{\\theta}_{t+1} $表示在处理过小批量数据$ \\lbrace\\mathbf{x}^{1}, \\mathbf{x}^2, \\dots, \\mathbf{x}^{B_{s}}\\rbrace $之后第$ t+1 $步的模型参数。Adamax优化器和Adam优化器的区别：使用无穷范数来代替二阶矩估计。\nAdamW优化器 $$ \\begin{array}{l} \\boldsymbol{g}_{t} = \\frac{1}{B_{s}}\\nabla_{\\boldsymbol{\\theta}}\\sum_{i=1}^{B_{s}}\\mathcal{L}(\\mathbf{x}^i, \\boldsymbol{\\theta}_{t})\\quad \u0026\\text{(compute gradient at the current position)} \\\\ \\boldsymbol{s}_{t+1} = \\rho_{1}\\boldsymbol{s}_{t} + (1 - \\rho_{1})\\boldsymbol{g}_{t}\\quad\u0026\\text{(update the biased first momentum)} \\\\ \\boldsymbol{r}_{t+1} = \\rho_{2}\\boldsymbol{r}_{t} + (1 - \\rho_{2})\\boldsymbol{g}_{t}\\circ\\boldsymbol{g}_{t}\\quad\u0026\\text{(update the biased second momentum)} \\\\ \\hat{\\boldsymbol{s}}_{t+1}, \\hat{\\boldsymbol{r}}_{t+1} = \\frac{\\boldsymbol{s}_{t+1}}{1 - \\rho_{1}^{t + 1}}, \\frac{\\boldsymbol{r}_{t+1}}{1 - \\rho_{2}^{t + 1}}\\quad\u0026\\text{(bias correction of first momentum and second momentum)} \\\\ \\boldsymbol{\\theta}_{t+1} = \\boldsymbol{\\theta}_{t} - \\eta \\:\\cdot\\frac{\\hat{\\boldsymbol{s}}_{t+1}}{\\delta + \\sqrt{ \\hat{\\boldsymbol{r}}_{t+1} }}-\\eta\\:\\cdot \\lambda\\boldsymbol{\\theta}_{t} \\quad\u0026\\text{(separates weight decay from adaptive gradient scaling, ensuring true L2 regularization)} \\end{array} $$ 同样上述公式中$ \\eta $表示学习率，$ \\delta $表示一个较小的常数，用于被小数除时的数值稳定，$ \\rho_{1} $和$ \\rho_{2} $表示一阶矩估计和二阶矩估计的衰减速率，$ \\lambda $表示$ \\text{L2} $正则项系数。$ \\boldsymbol{s}_{0}=\\mathbf{0} $表示初始累积梯度变量，$ \\boldsymbol{r}_{0}=\\mathbf{0} $表示初始累积梯度平方变量。$ \\boldsymbol{\\theta}_{t} $表示第$ t $步时的模型参数，$ \\boldsymbol{\\theta}_{t+1} $表示在处理过小批量数据$ \\lbrace\\mathbf{x}^{1}, \\mathbf{x}^2, \\dots, \\mathbf{x}^{B_{s}}\\rbrace $之后第$ t+1 $步的模型参数。AdamW优化器和Adam优化器的主要区别：把$ \\text{L2} $正则化从梯度更新中分离出来，防止正则化不纯粹。\nRAdam优化器 $$ \\begin{array}{l} \\boldsymbol{g}_{t} = \\frac{1}{B_{s}}\\nabla_{\\boldsymbol{\\theta}}\\sum_{i=1}^{B_{s}}\\mathcal{L}(\\mathbf{x}^i, \\boldsymbol{\\theta}_{t})\\quad \u0026\\text{(compute gradient at the current position)} \\\\ \\boldsymbol{s}_{t+1} = \\rho_{1}\\boldsymbol{s}_{t} + (1 - \\rho_{1})\\boldsymbol{g}_{t}\\quad\u0026\\text{(update the biased first momentum)} \\\\ \\boldsymbol{r}_{t+1} = \\rho_{2}\\boldsymbol{r}_{t} + (1 - \\rho_{2})\\boldsymbol{g}_{t}\\circ\\boldsymbol{g}_{t}\\quad\u0026\\text{(update the biased second momentum)} \\\\ \\hat{\\boldsymbol{s}}_{t+1}, \\hat{\\boldsymbol{r}}_{t+1} = \\frac{\\boldsymbol{s}_{t+1}}{1 - \\rho_{1}^{t + 1}}, \\frac{\\boldsymbol{r}_{t+1}}{1 - \\rho_{2}^{t + 1}}\\quad\u0026\\text{(bias correction of first momentum and the second momentum)} \\\\ \\gamma_{t + 1} = \\gamma_{\\infty} - \\frac{2(t+1)\\rho_{2}^{t+1}}{1 - \\rho_{2}^{t+1}}\\quad \u0026\\text{(compute the length of the approximated SMA)} \\\\ \\begin{cases} \\psi_{t+1} = \\sqrt{ \\frac{(\\gamma_{t+1} - 4)(\\gamma_{t+1} - 2)\\gamma_{\\infty}}{(\\gamma_{\\infty} - 4)(\\gamma_{\\infty} - 2)\\gamma_{t+1}} }\\quad\u0026\\text{(compute the variance rectification term)} \\\\ \\boldsymbol{\\theta}_{t+1} = \\boldsymbol{\\theta}_{t} - \\eta\\:\\cdot \\psi_{t+1}\\frac{\\hat{\\boldsymbol{s}}_{t+1}}{\\delta + \\sqrt{ \\hat{\\boldsymbol{r}}_{t+1}} } \\quad\u0026\\text{(update the parameters with adaptive momentum)} \\end{cases}\\quad\u0026(\\text{if}\\:\\gamma_{t+1} \u003e 4) \\\\ \\begin{cases} \\boldsymbol{\\theta}_{t+1} = \\boldsymbol{\\theta}_{t} - \\eta\\:\\cdot \\hat{\\boldsymbol{s}}_{t+1}\\quad\\quad\\quad\\quad\\quad\u0026\\text{(update the parameters with un-adaptive momentum)} \\end{cases} \\quad\u0026\\text{(else)} \\end{array} $$ 同样上述公式中$ \\eta $表示学习率，$ \\delta $表示一个较小的常数，用于被小数除时的数值稳定，$ \\rho_{1} $和$ \\rho_{2} $表示一阶矩估计和二阶矩估计的衰减速率。$ \\boldsymbol{s}_{0}=\\mathbf{0} $表示初始累积梯度变量，$ \\boldsymbol{r}_{0}=\\mathbf{0} $表示初始累积梯度平方变量，$ \\gamma_{\\infty}=\\frac{2}{1-\\rho_{2}} - 1 $表示计算的近似SMA的最大长度。$ \\boldsymbol{\\theta}_{t} $表示第$ t $步时的模型参数，$ \\boldsymbol{\\theta}_{t+1} $表示在处理过小批量数据$ \\lbrace\\mathbf{x}^{1}, \\mathbf{x}^2, \\dots, \\mathbf{x}^{B_{s}}\\rbrace $之后第$ t+1 $步的模型参数。其与Adam优化器的区别是)，RAdam提出了一个方差校正因子$ \\psi $(rectification term)，自动调整有效学习率，让优化在初期更加稳定。\n调度器 上面一节中优化器中的超参数学习率$ \\eta $我们设定成了固定值，但是在真正实践中我们可以设定学习率$ \\eta $随着$ \\text{epoch} $变化($ \\text{epoch-based} $)或者随着$ \\text{step} $变化($ \\text{step-based} $)，这些变化我们可以通过调度器来进行实现，下面我们介绍一些常见的调度器。\n余弦调度器 由图可知，`$ \\text{step-based} $`的余弦调度器在每个`$ \\text{step} $`都会发生变化，而`$ \\text{epoch-based} $`的余弦调度器在每个`$ \\text{epoch} $`发生变化，而在相邻之间的`$ \\text{step} $`区间不会发生变化，通常`$ \\text{1 epoch}=\\text{1 step}\\times \\text{num batches} $`。 $$ \\eta_{t} = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})\\left( 1 + \\cos\\left( \\frac{t}{T_{\\text{max}}} \\pi\\right) \\right) $$ 其中$ t $表示调度的粒度，既可以是$ \\text{step} $级别又可以是$ \\text{epoch} $级别。\n线性调度器 同余弦调度器的绘制说明，线性调度器的公式为 $$ \\eta_{t} = \\eta_{\\text{max}} - \\frac{t}{T_{\\text{max}}}(\\eta_{\\text{max}} - \\eta_{\\text{min}}) $$ 其中$ t $表示调度的粒度，既可以是$ \\text{step} $级别又可以是$ \\text{epoch} $级别。\n多项式调度器 同余弦调度器绘制说明，多项式调度器的公式为 $$ \\eta_{t} = \\eta_{\\text{min}} + (\\eta_{\\text{max}} - \\eta_{\\text{min}})\\left( 1 - \\frac{t}{T_{\\text{max}}} \\right)^p $$ 其中$ t $表示调度的粒度，既可以是$ \\text{step} $级别又可以是$ \\text{epoch} $级别。$ p $表示多项式幂指数。\n预热调度器 预热调度器一般是使用`$ \\text{step} $`粒度级别的线性增长调度。也就是上图中的5个`$ \\text{epoch} $`之前的过程都属于`$ \\text{warmup} $`过程。 梯度累积优化 当使用单卡GPU进行模型训练时当我们的批次大小设定过大时会出现显存不足的情况，所以单卡GPU往往设定的批次大小偏小以避免显存爆炸，但是小批量的训练方式往往会导致多个批次计算的梯度不稳定，最终导致损失的收敛不稳定。为了解决上述困境，一个有效的解决方法就是使用梯度累积优化。\n假设小批量设定为$ b_{s} $，累积的大批量设定为$ B_{s} $，习惯上$ B_{s}=n\\:\\cdot b_{s} $，$ n $表示梯度累积的$ \\text{step} $数。我们可以证明$ n $个$ b_{s} $批次梯度累积优化等价于一次$ B_{s} $批次梯度优化。\n$$ \\begin{align} \\boldsymbol{g}_{t} \u0026= \\frac{1}{n}\\sum_{i=1}^n\\boldsymbol{g}_{t}^i\\\\ \u0026= \\frac{1}{n}\\sum_{i=1}^n \\frac{1}{b_{s}}\\nabla_{\\boldsymbol{\\theta}}\\sum_{j=1}^{b_{s}}\\mathcal{L}(\\mathbf{x}_{i}^j, \\boldsymbol{\\theta}_{t}) \\\\ \u0026= \\frac{1}{nb_{s}}\\sum_{i=1}^n\\sum_{j=1}^{b_{s}}\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\mathbf{x}_{i}^j, \\boldsymbol{\\theta}_{t}) \\\\ \u0026= \\frac{1}{B_{s}}\\nabla_{\\boldsymbol{\\theta}}\\sum_{i=1}^{B_{s}}\\mathcal{L}(\\mathbf{x}^i, \\boldsymbol{\\theta}_{t}) \\end{align} $$ 标签平滑 标签平滑是分类任务重的一种正则化技术，其思想是将原来的真实标签(one hot编码)转换为“软化”标签。在正确类别上赋予$ 1 - \\epsilon $的概率，再在其他类别上均匀分配$ \\epsilon $的概率，其中$ K $为多分类的类别总数。\n其中标签分类分布如下\n$$ p(y\\mid\\mathbf{z})=\\mathrm{softmax}_{y}(\\mathbf{z})=\\frac{\\exp[z_{y}]}{\\sum_{y'=1}^{K}\\exp[z_{y'}]} $$ 取负$ \\log $之后得到损失函数\n$$ -\\log p(y\\mid\\mathbf{z})=-\\log[\\mathrm{softmax}_{y}(\\mathbf{z})]=-\\log\\left[\\frac{\\exp[z_{y}]}{\\sum_{y'=1}^{K}\\exp[z_{y'}]}\\right] $$ $$ -\\nabla_{\\mathbf{z}}\\log[\\mathrm{softmax}_{y}(\\mathbf{z})] = \\mathrm{softmax}(\\mathbf{z}) - \\mathbf{e}_{y} $$ 上述损失函数求得梯度之后得到的结果表明了我们最终优化的结果应该使得$ \\mathrm{softmax}(\\mathbf{z}) $和真实标签分布$ \\mathbf{e}_{y} $尽可能接近。\n如果是平滑之后的标签模型输出分类分布和真实标签分类分布如下\n$$ p(y=k\\mid\\mathbf{z})=\\mathrm{softmax}_{k}(\\mathbf{z})=\\frac{\\exp[z_{k}]}{\\sum_{k'=1}^{K}\\exp[z_{k'}]} $$ $$ p(y=k) = q_{k} $$ 两个分布的交叉熵如下，最小化交叉熵等价于最小化两个分布的$ \\mathrm{KL} $散度。\n$$ H(p(y=k), p(y=k\\mid\\mathbf{z})) = -\\sum_{k=1}^K q_{k}\\log\\left[\\frac{\\exp[z_{k}]}{\\sum_{k'=1}^{K}\\exp[z_{k'}]}\\right] $$ $$ \\nabla_{\\mathbf{z}}H(p(y=k), p(y=k\\mid\\mathbf{z})) = \\mathrm{softmax}(\\mathbf{z}) - \\mathbf{y} $$ 平滑标签之后的梯度使得$ \\mathrm{softmax}(\\mathbf{z}) $和平滑标签分布$ \\mathbf{y} $尽可能接近。\n指数移动平均 在优化器一节中我们已经介绍了移动平均的思想使得学习率的收缩与梯度较近的历史信息相关。而模型的指数移动平均主要是进行权重的指数移动平均，使得最终得到的权重参数更加平稳，从而提升泛化能力。\n$$ \\mathbf{ema}_{t+1} = \\rho \\cdot\\mathbf{ema}_{t} + (1 - \\rho)\\cdot \\mathbf{w}_{t} $$ $ \\mathbf{w}_{t} $表示第$ t $步时的模型权重，$ \\mathbf{ema}_{0}=\\mathbf{0} $表示初始指数移动平均权重。\n还有一些小$ \\mathrm{trick} $包括梯度裁剪（$ \\tilde{\\boldsymbol{g}}_{t}=\\frac{\\mathrm{n_{max}}}{\\max(\\lvert \\lvert \\boldsymbol{g}_{t} \\rvert \\rvert_{p}^p, \\mathrm{n_{max}})}\\boldsymbol{g}_{t} $）、早停策略以及混合精度计算（AMP）也有时也都可以优化模型的训练过程。\n","permalink":"https://fordelkon.github.io/posts/train_trick/","summary":"\u003cp\u003e进行深度学习实践的过程中我们所需要做的不仅仅只是搭建好模型，如何通过一系列的技巧来训练出一个较为优秀的模型也是至关重要的。没有训练好的模型作为证明就算模型架构再好也无法说明提出的模型的优越性，这一篇博客主要介绍我们可以从哪些方面来优化模型的训练过程。\u003c/p\u003e","title":"深度学习训练技巧"},{"content":"发现了一个新的GitHub的项目，发现要使用conda库来创建新的虚拟环境装一大堆python库才能运行起来这个项目\u0026hellip;心中的激情之火已经浇灭了一大半😒；这时候又突然发现该项目支持Docker环境部署，可以直接拉取Docker镜像来运行该项目，好了，心中再次燃起激情之火😊。总之，Docker可以帮助我么省下配环境的时间，而且你拉取别人已经发布的镜像一般是别人已经在宿主机上已经跑通的镜像，那么不管你的平台是什么你也一定能跑通。下面让我们进一步看看Docker吧\u0026hellip;\nDocker基本概念 容器（Container）是一个隔离的进程，在主机机器上运行，与该主机上运行的所有其他进程隔离。 镜像（Image）镜像是一个只读模板，包含创建 Docker 容器的指令。 实际上你可以这样来类比镜像和容器，前者是一个装了操作系统的硬盘，但他是静态的，不能直接来运行，后者是一个没有硬盘的电脑，必须安装硬盘才能运行对应的操作系统。当然这样的类比有点瑕疵，但是容器对于镜像的依赖性可以很好地体现出来。 我们从镜像可以创建出无数的容器，也就是说我们可以随便对已经创建的容器进行实验，不怕担心其中的操作系统崩溃，因为我们只要删除这个崩溃的系统再重开就好了（有点像重生流了）。\nDocker操作流程 拉取镜像（docker pull） 获取容器运行所需要的基础镜像。\ndocker pull [-aq] name[:tag|@digest] 选项参数： -a ：下载仓库中的所有标签镜像 -q ：抑制详细输出 # 不指定标签时默认使用:latest标签 docker pull debian # (== docker pull debian:latest) # Using default tag: latest # latest: Pulling from library/debian # e756f3fdd6a3: Pull complete # Digest: sha256:3f1d6c17773a45c97bd8f158d665c9709d7b29ed7917ac934086ad96f92e4510 # Status: Downloaded newer image for debian:latest # docker.io/library/debian:latest # 通过摘要拉取可以确保获取特定版本的镜像，而不是最新版本 docker pull ubuntu@sha256:2e863c44b718727c860746568e1d54afd13b2fa71b160f5cd9058fc436217b30 创建并启动新容器（docker run） 根据镜像创建并启动容器。docker run本身带有docker pull的功能，当它在本地镜像库中找不到所拉取的镜像名称时，就会先去docker pull该镜像了，之后再根据镜像创建并启动容器。\ndocker run [options] name[:tag|@digest] [command] [arg...] 选项参数： -d ：后台运行容器（“detached” 模式）。容器在后台运行，终端不会被阻塞。 -it ：分配交互式终端，可以进入容器内部进行交互操作。 --name ：为容器指定一个自定义的名字。 --rm ：当容器退出时自动删除容器。 -p ：端口映射，将主机的端口映射到容器内部的端口（容器内部端口暴露给主机端口）。由于容器默认是隔离的，外部是无法访问容器内的服务的，因此需要创建映射规则，允许外部通过主机端口访问容器内的服务。 -v ：挂载卷，将主机的目录或文件挂载到容器的目录。 -e ：设置环境变量。 docker run --name test -d nginx:alpine docker run -p 8080:80 docker/welcome-to-doc docker run -it ubuntu /bin/bash # 进入bash终端 docker run --rm alpine echo \u0026#34;test\u0026#34; # test docker run -it --rm -v /home/delkon/compiler:/root/compiler maxxing/compiler-dev bash # -v /home/delkon/compiler:/root/compiler选项, 这个选项代表: 我希望把宿 # 主机的 /home/delkon/compiler 目录, 挂载 (mount) 到容器 # 的 /root/compiler 目录. 这样, 在进入容器之后, 我们就可以通过访 # 问 /root/compiler 来访问宿主机的 /home/max/compiler 目录了（修 # 改 /root/compiler 的内容也会改变本地 /home/max/compiler 的内容）。 docker run -e foo=bar postgres env # 添加foo=bar进入环境变量 根据容器ID（或名称）启动旧容器（docker exec） 有些时候我们想要复用某些容器而不是在创建启动之后就将其删除，这时候可以根据容器ID（或名称）来再次启动该容器。启动旧容器时我们首先应该保证旧容器处于运行状态。使用docker ps查看处于运行状态的容器列表，如果要运行docker exec的容器不处于运行状态，先运行docker start container来是该容器处于运行状态。上面的container可以索引到docker run运行后得到的容器。\u0026ndash;name参数对应的名称或原始索引。\ndocker exec [options] container command [arg...] 选项参数： -d ：后台运行容器（“detached” 模式）。容器在后台运行，终端不会被阻塞。 -it ：分配交互式终端，可以进入容器内部进行交互操作。 -u ：指定特定的用户身份来运行容器。 -e ：设置环境变量。 -w ： 指定容器内的工作目录来运行容器。 **下面的container可以索引到`docker run`运行后得到的容器。--name参数对应的名称或原始索引。** docker exec -it container bash # 进入交互式bash终端。 docker exec -d container touch /tmp/execWorks # 在后台创建一个文件，不会等待命令完成。 docker exec -e VAR_A=1 -e VAR_B=2 容器名称 env # 执行命令时设置环境变量。 docker exec -it -w /root container pwd # 在指定的工作目录/root中执行命令 自定义镜像 上面的流程主要是针对我们从本地拉取别人的写好上传到Docker Hub上的镜像，然后进行一系列的操作。不过别人的镜像也不总是能满足我们的需求，这时候我们可以自定义镜像来完成我们自己的独特需求。自定义镜像需要用到Dockerfile文件啦，可以这样来进行简单类比：写镜像就需要Dockerfile，Dockerfile就是镜像的“源代码”，Docker就是\u0026quot;编译器\u0026quot;。一般来说我们使用docker build命令行来使得该编译过程自动化。首先我们先来学习Dockerfile的编写规则。\nDockerfile结构 指令 描述 FROM \u0026lt;image\u0026gt; 定义构建镜像的基础镜像。 RUN \u0026lt;command\u0026gt; 在当前镜像的基础上执行命令，并提交结果为一个新层。RUN也有 shell 形式用于执行命令。 WORKDIR \u0026lt;directory\u0026gt; 为后续的RUN、CMD、ENTRYPOINT、COPY 和 ADD 指令设置工作目录。 COPY \u0026lt;src\u0026gt; \u0026lt;dest\u0026gt; 将新的文件或目录从 \u0026lt;src\u0026gt; 复制到容器文件系统中的 \u0026lt;dest\u0026gt; 路径下。 CMD \u0026lt;command\u0026gt; 定义启动基于此镜像的容器时默认运行的程序。每个 Dockerfile 只能有一个 CMD，如果有多个 CMD 指令，只有最后一个会生效。 EXPOSE \u0026lt;port\u0026gt; 声明容器监听的端口 ARG \u0026lt;expression\u0026gt; 定义变量名称和变量值，可以在docker build中加以调控。 一个简单的welcome-to-docker网页的Dockerfile的编写。\n# 基础node镜像 FROM node:18-alpine # 后续命令运行的工作目录 WORKDIR /app # 复制本地的package.json和package-lock.json到容器的/app目录下 COPY package*.json ./ # 同上 COPY ./src ./src COPY ./public ./public # “安装 Node 包，安装 serve，构建应用，并在最后移除依赖。” RUN npm install \\ \u0026amp;\u0026amp; npm install -g serve \u0026amp;\u0026amp; npm run build \u0026amp;\u0026amp; rm -rf node_modules EXPOSE 3000 # 使用serve命令启动该应用 CMD [ \u0026#34;serve\u0026#34;, \u0026#34;-s\u0026#34;, \u0026#34;build\u0026#34; ] “编译”Dockerfile文件：docker build 有了Dockerfile文件之后接下来就可以运行docker build来构建自定义镜像了。\ndocker build [options] path | url | - 选项参数： -t ：为构建的镜像命名并打标签（如 myimage:tag）。不指定标签时默认是 latest。 -f ：指定使用的 Dockerfile 文件，默认查找 path 下的 Dockerfile。 --rm ：构建完成后移除中间容器，默认是 true。 --build-arg ：设置构建时的变量 **path ：指向包含 Dockerfile 的目录，或者可以使用 url 指向一个远程的 Dockerfile。** docker build -t test:latest . # path docker build -f path/to/Dockerfile . # path docker build --build-arg NODE_VERSION=current . # path docker build https://github.com/docker-library/hello-world.git # url ","permalink":"https://fordelkon.github.io/posts/docker_intro/","summary":"\u003cp\u003e发现了一个新的GitHub的项目，发现要使用conda库来创建新的虚拟环境装一大堆python库才能运行起来这个项目\u0026hellip;心中的激情之火已经浇灭了一大半😒；这时候又突然发现该项目支持Docker环境部署，可以直接拉取Docker镜像来运行该项目，好了，心中再次燃起激情之火😊。总之，Docker可以帮助我么省下配环境的时间，而且你拉取别人已经发布的镜像一般是别人已经在宿主机上已经跑通的镜像，那么不管你的平台是什么你也一定能跑通。下面让我们进一步看看Docker吧\u0026hellip;\u003c/p\u003e","title":"使用Docker的艺术"},{"content":"熟练使用命令行是一种常常被忽视，或被认为难以掌握的技能，但实际上，它会提高你作为工程师的灵活性以及生产力。本文旨在了解命令行中的重定向功能和文件管理功能。\n重定向（redirect） 输入输出重定向 \u0026gt;覆盖，\u0026gt;\u0026gt;累加\n标准输入　(stdin) ：代码为0，使用\u0026lt;或\u0026lt;\u0026lt;； 标准输出　(stdout)：代码为1，使用\u0026gt;或\u0026gt;\u0026gt;； 标准错误输出(stderr)：代码为2，使用2\u0026gt;或2\u0026gt;\u0026gt;； 2\u0026gt;\u0026amp;1来将2\u0026gt;转到1\u0026gt;去，而1\u0026gt;\u0026amp;2来将1\u0026gt;转到2\u0026gt;去。（感觉像是首要定性，先分配好stdout和stderr的走向） 2\u0026gt;\u0026amp;1:\ntype list \u0026gt; list # bash: type: list: not found cat list type list \u0026gt; list 2\u0026gt;\u0026amp;1 cat list # bash: type: list: not found type cd \u0026gt; list 2\u0026gt;\u0026amp;1 # cd is a shell builtin 1\u0026gt;\u0026amp;2:\necho \u0026#34;error message\u0026#34; 1\u0026gt;\u0026amp;2 # error message echo \u0026#34;error message\u0026#34; 2\u0026gt; /dev/null 1\u0026gt;\u0026amp;2 管道重定向 |：仅能处理经由前面一个指令传来的正确信息，也就是 stdout 的信息，对于 stderr并没有直接处理的能力；必须要能够接受来自前一个指令的数据成为 standard input 继续处理才行。\n基础正则表达式(grep中的\u0026rsquo;pattern\u0026rsquo;格式) RE 字符 意义与范例 ^word 意义：待搜索的字符串(word)在行首！ 范例：搜索行首为 # 开始的那一行，并列出行号\ngrep -n '^#' regular_express.txt word$ 意义：待搜索的字符串(word)在行尾！ 范例：将行尾为 ! 的那一行打印出来，并列出行号\ngrep -n '!$' regular_express.txt . 意义：代表一定有一个任意字符的字符！ 范例：搜索的字符串可以是 (eve) (eae) (eee) (e e)， 但不能仅有 (ee) ！亦即 e 与 e 中间『一定』仅有一个字符，而空白字符也是字符！\ngrep -n 'e.e' regular_express.txt \\ 意义：跳脱字符，将特殊符号的特殊意义去除！ 范例：搜索含有单引号 \u0026rsquo; 的那一行！\ngrep -n \\' regular_express.txt * 意义：重复零个到无穷多个的前一个 RE 字符 范例：找出含有 (es) (ess) (esss) 等等的字符串，注意，因为 * 可以是 0 个，所以 es 也是符合带搜索字符串。另外，因为 * 为重复前一个 RE 字符的符号， 因此，在 * 之前必须要紧接着一个 RE 字符喔！例如任意字符则为 .* ！\ngrep -n 'ess*' regular_express.txt [list] 意义：字符集合的 RE 字符，里面列出想要截取的字符！ 范例：搜索含有 (gl) 或 (gd) 的那一行，需要特别留意的是，在[]当中谨代表一个待搜索的字符， 例如a[afl]y代表搜索的字符串可以是 aay, afy, aly 即 [afl]代表 a 或 f 或 l 的意思！\ngrep -n 'g[ld]' regular_express.txt [n1-n2] 意义：字符集合的 RE 字符，里面列出想要截取的字符范围！ 范例：搜索含有任意数字的那一行！需特别留意，在字符集合 [] 中的减号 - 是有特殊意义的，他代表两个字符之间的所有连续字符！但这个连续与否与 ASCII 编码有关，因此，你的编码需要设置正确(在 bash 当中，需要确定 LANG 与 LANGUAGE 的变量是否正确！) 例如所有大写字符则为 [A-Z]\ngrep -n '[A-Z]' regular_express.txt [^list] 意义：字符集合的 RE 字符，里面列出不要的字符串或范围！ 范例：搜索的字符串可以是 (oog) (ood) 但不能是 (oot) ，那个 ^ 在 [] 内时，代表的意义是『反向选择』的意思。 例如，我不要大写字符，则为[^A-Z]。但是，需要特别注意的是，如果以 grep -n [^A-Z] regular_express.txt 来搜索，却发现该文件内的所有行都被列出，为什么？因为这个 [^A-Z] 是非大写字符的意思， 因为每一行均有非大写字符，例如第一行的 \u0026ldquo;Open Source\u0026rdquo; 就有 p,e,n,o\u0026hellip;. 等等的小写字\ngrep -n 'oo[^t]' regular_express.txt \\{n,m\\} 意义：连续 n 到 m 个的前一个 RE 字符 意义：若为 \\{n\\} 则是连续 n 个的前一个 RE 字符， 意义：若是 \\{n,\\} 则是连续 n 个以上的前一个 RE 字符！ 范例：在 g 与 g 之间有 2 个到 3 个的 o 存在的字符串，亦即 (goog)(gooog)\ngrep -n 'go\\{2,3\\}g' regular_express.txt 常用的管道命令grep:\ngrep [-acinv] [--color=auto] \u0026#39;pattern\u0026#39; filename 选项与参数： -i ：忽略大小写的不同，所以大小写视为相同 -o ：只输出匹配的部分而不是整行 -v ：反向选择，亦即显示出没有匹配\u0026#39;pattern\u0026#39;的字符串内容的那些行！ -A ：显示匹配行+匹配行行后的几行(after) -B ：显示匹配行+匹配行行前的几行(before) -C ：显示匹配行+匹配行行前后的几行(context) --color=auto ：可以将找到的关键字部分加上颜色的显示喔！ # 将有出现 root 的那一行就取出来； last | grep \u0026#39;root\u0026#39; # 只要没有 root 的就取出！ last | grep -v \u0026#39;root\u0026#39; # # wtmp begins Tue Mar 11 22:41:15 2025 # 在 last 的输出消息中，只要有 root 就取出，并且仅取第一栏 last | grep -v \u0026#39;root\u0026#39; | cut -d \u0026#39; \u0026#39; -f 1 # # wtmp # 在取出 root 之后，利用上个指令 cut 的处理，就能够仅取得第一栏啰！ # 神奇的是，如果加上 --color=auto 的选项，找到的关键字部分会用特殊颜色显示喔！ 常用的管道命令awk：\nawk [-F] [delimiter] \u0026#39;pattern {action}\u0026#39; filename 选项与参数： -F ：制定分隔符，默认为空格或制表符 # 列出当前GPU下所有的python进程号 nvidia-smi | grep python | awk \u0026#39;{print $5}\u0026#39; # 18108 # 18737 # 19383 # 19565 # 19725 # 19799 # 19859 # 19977 # 20550 # 20733 awk \u0026#39;FS=\u0026#34;:\u0026#34; { print $1, $3 }\u0026#39; /etc/passwd # root:x:0:0:root:/root:/bin/bash # daemon 1 # bin 2 # sys 3 # sync 4 # games 5 # man 6 # ...... awk动作中的内置变量，动作中的关键字是print：\n$0：当前行的所有内容。 $1, $2, $3,\u0026hellip;：每行的各个字段，从第一个字段开始。 NR：当前行号。 NF：当前行的字段数。 FS：字段分隔符，默认为空格或制表符。 OFS：输出字段分隔符，默认为空格。 RS：行分隔符，默认为换行符。 ORS：输出行分隔符，默认为换行符。 常用管道命令sed：\nsed [-nefr] [action] 选项与参数： -n ：使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN 的数据一般都会被列出到屏幕上。 但如果加上 -n 参数后，则只有经过 sed 特殊处理的那一行(或者动作)才会被列出来。 -e ：直接在指令列模式上进行 sed 的动作编辑； -f ：直接将 sed 的动作写在一个文件内， -f filename 则可以运行 filename 内的 sed 动作； -r ：sed 的动作支持的是延伸型正规表示法的语法。(缺省是基础正规表示法语法) -i ：直接修改读取的文件内容，而不是由屏幕输出。 动作说明： [n1[,n2]]function n1, n2 ：不见得会存在，一般代表『选择进行动作的行数』，举例来说，如果我的动作 是需要在 10 到 20 行之间进行的，则『 10,20[动作行为] 』 function 有底下这些咚咚： a ：添加， a 的后面可以接字符串，而这些字符串会在新的一行出现(目前的下一行)～ c ：取代， c 的后面可以接字符串，这些字符串可以取代 n1,n2 之间的行！ d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚； i ：插入， i 的后面可以接字符串，而这些字符串会在新的一行出现(目前的上一行)； p ：打印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运作～ s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！ 例如 1,20s/old/new/g 就是啦！（类似vim命令行替换操作） nl /etc/passwd | sed \u0026#39;2,5d\u0026#39; # 将 /etc/passwd 的内容列出并且打印行号，同时，请将第 2~5 行删除！ nl /etc/passwd | sed \u0026#39;2a drink tea\u0026#39; # 在第二行后(亦即是加在第三行)加上『drink tea』字样！ nl /etc/passwd | sed \u0026#39;2i drink tea\u0026#39; # 在第二行前(亦即是加在第三行)加上『drink tea』字样！ nl /etc/passwd | sed \u0026#39;2,5c No 2-5 number\u0026#39; # 将第2-5行的内容取代成为『No 2-5 number』 nl /etc/passwd | sed -n \u0026#39;5,7p\u0026#39; # 列出 /etc/passwd 文件内的第 5-7 行 cat /etc/man_db.conf | grep \u0026#39;MAN\u0026#39;| sed \u0026#39;s/#.*$//g\u0026#39; 删除掉注解之后的数据！ xargs + |：xargs可以读入stdin的数据，并且以空格或换行字符作为分辨，将stdin的数据分隔成为arguments。\nxargs搭配｜更加美味😋：\ncommand1 | xargs [-ndI{}] command2 选项与参数： -n ：后面接次数，每次command2指令运行时，要使用几个参数的意思。 -d ：指定定界符，默认是空格或换行符。delimiter -I{}：指定替换字符串。每次读取一行数据并将{}替换为该行数据。 cat hosts # delkon # study # flypig # ikun # daniel cat hosts | xargs -I{} echo root@{} # root@delkon # root@study # root@flypig # root@ikun # root@daniel cat hosts | xargs -n 2 echo # delkon study # flypig ikun # daniel ls # dataloaders.py lr_scheduler.py torch_utils.py find . -name \u0026#39;*.py\u0026#39; | xargs grep \u0026#39;matplotlib\u0026#39; # ./dataloaders.py:import matplotlib.pyplot as plt # ./dataloaders.py:from matplotlib import rcParams 文件管理 ls -l展示文件属性 ls -l # total 64 # lrwxrwxrwx 1 root root 7 Apr 22 2024 bin -\u0026gt; usr/bin # drwxr-xr-x 2 root root 4096 Apr 22 2024 boot # drwxr-xr-x 5 root root 360 Mar 13 15:38 dev # drwxr-xr-x 1 root root 4096 Mar 12 20:33 etc # drwxr-xr-x 1 root root 4096 Jan 27 10:19 home # lrwxrwxrwx 1 root root 7 Apr 22 2024 lib -\u0026gt; usr/lib # drwxr-xr-x 2 root root 4096 Jan 27 10:12 media # drwxr-xr-x 2 root root 4096 Jan 27 10:12 mnt # drwxr-xr-x 2 root root 4096 Jan 27 10:12 opt # dr-xr-xr-x 213 root root 0 Mar 13 15:38 proc # drwx------ 1 root root 4096 Mar 13 16:25 root # drwxr-xr-x 4 root root 4096 Jan 27 10:19 run # lrwxrwxrwx 1 root root 8 Apr 22 2024 sbin -\u0026gt; usr/sbin # drwxr-xr-x 2 root root 4096 Jan 27 10:12 srv # dr-xr-xr-x 11 root root 0 Mar 13 15:51 sys # drwxrwxrwt 1 root root 4096 Mar 12 17:30 tmp # drwxr-xr-x 1 root root 4096 Jan 27 10:12 usr # drwxr-xr-x 1 root root 4096 Jan 27 10:19 var 第一列总共10位\n第一位表示文件类型，可以有以下几种字母表示： -：普通文件 d：目录 l：符号连接 b：块设备文件 c：字符设备文件 s：套接字 p：命名管道 剩下9位分为3组，每组3位分别有以下权限r（可读）w（可写）x（可执行） 2-4位：文件属主（owner）的权限 5-7位：同组用户（group）的权限 8-10位：其他用户（others）的权限 第二列表示硬链接数，硬链接是指向同一个文件的多个文件名。对于目录，这个数字表示目录下的子目录数量加 2（当前目录 . 和父目录 ..）。\n第三列和第四列分别表示文件属主和文件属组。\n第五列表示文件大小，以字节为单位。如果文件是符号链接，大小为链接目标的路径长度（如 bin -\u0026gt; usr/bin 中，大小为 7 是因为 usr/bin 有 7 个字符）。如果是目录，则一般固定为 4096 字节。\n第六列第七列第八列表示最后修改时间。\n第九列表示文件名，如果是符号链接（如 bin -\u0026gt; usr/bin），则后面会显示链接的目标。\nln进行符号链接和硬链接 ln [-sf] src dst 选项与参数： -s ：创建符号链接。 -f ：强制创建链接文件，覆盖已经存在的目标文件。 ls # Python hosts ln hosts hardlink_hosts ls # Python hardlink_hosts hosts ln -s hosts symboliclink_hosts ls # Python hardlink_hosts hosts symboliclink_hosts ls -l # drwxr-xr-x 2 root root 4096 Mar 13 16:25 Python # -rw-r--r-- 2 root root 32 Mar 13 16:09 hardlink_hosts # -rw-r--r-- 2 root root 32 Mar 13 16:09 hosts # lrwxrwxrwx 1 root root 5 Mar 13 17:25 symboliclink_hosts -\u0026gt; hosts cat hosts cat hardlink_hosts cat symboliclink_hosts # delkon # study # flypig # ikun # daniel 特性 硬链接（Hard Link） 符号链接（Symbolic Link） 指向 指向文件的物理数据块 指向文件的路径 文件大小 与原文件相同 符号链接本身只占用少量空间（保存路径） 文件系统限制 只能在同一文件系统上创建 可以跨文件系统创建 删除效果 删除硬链接不会删除文件数据，除非所有硬链接被删除 删除符号链接不会影响原文件 适用场景 文件备份，防止意外删除 快捷访问其他文件、跨目录、文件系统使用 硬盘 硬盘的使用：硬盘分区-\u0026gt;硬盘格式化（format)-\u0026gt;文件系统的挂载\n硬盘分区 /dev/sd[a-p][1-128]：为分区后的实体硬盘分配的硬盘文件名； /dev/vd[a-d][1-128]：为分区后的虚拟硬盘分配的硬盘文件名。 本系统下的所有磁盘与磁盘内的分割信息使用lsblk(list block device)查看\nlsblk [-dfimpt] [device] 选项与参数： -d ：仅列出磁盘本身，并不会列出该磁盘的分割数据 -f ：同时列出该磁盘内的文件系统名称 -i ：使用 ASCII 的线段输出，不要使用复杂的编码 (再某些环境下很有用) -m ：同时输出该设备在 /dev 底下的权限数据 (rwx 的数据) -p ：列出该设备的完整文件名！而不是仅列出最后的名字而已。 -t ：列出该磁盘设备的详细数据，包括磁盘队列机制、预读写的数据量大小等 lsblk # NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS # nbd0 43:0 0 0B 0 disk # nbd1 43:32 0 0B 0 disk # nbd2 43:64 0 0B 0 disk # nbd3 43:96 0 0B 0 disk # nbd4 43:128 0 0B 0 disk # nbd5 43:160 0 0B 0 disk # nbd6 43:192 0 0B 0 disk # nbd7 43:224 0 0B 0 disk # vda 254:0 0 59.6G 0 disk # `-vda1 254:1 0 59.6G 0 part /etc/hosts # /etc/hostname # /etc/resolv.conf # vdb 254:16 0 535.2M 1 disk # nbd8 43:256 0 0B 0 disk # nbd9 43:288 0 0B 0 disk # nbd10 43:320 0 0B 0 disk # nbd11 43:352 0 0B 0 disk # nbd12 43:384 0 0B 0 disk # nbd13 43:416 0 0B 0 disk # nbd14 43:448 0 0B 0 disk # nbd15 43:480 0 0B 0 disk NAME：就是设备的文件名！会省略 /dev 等前导目录！ MAJ:MIN：其实核心认识的设备都是透过这两个代码来熟悉的！分别是主要：次要设备代码！ RM：是否为可卸载设备 (removable device)，如光盘、USB 磁盘等等 SIZE：当然就是容量啰！ RO：是否为唯读设备的意思 TYPE：是磁盘 (disk)、分区 (partition) 还是唯读内存 (rom) 等输出 MOUTPOINT：就是挂载点！ 硬盘格式化 分割完毕后自然就是要进行文件系统的格式化，我们使用mkfs(make filesystem)来进行分区后硬盘的格式化。\nmkfs[tab][tab] # mkfs mkfs.cramfs mkfs.ext3 mkfs.minix # mkfs.bfs mkfs.ext2 mkfs.ext4 文件系统挂载 我们首先要明确，挂载点是目录，这个目录是进入硬盘分区（文件系统）的入口。同时挂载之前我们还应该确定一些事：\n单一文件系统不应该被重复挂载在不同的挂载点(目录)中； 单一目录不应该重复挂载多个文件系统； 要作为挂载点的目录，理论上应该都是空目录才是。 挂载使用的命令是mount，具体如下：\nmount -a mount [-l] mount [-t 文件系统] LABEL=\u0026#39;\u0026#39; 挂载点 mount [-t 文件系统] UUID=\u0026#39;\u0026#39; 挂载点 # 鸟哥近期建议用这种方式喔！ mount [-t 文件系统] 设备文件名 挂载点 选项与参数： -a ：依照设置档 [/etc/fstab](https://muicoder.github.io/linux_basic/0230filesystem.html#fstab)的数据将所有未挂载的磁盘都挂载上来 -l ：单纯的输入 mount 会显示目前挂载的信息。加上 -l 可增列 Label 名称！ -t ：可以加上文件系统种类来指定欲挂载的类型。常见的 Linux 支持类型有：xfs, ext3, ext4, reiserfs, vfat, iso9660(光盘格式), nfs, cifs, smbfs (后三种为网络文件系统类型) 设备文件的卸载 umount [-fn] 设备文件名或挂载点 选项与参数： -f ：强制卸载！可用在类似网络文件系统 (NFS) 无法读取到的情况下； -l ：立刻卸载文件系统，比 -f 还强！ -n ：不更新 /etc/mtab 情况下卸载。 硬盘状态 df（disk free）用于显示磁盘的整体使用情况。\ndf [-akmhHTi] [目录或文件名] 选项与参数： -a ：列出所有的文件系统，包括系统特有的 /proc 等文件系统； -k ：以 KBytes 的容量显示各文件系统； -m ：以 MBytes 的容量显示各文件系统； -h ：以人们较易阅读的 GBytes, MBytes, KBytes 等格式自行显示； -H ：以 M=1000K 取代 M=1024K 的进位方式； -T ：连同该 partition 的 filesystem 名称 (例如 xfs) 也列出； -i ：不用磁盘容量，而以 inode 的数量来显示 df -h # Filesystem Size Used Avail Use% Mounted on # overlay 59G 1.3G 55G 3% / # tmpfs 64M 0 64M 0% /dev # shm 64M 0 64M 0% /dev/shm # /dev/vda1 59G 1.3G 55G 3% /etc/hosts # tmpfs 2.0G 0 2.0G 0% /proc/scsi # tmpfs 2.0G 0 2.0G 0% /sys/firmware du（disk usage）用于查看文件和目录的磁盘使用情况。\ndu [-ahskm] 文件或目录名称 -a ：列出所有的文件与目录容量，因为缺省仅统计目录底下的文件量而已。 -h ：以人们较易读的容量格式 (G/M) 显示； -s ：列出总量而已，而不列出每个各别的目录占用容量； -S ：不包括子目录下的总计，与 -s 有点差别。 -k ：以 KBytes 列出容量显示； -m ：以 MBytes 列出容量显示； Linux文件 文件属性和权限的更改 • chown 用于更改文件或目录的所有者和组。要注意的是， 用户必须是已经存在系统中的帐号，也就是在/etc/passwd 这个文件中有纪录的用户名才能改变。可更改的组名也记录在/etc/group中。\nchown [-R] 用户 文件或目录 chown [-R] 用户:组 文件或目录 选项与参数： -R : 进行递归(recursive)的持续变更，亦即连同次目录下的所有文件都变更 ll # total 32 # drwxr-xr-x 2 ubuntu ubuntu 4096 Mar 14 11:24 ./ # drwxr-x--- 1 ubuntu ubuntu 4096 Mar 14 11:24 ../ # -rw-r--r-- 1 ubuntu ubuntu 8733 Mar 13 16:25 dataloaders.py # -rw-r--r-- 1 ubuntu ubuntu 4231 Mar 13 16:24 lr_scheduler.py # -rw-r--r-- 1 ubuntu ubuntu 4043 Mar 13 16:24 torch_utils.py chown -R root:root ./ ll # total 32 # drwxr-xr-x 2 root root 4096 Mar 14 11:27 ./ # drwxr-x--- 1 ubuntu ubuntu 4096 Mar 14 11:24 ../ # -rw-r--r-- 1 root root 8748 Mar 14 11:27 dataloaders.py # -rw-r--r-- 1 root root 4231 Mar 13 16:24 lr_scheduler.py # -rw-r--r-- 1 root root 4043 Mar 13 16:24 torch_utils.py • chmod 用于更改文件或目录的权限，控制读、写、执行权限。\n数字 chmod [-R] xyz 文件或目录 选项与参数： xyz : 就是刚刚提到的数字类型的权限属性，为 r(4)w(2)x(1) 属性数值的相加。 -R : 进行递归(recursive)的持续变更，亦即连同次目录下的所有文件都会变更 ll ./dataloader.py # -rw-r--r-- 1 root root 8748 Mar 14 11:27 dataloaders.py chmod a+w ./dataloader.py ll ./dataloader.py # -rw-rw-rw- 1 root root 8748 Mar 14 11:27 dataloaders.py chmod u=rw.go=r ./dataloader.py ll ./dataloader.py # -rw-r--r-- 1 root root 8748 Mar 14 11:27 ./dataloaders.py 符号 chmod u (user)\ng (group)\no (others)\na (all) +(加入) -(除去) =(设置) r w x 文件或目录 文件搜索 find [PATH] [option] [action] 选项与参数： 与文件权限及名称有关的参数： -name filename：搜索文件名称为 filename 的文件； -size [+-]SIZE：搜索比 SIZE 还要大(+)或小(-)的文件。这个 SIZE 的规格有：c: 代表 byte， k: 代表 1024bytes。所以，要找比 50KB还要大的文件，就是『 -size +50k 』 -type TYPE ：搜索文件的类型为 TYPE 的，类型主要有：一般正规文件 (f), 设备文件 (b, c), 目录 (d), 链接档 (l), socket (s), 及 FIFO (p) 等属性。 ll /Python # total 32 # drwxr-xr-x 2 root root 4096 Mar 14 11:40 ./ # drwxr-x--- 1 ubuntu ubuntu 4096 Mar 14 12:50 ../ # -rw-r--r-- 1 root root 8748 Mar 14 11:27 dataloaders.py # -rw-r--r-- 1 root root 4231 Mar 13 16:24 lr_scheduler.py # -rw-r--r-- 1 root root 4043 Mar 13 16:24 torch_utils.py find Python/ -name \u0026#39;*.py\u0026#39; # Python/torch_utils.py # Python/lr_scheduler.py # Python/dataloaders.py find Python/ -size -20k # Python/ # Python/torch_utils.py # Python/lr_scheduler.py # Python/dataloaders.py find Python/ -type f # Python/torch_utils.py # Python/lr_scheduler.py # Python/dataloaders.py ","permalink":"https://fordelkon.github.io/posts/cmd_intro_2/","summary":"\u003cp\u003e熟练使用命令行是一种常常被忽视，或被认为难以掌握的技能，但实际上，它会提高你作为工程师的灵活性以及生产力。本文旨在了解命令行中的重定向功能和文件管理功能。\u003c/p\u003e","title":"使用命令行的艺术2"},{"content":"熟练使用命令行是一种常常被忽视，或被认为难以掌握的技能，但实际上，它会提高你作为工程师的灵活性以及生产力。本文旨在了解命令行的Shell语言的一些基础概念和有关使用命令行的Shell的一些快捷操作，额外带一些Linux系统中系统文件说明\u0026hellip;\n使用docker拉取Ubuntu容器 由于本人的笔记本并非Linux操作系统，为了方便命令行的学习而又不想搭建虚拟机双开系统，我们使用Docker来拉取一个Ubuntu镜像来方便我们学习，有关Docker的介绍参考我的另一篇文章使用Docker的艺术。\n拉取Ubuntu镜像 docker pull ubuntu 运行一个交互式的 Ubuntu 容器 docker run -it ubuntu docker run会根据后面的镜像名称拉起一个新的容器并进入它的命令行。-it 标志表示以交互模式启动，并连接到该容器的终端。进入容器后，你将获得一个完全隔离的 Linux 系统，可以像平常一样使用 Shell。\n退出容器 你可以在Linux系统中运行 exit 命令来退出容器。默认情况下，当你退出容器后，容器也会自动停止。如果你想保持容器在后台运行，可以通过以下方式运行容器： docker run -d ubuntu 重新进入容器 如果是在Linux系统中运行exit命令后，退出容器后容器自动停止，此时再想打开这个容器的话我们先运行以下命令可以查看所有的容器（包括已经停止的），我们可以从中找到我们的容器ID。 docker ps -a # 查看所有的容器，包括停止的 我的电脑上输出的结果是：\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3a8357da8968 ubuntu \u0026#34;/bin/bash\u0026#34; 2 minutes ago Exited (0) About a minute ago tender_elbakyan 然后再根据容器ID启动一个停止的容器：\ndocker start 3a8357da8968 docker exec会进入一个已经在运行的容器：\ndocker exec -it 3a8357da8968 /bin/bash 删除容器和镜像 当我们不在需要容器和镜像的时候，可以删除容器和镜像来节省内存。首先根据容器ID删除容器： docker rm 3a8357da8968 再根据镜像ID删除镜像。先得到镜像ID：\ndocker images 我的电脑的运行结果是：\nREPOSITORY TAG IMAGE ID CREATED SIZE ubuntu latest c3d1a3432580 6 weeks ago 101MB 再删除镜像：\ndocker rmi c3d1a3432580 Bash Shell Linux系统文件中的shell Shell（壳程序）可以提供使用者操作应用程序的接口。/bin/bash是Linux默认的shell，Linux可用的shell记录在/etc/shells中，我们可以通过以下命令查看Linux可用的shells：\ncat /etc/shells 得到的输出是：\n# /etc/shells: valid login shells /bin/sh /usr/bin/sh /bin/bash /usr/bin/bash /bin/rbash /usr/bin/rbash /usr/bin/dash 登陆Linux系统时，系统会给予一个shell，这个登陆取得的shell记录在/etc/passwd中，可以通过以下命令查看：\ncat /etc/passwd 得到的输出是：\nroot@611b47761989:/# cat /etc/passwd root:x:0:0:root:/root:/bin/bash daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin ......（下面省略）...... bash shell的功能 记忆使用过的指令（记录的指令在~/.bash_history中） 命令与文件的补全（使用tab键，两次连按tab键会对匹配的命令或文件进行显示，如果只有一个与之匹配的命令或文件，则一次tab键会自动补全） 设置命令别名 比如要现实目录下面的所有文件 （包含隐藏文件） 及所有的文件属性，我们可以运行以下命令： ls -al 但我们又是嫌弃这样写太过麻烦，我们可以对以上命令进行别名命名：\nalias lm=\u0026#39;ls -al\u0026#39; 那么lm的功能就和之前的ls -al功能一致了。\n程序化脚本（shell script） 万用字符匹配*（指令列输入指令的万用字符，不带引号） 符号 意义 * 代表“ 0 个到无穷多个”任意字符 ? 代表“一定有一个”任意字符 [ ] 同样代表“一定有一个在括号内”的字符（非任意字符）。例如[abcd] 代表“一定有一个字符， 可能是 a, b, c, d 这四个任何一个” [ - ] 若有减号在中括号内时，代表“在编码顺序内的所有字符”。例如[0-9] 代表 0 到 9 之间的所有数字，因为数字的语系编码是连续的！ [^ ] 若中括号内的第一个字符为指数符号 （^） ，那表示“反向选择”，例如 [^abc] 代表 一定有一个字符，只要是非 a, b, c 的其他字符就接受的意思。 与命令行相关的特殊符号 # 注解符号：这个最常被使用在 script 当中，视为说明！在后的数据均不执行 \\ 跳脱符号：将“特殊字符或万用字符”还原成一般字符 | 管道（pipe）：分隔两个管线命令的界定； ; 连续指令下达分隔符号：连续性命令的界定 （注意！与管线命令并不相同） ~ 使用者的主文件夹 $ 取用变量前置字符：亦即是变量之前需要加的变量取代值 \u0026amp; 工作控制 （job control）：将指令变成背景下工作 ! 逻辑运算意义上的“非” not 的意思！ / 目录符号：路径分隔的符号 \u0026gt;, \u0026raquo; 数据流重导向：输出导向，分别是“取代”与“累加” \u0026lt;, \u0026laquo; 数据流重导向：输入导向 \u0026rsquo; ' 单引号，不具有变量置换的功能 （$ 变为纯文本） \u0026quot; \u0026quot; 具有变量置换的功能！ （$ 可保留相关功能） 两个“ ` ”中间为可以先执行的指令，亦可使用 $（ ） （ ） 在中间为子 shell 的起始与结束 { } 在中间为命令区块的组合！ bash shell的内置命令查询：type 通过type指令我们可以知道每个指令是否为 bash 的内置指令，此外利用type搜寻后面的名称时，如果后面接的名称并不能以可执行文件的状态被找到， 那么该名称是不会被显示出来的。因此我们可以也可以直接运行可执行文件来代替原命令。\ntype -a ls 得到的输出为：\nls is aliased to `ls --color=auto\u0026#39; ls is /usr/bin/ls ls is /bin/ls 因此我们也可以直接运行/usr/bin/ls或/bin/ls来代替ls。找指令也可以使用which。\nbash shell中的快速编辑按钮 ctrl-r搜索命令行历史记录（按下按键之后，输入关键字便可以搜索，重复按下ctrl-r会向后查找匹配项，按下Enter键会执行当前匹配的命令，而按下右方向键会将匹配项放入当前行中，不会直接执行，以便做出修改）。 ctrl-w删除你键入的最后一个单词，ctrl-u可以删除行内光标所在位置之前的内容，alt-b和 alt-f可以以单词为单位移动光标，ctrl-a可以将光标移至行首，ctrl-e可以将光标移至行尾，ctrl-k可以删除光标至行尾的所有内容，ctrl-l可以清屏。键入 man readline 可以查看 Bash 中的默认快捷键。内容有很多，例如 alt-.循环地移向前一个参数，而alt-*可以展开通配符。 shell的变量 字符串和数组是 Shell 中最常用的变量类型。 如果变量类型是数组，我们可以通过以下方式遍历所有元素：\nnames=(\u0026#34;delkon\u0026#34; \u0026#34;ikun\u0026#34; \u0026#34;bob\u0026#34;) echo \u0026#34;${names[@]}\u0026#34; # delkon ikun bob # 但是下面的命令只能索引到第一个元素 echo \u0026#34;$names\u0026#34; delkon 使用echo命令可以读出变量 echo ${variable}读出variable的值(variable是字符串) echo $(command)读出command的stdout echo $((expression))读出表达式的值\n系统自带的环境变量 利用etc观察系统自带环境变量如下：\nHOSTNAME=611b47761989 # 这部主机的主机名称 PWD=/ # 当前工作目录 HOME=/root # 当前用户的主目录 LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=00:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.avif=01;35:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:*~=00;90:*#=00;90:*.bak=00;90:*.crdownload=00;90:*.dpkg-dist=00;90:*.dpkg-new=00;90:*.dpkg-old=00;90:*.dpkg-tmp=00;90:*.old=00;90:*.orig=00;90:*.part=00;90:*.rej=00;90:*.rpmnew=00;90:*.rpmorig=00;90:*.rpmsave=00;90:*.swp=00;90:*.tmp=00;90:*.ucf-dist=00;90:*.ucf-new=00;90:*.ucf-old=00;90: TERM=xterm # 这个终端机使用的环境是什么类型 SHLVL=1 # 当前 shell 会话的深度层级 PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin # 系统搜索可执行文件的路径列表 _=/usr/bin/env # 这是最后一个执行命令的路径 比较重要的除了上面介绍的之外还有一个RANDOM变量，在 BASH 的环境下，这个 RANDOM 变量的内容，介于 0~32767 之间，由/dev/random乱数器产生。\nbash内的自订变量 利用set命令观察bash内的其他变量如下：\nBASH=/bin/bash ...... BASH_ALIASES=() BASH_ARGC=([0]=\u0026#34;0\u0026#34;) BASH_ARGV=() BASH_CMDS=() BASH_LINENO=() BASH_LOADABLES_PATH=/usr/local/lib/bash:/usr/lib/bash:/opt/local/lib/bash:/usr/pkg/lib/bash:/opt/pkg/lib/bash:. BASH_SOURCE=() BASH_VERSINFO=([0]=\u0026#34;5\u0026#34; [1]=\u0026#34;2\u0026#34; [2]=\u0026#34;21\u0026#34; [3]=\u0026#34;1\u0026#34; [4]=\u0026#34;release\u0026#34; [5]=\u0026#34;aarch64-unknown-linux-gnu\u0026#34;) BASH_VERSION=\u0026#39;5.2.21(1)-release\u0026#39; COLUMNS=80 DIRSTACK=() EUID=0 GROUPS=() HISTCONTROL=ignoredups:ignorespace HISTFILE=/root/.bash_history HISTFILESIZE=2000 HISTSIZE=1000 HOME=/root HOSTNAME=611b47761989 HOSTTYPE=aarch64 IFS=$\u0026#39; \\t\\n\u0026#39; LINES=25 ...... MACHTYPE=aarch64-unknown-linux-gnu MAILCHECK=60 OPTERR=1 OPTIND=1 OSTYPE=linux-gnu PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PIPESTATUS=([0]=\u0026#34;0\u0026#34;) PPID=0 PS1=\u0026#39;\\[\\e]0;\\u@\\h: \\w\\a\\]${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ \u0026#39; PS2=\u0026#39;\u0026gt; \u0026#39; PS4=\u0026#39;+ \u0026#39; PWD=/ SHELL=/bin/bash SHELLOPTS=braceexpand:emacs:hashall:histexpand:history:interactive-comments:monitor SHLVL=1 TERM=xterm UID=0 _=clear 上面的变量有一些比较重要，我们分而述之。\nPS1：（提示字符的设置） 当我们每次按下enter键去执行某个指令后，最后要再次出现提示符时就会去读取这个变量值。 PS1=\u0026#39;\\[\\e]0;\\u@\\h: \\w\\a\\]${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ \u0026#39; 其中\\[\\e]0;...\\a\\]: 这是一个 ANSI 转义序列，用于在支持的终端中设置窗口的标题或图标。${debian_chroot:+($debian_chroot)}是条件表达式，用于在 Debian 或其他带有 chroot 环境时显示当前的 chroot 名称。\\u@\\h显示格式为 用户名@主机名，\\w显示当前的工作目录，最后\\$根据当前用户是否是超级用户显示不同的符号。还有一些其他比较有意思的符号，比如\n# ： 下达的第几个指令。 \\t ：显示时间，为 24 小时格式的“HH:MM:SS” \\T ：显示时间，为 12 小时格式的“HH:MM:SS” \\A ：显示时间，为 24 小时格式的“HH:MM” \\@ ：显示时间，为 12 小时格式的“am/pm”样式 $：本shell的PID 我们可以运行echo ${$}来展示本shell的PID号码，结果如下: 51 ?：上个执行指令的回传值 如果成功的执行上个指令， 则会回传一个 0 值，如果执行过程发生错误，就会回传非为 0 的数值。具体情形如下所示： cd cati 结果为：\nbash: cd: cati: No such file or directory 再运行：\necho ${?} 结果为：\n1 自订变量和环境变量的转换 自订变量转成环境变量 采用export命令或declare -x： export variable declare -x variable 环境变量（由自订变量转换而成的环境变量）转成自订变量 declare [-aixr] variable 选项与参数： -a ：将后面名为 variable 的变量定义成为阵列 （array） 类型 -i ：将后面名为 variable 的变量定义成为整数数字 （integer） 类型 -x ：用法与 export 一样，就是将后面的 variable 变成环境变量； -r ：将变量设置成为 readonly 类型，该变量不可被更改内容，也不能 unset 采用declare +x:\ndeclare +x variable bash中与变量扩展方式 #：从字符串开头删除与pattern匹配的最短部分，并返回剩下的字符串。也可以用来获取变量的字符长度。 语法：${variable#pattern} 语法：${#variable} ##：从字符串开头删除与pattern匹配的最长部分，并返回剩下的字符串。 语法：${variable##pattern} 具体示例如下：\nstr=abc.defg.hijkl.txt echo ${str#*.} # defg.hijkl.txt echo ${str##*.} # txt %: 从字符串末尾删除与 pattern 匹配的最短部分，并返回剩下的字符串。 语法：${variable%pattern} %%：从字符串末尾删除与 pattern 匹配的最短部分，并返回剩下的字符串。 语法：${variable%%pattern} 具体示例如下： echo ${str%.*} # abc.defg.hijkl echo ${str%%.*} # abc /：将变量 variable 中第一个匹配 pattern 的部分替换为 replacement。 语法：${variable/pattern/replacement} //：将变量 variable 中所有匹配 pattern 的部分替换为 replacement。 语法：${variable//pattern/replacement} 具体示例如下： fname=delkon-university-works echo ${fname/-/_} # delkon_university-works echo ${fname//-/_} # delkon_university_works :-：如果变量未定义或为空，则返回default值。 语法：${variable:-default} :=：如果变量未定义或为空，则将其赋值为 default。 语法：${variable:=default} :+：如果变量已定义且不为空，则返回 replacement，否则返回空字符串。 语法：${variable:+replacement} :?：如果变量未定义或为空，则输出 error 消息并退出脚本。 语法：${variable:?error} 具体一些情况如下表格所示：\n变量设置方式 str 没有设置 str 为空字串 str 已设置非为空字串 var=${str-expr} var=expr var= var=$str var=${str:-expr} var=expr var=expr var=$str var=${str+expr} var= var=expr var=expr var=${str:+expr} var= var= var=expr var=${str=expr} str=expr var=expr str 不变 var= str 不变 var=$str var=${str:=expr} str=expr var=expr str=expr var=expr str 不变 var=$str var=${str?expr} expr 输出至 stderr var= var=$str var=${str:?expr} expr 输出至 stderr expr 输出至 stderr var=$str ${variable:offset}和${variable:offset:length}用来从变量中提取子字符串。 bash配置 source或.后接配置文件会立即使用该配置文件。\n","permalink":"https://fordelkon.github.io/posts/cmd_intro_1/","summary":"\u003cp\u003e熟练使用命令行是一种常常被忽视，或被认为难以掌握的技能，但实际上，它会提高你作为工程师的灵活性以及生产力。本文旨在了解命令行的Shell语言的一些基础概念和有关使用命令行的Shell的一些快捷操作，额外带一些Linux系统中系统文件说明\u0026hellip;\u003c/p\u003e","title":"使用命令行的艺术1"},{"content":"这篇博客主要自底向上地介绍Git命令行，有时甚至会使用一些python代码来对一些Git的功能进行更加详细的分析。我一直认为基础一旦打好，那么一些更高级的用法也可以循序渐进地了解，而且是更加透彻的了解。不是像博主一开始那样以为只要死记硬背git add，git commit,git pull，git clone等常见命令的一些用法就可以了😭（实际上网上大多数教程就是这样教的\u0026hellip;），在这上面走了不少弯路，所以从头开始打地基写作此文留以警示⚠️。\nGit仓库（Git Repository） 要学习Git，首先我们要知道我们运行Git命令是对什么对象进行操作的，在Git的相关术语中，我们把这个对象叫做Git仓库（Git Repository），Git仓库实际上就是一个文件夹，在这个文件夹里我们通过.git文件夹（隐藏文件夹）对Git仓库中的工作区中的文件（非隐藏文件夹）内容的改变进行记录，当然并不是所有非隐藏文件夹中文件的改变都会被记录，被.gitingore文件所标识的文件被改变后.git文件夹不会对其进行记录。根据我上面所说，Git操作最隐晦的地方就在于对于.git文件夹中内容的修改来保证对于Git仓库非隐藏文件夹中文件内容修改的记录。\n根据上面的描述，我们可以得到一下简略的公式：\n$$\\mathrm{Git}\\ \\mathrm{Repository} = \\mathrm{.git}\\ \\mathrm{folder} + \\mathrm{worktree}\\ \\mathrm{folder}\\tag{1}$$ 更加详尽的来说以python来构建Git仓库类：\nclass GitRepository (object): \u0026#34;\u0026#34;\u0026#34;A git repository\u0026#34;\u0026#34;\u0026#34; worktree = None gitdir = None def __init__(self, path): self.worktree = path self.gitdir = os.path.join(path, \u0026#34;.git\u0026#34;) .git文件夹内部结构探究 前面我们已经知道了Git操作最隐晦的地方就在于对于.git文件夹中内容的修改来保证对于Git仓库非隐藏文件夹中文件内容修改的记录，那接下来我们就要对此进行脱贫攻坚了。由于.git是隐藏文件夹，所以我们要先对.git文件夹中的文件分布有一定的了解，git init初始化后的.git文件夹中的文件分布如图1所示，此时Git仓库内除了.git文件夹之外一片荒芜。\n图1：运行git init之后.git文件夹的文件分布结构 然后我们再本地Git仓库中添加可见文件，添加后的结果如图2所示。\n图2：Git仓库添加文件后的文件分布 将上述所有文件运行git add之后在进行git commit观察.git文件夹中的文件分布，如图3所示。可以看到相较于最初的.git文件，我们在git add和git commit之后文件夹中多出了index文件，log文件夹，objects文件夹中的8个文件以及refs/heads下的main文件，其他的一些变化我们不做考虑。有果导因我们可以知道.git文件夹内部的这些变化中有对于Git仓库非隐藏文件夹文件修改的记录。\n图3：运行git add和git commit之后.git文件夹的文件分布结构 Git对象（Git Object） 上面的变化究竟是如何实现的呢？要知道Git中的几乎一切都被存储为Git对象！也就是说我们可以通过Git对象进行操作来完成上面的变化。说了这么多，让我们来为Git对象下一个比较官方的定义：Git对象就是在 Git 仓库中的文件，它们的路径由它们的内容决定。\nGit对象范性可以借由python来实现：\nclass GitObject (object): def __init__(self, data=None): if data != None: self.deserialize(data) else: self.init() def serialize(self): \u0026#34;\u0026#34;\u0026#34;将对象转变为zip文件解压缩后的byte格式\u0026#34;\u0026#34;\u0026#34; raise Exception(\u0026#34;Unimplemented!\u0026#34;) def deserialize(self, data): \u0026#34;\u0026#34;\u0026#34;data通常为zip文件解压缩后的byte格式，根据类型解码\u0026#34;\u0026#34;\u0026#34; raise Exception(\u0026#34;Unimplemented!\u0026#34;) def init(self): pass # Just do nothing. This is a reasonable default! Git对象又细分为以下四种类型：GitBlob（Binary Large Object）对象， GitCommit对象， GitTree对象， GitTag对象，以下分别进行介绍。\nGitBlob对象 我们先最直观的看看Git中对于Blob内容的展示，如图4所示：\n图4：运行git cat-file之后对a.txt所对应的类型和类型内容的展示 Blobs 是用户数据：你放入 Git 中的每个文件的内容（如a.txt、b.txt、src/c.txt、src/d.txt中的内容）的字节形式都被存储为一个 blob。这样做使它们很容易操作，因为 blob 没有特定的语法或约束，除了基本的对象存储机制之外，它们只是未指定的数据。\nGitBlob对象的python实现如下：\nclass GitBlob(GitObject): fmt=b\u0026#39;blob\u0026#39; def serialize(self): return self.blobdata def deserialize(self, data): self.blobdata = data GitTree对象 同上，我们先最直观的看看Git中对于树内容的展示，如图5所示：\n图5：运行git cat-file之后对最顶层的树所对应的类型和类型内容的展示 非正式地说，树（tree）描述了Git仓库非隐藏文件夹中的内容，它将 blobs（文件对象）与路径关联起来。树是一个由三个元素组成的元组数组，这些元素包括文件模式、相对于工作树的路径，以及一个 SHA-1 值。一个典型的树的内容如下所示：\nMode SHA-1 Path 100644 06f844865cfc4b68116d2cbf00833b294aae63ec .DS_Store 100644 e12523960bf9941182c801077be75dce699ff37c a.txt 100644 753e270e92068316ec7fa2b6a40e780a4e1d14d7 b.txt 040000 30d66379dddee7068ab4fd3a17cc1ef9555278ac src 模式（Mode）就是文件的模式，路径（Path）是文件的位置。SHA-1 是指向一个 blob 或另一个树对象。如果是 blob，路径表示的是一个文件；如果是树对象，路径表示的是一个目录。\n常见的文件模式有以下几种：\n100644: 普通文件，具有标准的读写权限（普通的文本文件或代码文件）。 100755: 可执行文件，具有执行权限（如脚本或可执行程序）。 040000: 目录（directory）。 120000: 符号链接（symbolic link）。 160000: Git 子模块（submodule）。 而实际上当我们解析树的时候，也就是对.git/objects中树的SHA-1路径所代表的文件进行解压缩后提纯到的树对象内容的字节编码，它们的格式通常如下：\n[mode] space [path] 0x00 [sha-1] （byte格式）\n由于树对应的文件夹中的文件不止一个，有时甚至会有在文件夹中进行文件夹嵌套。因此我们要设计出叶子对应单个文件，树对应由不同文件所组成的文件夹。\n我们可以将叶子对象和树对象按以下python代码来表示：\nclass GitTreeLeaf (object): def __init__(self, mode, path, sha): self.mode = mode # 模式 self.path = path # 文件路径 self.sha = sha # 文件路径索引到的文件内容标准化后所对应的sha-1值 class GitTree(GitObject): fmt=b\u0026#39;tree\u0026#39; def deserialize(self, data): # tree_parse是解析所得到的树对象的字节编码数据 self.items = tree_parse(data) def serialize(self): # tree_serialize将解析后的结果求逆得到树对象的字节编码数据 return tree_serialize(self) def init(self): self.items = list() 由于一个树中有时不单单包含叶子更有可能包含子树，具体情形见上面一棵树的典型情况，tree_parse和tree_serialize函数如下所示：\ndef tree_parse(raw): pos = 0 max = len(raw) ret = list() while pos \u0026lt; max: pos, data = tree_parse_one(raw, pos) ret.append(data) return ret def tree_parse_one(raw, start=0): # [mode] space [path] 0x00 [sha-1] （byte格式） # 查找字节形式空格以确定mode x = raw.find(b\u0026#39; \u0026#39;, start) assert x-start == 5 or x-start==6 # 读取mode mode = raw[start:x] if len(mode) == 5: # 标准到6字节 mode = b\u0026#34;0\u0026#34; + mode # 查找字节形式空终止符以确定path y = raw.find(b\u0026#39;\\x00\u0026#39;, x) # 读取path path = raw[x+1:y] # 读取sha… # raw[y+1:y+21] 提取的是 20 字节的二进制数据（SHA-1 哈希值）。 raw_sha = int.from_bytes(raw[y+1:y+21], \u0026#34;big\u0026#34;) # int.from_bytes(raw[y+1:y+21], \u0026#34;big\u0026#34;)将提取的 20 字节二进制数据转 # 换为一个整数，然后使用 format(raw_sha, \u0026#34;040x\u0026#34;) 将这个整数转换为 40 # 位的十六进制字符串 。Git中通常使用的sha值时这种形式。比如.DS_Store对应 # 的06f844865cfc4b68116d2cbf00833b294aae63ec sha = format(raw_sha, \u0026#34;040x\u0026#34;) return y+21, GitTreeLeaf(mode, path.decode(\u0026#34;utf8\u0026#34;), sha) def tree_serialize(obj): obj.items.sort(key=tree_leaf_sort_key) ret = b\u0026#39;\u0026#39; for i in obj.items: ret += i.mode ret += b\u0026#39; \u0026#39; ret += i.path.encode(\u0026#34;utf8\u0026#34;) ret += b\u0026#39;\\x00\u0026#39; sha = int(i.sha, 16) ret += sha.to_bytes(20, byteorder=\u0026#34;big\u0026#34;) return ret def tree_leaf_sort_key(leaf): if leaf.mode.startswith(b\u0026#34;10\u0026#34;): return leaf.path # 文件 else: return leaf.path + \u0026#34;/\u0026#34; # 文件夹 GitCommit对象 同上，我们先最直观的看看Git中对于树内容的展示，如图6所示：\n图6：运行git cat-file之后对最顶层的提交所对应的类型和类型内容的展示 一个提交（Commit）的典型如下所示：\ntree 50306289de5ae719af85eaad3430d785517a11e7 parent 735a65cef921f8e30ae55fdf19b695eb15ea8d45 author fordelkon \u0026lt;27xxx88816@qq.com\u0026gt; 1741406298 +0800 committer fordelkon \u0026lt;27xxx88816@qq.com\u0026gt; 1741406298 +0800 life is short, I use Python 从上面的典型来看，一个提交由以下几部分组成：\n树对象，也就是工作树的内容、文件和目录； 零个、一个或多个父提交； 一个作者身份（姓名和邮箱）以及一个时间戳； 一个提交者身份（姓名和邮箱）以及一个时间戳； 一个提交信息。 从提交的组成来看，我们可以明白已经创建好的提交是不可变的。如果我们更改了作者、父提交或任何一个文件，那么我们实际上最终会创建一个新的、不同的提交对象与改变后的结果绑定。所以每一个提交都与它在整个仓库中的位置及其与最初提交的关系紧密相连。换句话说，一个给定的提交 ID （sha-1）不仅标识了某些文件的内容，还将提交与它的整个历史及整个仓库绑定在一起。也就是说，有了提交，我们的Git的历史记录功能就有了保证！ 一个提交对象的python代码如下所示：\nclass GitCommit(GitObject): fmt=b\u0026#39;commit\u0026#39; def deserialize(self, data): # kvlm_parse是解析所得到的提交对象的字节编码数据 self.kvlm = kvlm_parse(data) def serialize(self): # kvlm_serialize将解析后的结果求逆得到提交对象的字节编码数据 return kvlm_serialize(self.kvlm) def init(self): self.kvlm = dict() 由提交的典型来看，我们可以将提交对象的字节编码数据转换成键值对的字典格式，由于有空格和回车。更形象的表示如下:\n[key1] space [value1] \\n \u0026hellip; [keyn] space [valuen] \\n [commit]\n因此，kvlm_parse和kvlm_serialize的python代码如下所示\ndef kvlm_parse(raw, start=0, dct=None): # 如果 dct 为空，初始化一个空字典 if not dct: dct = dict() # 不能在函数参数中直接声明 dct=dict()，否则所有函数调用会共用同一个字典， # 导致每次调用时字典不断增长。 # 这个函数是递归的：它读取一个键/值对，然后调用自身来处理下一个位置。 # 因此我们首先需要知道当前的位置：是在一个关键字，还是已经到了消息部分。 # 查找下一个空格和换行符的位置 spc = raw.find(b\u0026#39; \u0026#39;, start) nl = raw.find(b\u0026#39;\\n\u0026#39;, start) # 如果空格出现在换行符之前，说明我们有一个关键字。否则，它是最终的消息部分， # 我们会读取直到文件的末尾。 # 基本情况 # ========= # 如果换行符先出现（或者根本没有空格，这种情况下 find 返回 -1）， # 我们假设遇到了一个空行。空行意味着剩余的数据是消息部分。 # 我们将它存储在字典中，键为 None，然后返回。 if (spc \u0026lt; 0) or (nl \u0026lt; spc): assert nl == start dct[None] = raw[start+1:] # 存储消息部分 return dct # 递归情况 # ============== # 读取一个键值对并递归处理下一个。 key = raw[start:spc] # 查找值的结尾。以空格开头的行表示值的延续行， # 因此我们需要循环，直到找到一个不是以空格开头的换行符。 end = start while True: end = raw.find(b\u0026#39;\\n\u0026#39;, end+1) if raw[end+1] != ord(\u0026#39; \u0026#39;): break # 找到一个不以空格开头的换行符 # 获取值，同时删除延续行的前导空格 value = raw[spc+1:end].replace(b\u0026#39;\\n \u0026#39;, b\u0026#39;\\n\u0026#39;) # 不要覆盖现有的数据内容 if key in dct: # 如果字典中已有该键，且值为列表，则直接添加新值 if type(dct[key]) == list: dct[key].append(value) else: # 如果已有的值不是列表，创建一个列表来存储多个值 dct[key] = [ dct[key], value ] else: # 如果字典中没有该键，则直接存储键值对 dct[key]=value # 递归处理剩余的部分 return kvlm_parse(raw, start=end+1, dct=dct) def kvlm_serialize(kvlm): ret = b\u0026#39;\u0026#39; # 初始化一个空的字节串用于存储序列化结果 # 输出字段 for k in kvlm.keys(): # 跳过消息体本身（消息存储在字典的 None 键中） if k == None: continue val = kvlm[k] # 将单个值规范化为列表，以便统一处理 if type(val) != list: val = [ val ] # 遍历值列表，处理每个值 for v in val: # 拼接键和值，并确保换行符后面有一个空格（用于表示值的延续行） ret += k + b\u0026#39; \u0026#39; + (v.replace(b\u0026#39;\\n\u0026#39;, b\u0026#39;\\n \u0026#39;)) + b\u0026#39;\\n\u0026#39; # 最后拼接消息体，消息体之前需要一个空行分隔 ret += b\u0026#39;\\n\u0026#39; + kvlm[None] return ret # 返回序列化后的字节串 GitTag对象 标签实际上就是引用（refs）。它们位于 .git/refs/tags/ 目录下。值得注意的是，标签有两种类型：轻量标签和标签对象。\n轻量标签（“Lightweight” tags） 仅仅是指向提交、树对象或 blob 对象的普通引用。\n标签对象（Tag objects） 是指向标签类型对象的普通引用。与轻量标签不同，标签对象包含作者、日期、可选的 PGP 签名以及可选的注释。它们的格式与提交对象相同。\n因此，GitTag的python代码如下所示：\nclass GitTag(GitCommit): fmt = b\u0026#39;tag\u0026#39; 我们已经了解了上面四种Git对象，由Git对象的内容决定路径的性质，可以保证对于非隐藏文件夹中文件内容修改的记录。也就是说，Git仓库非隐藏文件夹中的文件一旦被修改，那么相应的Git对象的路径也会发生改变，将修改后的不同的Git对象的文件标准化后压缩按照改变的路径存储在.git/objects文件夹下，这样可以保证对该改变的记录。那么文件的内容和文件的路径有着明确的映射关系吗？Git给出的答案是对标准化后的文件内容进行 SHA-1哈希后得到文件的路径。如何进行标准化也是我们值得注意的，Git中实现的方案是字节形式类型头+字节形式空格+字节形式大小+字节形式空分离符+对象内容的字节编码。 具体方案如下所示：\n[fmt] space [size] 0x00 [data] (byte格式)\n根据这一标准化的形式我们可以对对象进行读和写操作，所有对象的核心载体是对象内容的字节编码。具体python代码如下：\ndef object_read(repo, sha): \u0026#34;\u0026#34;\u0026#34;Read object sha from Git repository repo. Return a GitObject whose exact type depends on the object.\u0026#34;\u0026#34;\u0026#34; # 由sha1值得到对应路径 path = repo_file(repo, \u0026#34;objects\u0026#34;, sha[0:2], sha[2:]) if not os.path.isfile(path): return None with open (path, \u0026#34;rb\u0026#34;) as f: raw = zlib.decompress(f.read()) # 读取对象类型 x = raw.find(b\u0026#39; \u0026#39;) # 0x20 字节形式空格 fmt = raw[0:x] # 字节形式类型头 # 读取有效的对象大小 y = raw.find(b\u0026#39;\\x00\u0026#39;, x) # 0x00 字节形式空分离符 size = int(raw[x:y].decode(\u0026#34;ascii\u0026#34;)) if size != len(raw)-y-1: raise Exception(f\u0026#34;Malformed object {sha}: bad length\u0026#34;) # 根据对象类型选择生成器 match fmt: case b\u0026#39;commit\u0026#39; : c=GitCommit case b\u0026#39;tree\u0026#39; : c=GitTree case b\u0026#39;tag\u0026#39; : c=GitTag case b\u0026#39;blob\u0026#39; : c=GitBlob case _: raise Exception(f\u0026#34;Unknown type {fmt.decode(\u0026#34;ascii\u0026#34;)} for object {sha}\u0026#34;) # 调用生成器返回对象 return c(raw[y+1:]) # raw[y+1:]对象内容的字节编码 def object_write(obj, repo=None): # 对象内容的字节编码 data = obj.serialize() # 添加一些前缀成为标准格式 result = obj.fmt + b\u0026#39; \u0026#39; + str(len(data)).encode() + b\u0026#39;\\x00\u0026#39; + data # 计算sha1 sha = hashlib.sha1(result).hexdigest() if repo: # 由sha1值得到对应路径 path=repo_file(repo, \u0026#34;objects\u0026#34;, sha[0:2], sha[2:], mkdir=True) if not os.path.exists(path): with open(path, \u0026#39;wb\u0026#39;) as f: # Compress and write f.write(zlib.compress(result)) return sha 好了，前戏已经准备了这么多，我们可以凭借Git仓库和Git对象来实现最最最重要的Git两连击吗（git add和git commit）？答案当然是\u0026hellip;\u0026hellip;否定的。是的，我们已经拥有了这么多的对象，也有了读取和写入对象的功能，但是一旦我们改变文件（不妨就改变a.txt文件的内容），由前面我们说的主要的三种对象来看，GitBlob元数据会改变，随之而来的GitTree元数据会改变，进而GitCommit元数据也会改变。这个过程不是一挥而就的，所以Git种才会分为git add和git commit两步走。在git add的过程中我们将修改后的文件属性变化提交到暂存区（Staging area），也就是我们图3中的.git/index文件中。然后使用git commit将暂存区中的所有记录的文件统合生成新的GitTree，进而生成新的GitCommit。很明显，我们还需要一个表示暂存区的类型。\n暂存区（Staging area） 暂存区在.git文件夹中的展现形式就是.git/index文件，在一次提交之后，.git/index文件可以看作是该提交的一种副本：它保存了与对应的树相同的路径/Blob（对象）的关联关系。但它还保存了Git仓库中关于文件的额外信息，比如它们的创建/修改时间，因此 git status 通常不需要实际比较文件：它只需要检查文件的修改时间是否与索引文件中存储的时间相同，只有当它们不同时，才会执行实际的比较。类比树对象的表示，.git/index文件中包含许多元素，所以我们的第一个任务是对单个元素进行表示，之后是对整体.git/index文件进行表示。\n单个元素和整体.git/index文件的python表示如下：\nclass GitIndexEntry (object): def __init__(self, ctime=None, mtime=None, dev=None, ino=None, mode_type=None, mode_perms=None, uid=None, gid=None, fsize=None, sha=None, flag_assume_valid=None, flag_stage=None, name=None): # 文件元数据最后更改的时间。格式是一个二元组 # (以秒为单位的时间戳, 纳秒) self.ctime = ctime # 文件数据最后更改的时间。格式是一个二元组 # (以秒为单位的时间戳, 纳秒) self.mtime = mtime # 包含该文件的设备ID self.dev = dev # 文件的inode编号 self.ino = ino # 对象类型，可以是 b1000 (普通文件), b1010 (符号链接), # b1110 (gitlink) self.mode_type = mode_type # 对象的权限，表示为一个整数 self.mode_perms = mode_perms # 文件所有者的用户ID self.uid = uid # 文件所有者的组ID self.gid = gid # 对象的大小，以字节为单位 self.fsize = fsize # 对象的SHA哈希值 self.sha = sha # 标志：假设该对象有效 self.flag_assume_valid = flag_assume_valid # 文件的阶段标志 self.flag_stage = flag_stage # 对象的名称（包括完整路径） self.name = name class GitIndex (object): version = None entries = [] # ext = None # sha = None def __init__(self, version=2, entries=None): if not entries: entries = list() self.version = version self.entries = entries .git/index文件是一个二进制文件，可能是出于性能考虑。尽管如此，它的格式相对简单。文件开始部分是一个头部信息，包含了 DIRC 魔法字节、版本号以及该索引文件中的条目总数。更形象的格式如下：\n[DIRC] [version] [count] [entries]\n所以我们可以定义index_read和index_write函数如下：\ndef index_read(repo): # 获取仓库索引文件的路径 index_file = repo_file(repo, \u0026#34;index\u0026#34;) # 如果索引文件不存在（例如新仓库），则返回一个空的 GitIndex 实例 if not os.path.exists(index_file): return GitIndex() # 打开索引文件，以二进制方式读取 with open(index_file, \u0026#39;rb\u0026#39;) as f: raw = f.read() # 索引文件的头部包含 12 个字节 header = raw[:12] signature = header[:4] # 检查索引文件的魔法字节，必须为 \u0026#34;DIRC\u0026#34;，代表 \u0026#34;DirCache\u0026#34; assert signature == b\u0026#34;DIRC\u0026#34; # 从头部解析版本号（4-8字节），此处只支持版本 2 version = int.from_bytes(header[4:8], \u0026#34;big\u0026#34;) assert version == 2, \u0026#34;wyag 只支持索引文件版本 2\u0026#34; # 从头部解析索引文件中的条目数量（8-12字节） count = int.from_bytes(header[8:12], \u0026#34;big\u0026#34;) # 用于存储读取到的索引条目 entries = list() # 索引文件内容部分从第 12 个字节开始 content = raw[12:] idx = 0 # 循环解析每个条目，根据文件头部给出的条目数进行循环 for i in range(0, count): # 解析创建时间（秒数和纳秒数） ctime_s = int.from_bytes(content[idx: idx+4], \u0026#34;big\u0026#34;) ctime_ns = int.from_bytes(content[idx+4: idx+8], \u0026#34;big\u0026#34;) # 解析修改时间（秒数和纳秒数） mtime_s = int.from_bytes(content[idx+8: idx+12], \u0026#34;big\u0026#34;) mtime_ns = int.from_bytes(content[idx+12: idx+16], \u0026#34;big\u0026#34;) # 解析设备 ID dev = int.from_bytes(content[idx+16: idx+20], \u0026#34;big\u0026#34;) # 解析 inode 编号 ino = int.from_bytes(content[idx+20: idx+24], \u0026#34;big\u0026#34;) # 忽略的字段 unused = int.from_bytes(content[idx+24: idx+26], \u0026#34;big\u0026#34;) assert 0 == unused # 解析文件模式（包括类型和权限） mode = int.from_bytes(content[idx+26: idx+28], \u0026#34;big\u0026#34;) mode_type = mode \u0026gt;\u0026gt; 12 assert mode_type in [0b1000, 0b1010, 0b1110] # 文件类型必须是常规文件、符号链接或 gitlink mode_perms = mode \u0026amp; 0b0000000111111111 # 解析用户 ID 和组 ID uid = int.from_bytes(content[idx+28: idx+32], \u0026#34;big\u0026#34;) gid = int.from_bytes(content[idx+32: idx+36], \u0026#34;big\u0026#34;) # 解析文件大小 fsize = int.from_bytes(content[idx+36: idx+40], \u0026#34;big\u0026#34;) # 解析 SHA（对象 ID），并格式化为 40 字符的小写十六进制字符串 sha = format(int.from_bytes(content[idx+40: idx+60], \u0026#34;big\u0026#34;), \u0026#34;040x\u0026#34;) # 解析标志位 flags = int.from_bytes(content[idx+60: idx+62], \u0026#34;big\u0026#34;) # 解析假定有效标志位 flag_assume_valid = (flags \u0026amp; 0b1000000000000000) != 0 # 解析扩展标志位（被忽略） flag_extended = (flags \u0026amp; 0b0100000000000000) != 0 assert not flag_extended # 解析阶段标志位 flag_stage = flags \u0026amp; 0b0011000000000000 # 解析文件名长度（12 位） name_length = flags \u0026amp; 0b0000111111111111 # 读取了 62 个字节，继续处理文件名 idx += 62 # 如果文件名长度小于 0xFFF，则文件名之后有一个空字节终止符 if name_length \u0026lt; 0xFFF: assert content[idx + name_length] == 0x00 raw_name = content[idx:idx+name_length] idx += name_length + 1 else: # 处理文件名长度大于等于 0xFFF 的情况，需要查找空字节终止符 print(f\u0026#34;注意: 文件名长度为 0x{name_length:X} 字节长。\u0026#34;) null_idx = content.find(b\u0026#39;\\x00\u0026#39;, idx + 0xFFF) raw_name = content[idx: null_idx] idx = null_idx + 1 # 将文件名解析为 UTF-8 字符串 name = raw_name.decode(\u0026#34;utf8\u0026#34;) # 索引文件中的数据以 8 字节对齐，因此需要根据指针对齐调整 idx idx = 8 * ceil(idx / 8) # 将解析出的索引条目添加到列表中 entries.append(GitIndexEntry(ctime=(ctime_s, ctime_ns), mtime=(mtime_s, mtime_ns), dev=dev, ino=ino, mode_type=mode_type, mode_perms=mode_perms, uid=uid, gid=gid, fsize=fsize, sha=sha, flag_assume_valid=flag_assume_valid, flag_stage=flag_stage, name=name)) # 返回包含所有索引条目的 GitIndex 实例 return GitIndex(version=version, entries=entries) def index_write(repo, index): with open(repo_file(repo, \u0026#34;index\u0026#34;), \u0026#34;wb\u0026#34;) as f: # 写入头部信息 # 写入魔术字节 \u0026#34;DIRC\u0026#34; 以标识该文件为 Git 索引文件。 f.write(b\u0026#34;DIRC\u0026#34;) # 写入版本号（固定为 2）。 f.write(index.version.to_bytes(4, \u0026#34;big\u0026#34;)) # 写入索引条目数量。 f.write(len(index.entries).to_bytes(4, \u0026#34;big\u0026#34;)) # 写入条目数据 idx = 0 for e in index.entries: # 写入创建时间（秒）和创建时间的纳秒部分。 f.write(e.ctime[0].to_bytes(4, \u0026#34;big\u0026#34;)) f.write(e.ctime[1].to_bytes(4, \u0026#34;big\u0026#34;)) # 写入修改时间（秒）和修改时间的纳秒部分。 f.write(e.mtime[0].to_bytes(4, \u0026#34;big\u0026#34;)) f.write(e.mtime[1].to_bytes(4, \u0026#34;big\u0026#34;)) # 写入设备号和 inode 号。 f.write(e.dev.to_bytes(4, \u0026#34;big\u0026#34;)) f.write(e.ino.to_bytes(4, \u0026#34;big\u0026#34;)) # 写入文件权限模式（类型和权限合并）。 mode = (e.mode_type \u0026lt;\u0026lt; 12) | e.mode_perms f.write(mode.to_bytes(4, \u0026#34;big\u0026#34;)) # 写入用户 ID 和组 ID。 f.write(e.uid.to_bytes(4, \u0026#34;big\u0026#34;)) f.write(e.gid.to_bytes(4, \u0026#34;big\u0026#34;)) # 写入文件大小。 f.write(e.fsize.to_bytes(4, \u0026#34;big\u0026#34;)) # 写入 SHA-1 对象 ID。 f.write(int(e.sha, 16).to_bytes(20, \u0026#34;big\u0026#34;)) # 处理标志位 `flag_assume_valid`。 flag_assume_valid = 0x1 \u0026lt;\u0026lt; 15 if e.flag_assume_valid else 0 # 将文件名编码为 UTF-8，并计算长度。 name_bytes = e.name.encode(\u0026#34;utf8\u0026#34;) bytes_len = len(name_bytes) if bytes_len \u0026gt;= 0xFFF: name_length = 0xFFF # 长度过长时，标记为 0xFFF。 else: name_length = bytes_len # 将 `flag_assume_valid`、`flag_stage` 和名称长度合并到 2 个字节中。 f.write((flag_assume_valid | e.flag_stage | name_length).to_bytes(2, \u0026#34;big\u0026#34;)) # 写入文件名，并附加一个 0x00 作为结尾。 f.write(name_bytes) f.write((0).to_bytes(1, \u0026#34;big\u0026#34;)) # 计算当前条目的字节数。 idx += 62 + len(name_bytes) + 1 # 若条目不是 8 字节对齐，则进行填充。 if idx % 8 != 0: pad = 8 - (idx % 8) f.write((0).to_bytes(pad, \u0026#34;big\u0026#34;)) idx += pad 按照我们前面所说的，git add会根据所修改的文件路径对.git/index文件中的内容进行修改。具体实现方式是从.git/index文件中移除指定路径的条目（不物理删除文件），然后对每个路径，读取文件内容，计算文件的哈希值并获取文件的元数据信息，然后将文件的相关信息添加到.git/index文件中，包括 ctime、mtime、文件权限等，最后将新的索引条目写回索引文件。具体的add函数实现如下：\ndef add(repo, paths, delete=True, skip_missing=False): # 首先调用 rm 函数从索引中移除这些路径的条目，避免重复（不物理删除文件）。 rm(repo, paths, delete=False, skip_missing=True) # 获取工作树的根目录路径（末尾加上路径分隔符） worktree = repo.worktree + os.sep # 将路径转换为 (绝对路径，相对路径) 的对，并确保它们在工作树内且为文件 clean_paths = set() for path in paths: abspath = os.path.abspath(path) # 获取绝对路径 if not (abspath.startswith(worktree) and os.path.isfile(abspath)): # 确保路径在工作树内且为文件 raise Exception(f\u0026#34;Not a file, or outside the worktree: {paths}\u0026#34;) # 如果路径无效或不在工作树内，抛出异常 relpath = os.path.relpath(abspath, repo.worktree) # 获取相对路径 clean_paths.add((abspath, relpath)) # 添加到 clean_paths 集合中 # 查找并读取索引。由于 `rm` 已经修改了索引，这里再次读取。 # @FIXME：可以通过传递命令来移动索引，而不是反复读写索引。 index = index_read(repo) # 遍历每个路径对，读取文件，生成哈希并更新索引条目 for (abspath, relpath) in clean_paths: with open(abspath, \u0026#34;rb\u0026#34;) as fd: sha = object_hash(fd, b\u0026#34;blob\u0026#34;, repo) # 计算文件的 SHA 哈希值 stat = os.stat(abspath) # 获取文件状态 # 获取文件的创建时间和修改时间（秒和纳秒） ctime_s = int(stat.st_ctime) ctime_ns = stat.st_ctime_ns % 10**9 mtime_s = int(stat.st_mtime) mtime_ns = stat.st_mtime_ns % 10**9 # 创建 Git 索引条目对象 entry = GitIndexEntry(ctime=(ctime_s, ctime_ns), mtime=(mtime_s, mtime_ns), dev=stat.st_dev, ino=stat.st_ino, mode_type=0b1000, mode_perms=0o644, uid=stat.st_uid, gid=stat.st_gid, fsize=stat.st_size, sha=sha, flag_assume_valid=False, flag_stage=False, name=relpath) # 将新条目添加到索引条目列表 index.entries.append(entry) # 将更新后的索引写回文件 index_write(repo, index) def rm(repo, paths, delete=True, skip_missing=False): # 查找并读取索引文件 index = index_read(repo) # 获取工作树的根目录路径（末尾加上路径分隔符） worktree = repo.worktree + os.sep # 将输入路径转换为绝对路径，并确保它们位于工作树内 abspaths = set() for path in paths: abspath = os.path.abspath(path) # 获取绝对路径 if abspath.startswith(worktree): # 确保路径在工作树中 abspaths.add(abspath) else: raise Exception(f\u0026#34;Cannot remove paths outside of worktree: {paths}\u0026#34;) # 如果路径不在工作树内，抛出异常 # 将要保留的索引条目列表，用于更新索引文件 kept_entries = list() # 将要删除的路径列表，用于物理删除文件 remove = list() # 遍历索引条目，删除匹配的路径，保留其余条目 for e in index.entries: full_path = os.path.join(repo.worktree, e.name) # 获取索引条目的完整路径 if full_path in abspaths: # 如果路径在待删除列表中 remove.append(full_path) # 加入待删除列表 abspaths.remove(full_path) # 从待删除路径中移除 else: kept_entries.append(e) # 保留该条目 # 如果有未在索引中找到的路径，且 skip_missing=False，则抛出异常 if len(abspaths) \u0026gt; 0 and not skip_missing: raise Exception(f\u0026#34;Cannot remove paths not in the index: {abspaths}\u0026#34;) # 物理删除文件系统中的路径 if delete: for path in remove: os.unlink(path) # 删除文件 # 更新索引条目，并将其写回索引文件 index.entries = kept_entries index_write(repo, index) 然后再使用git add之后的.git/index文件生成树对象，最后再借由树对象生成提交对象！！！具体python代码实现如下：\ndef tree_from_index(repo, index): # 初始化一个字典，用于存储目录及其内容，根目录 \u0026#34;\u0026#34; 存储一个空列表。 contents = dict() contents[\u0026#34;\u0026#34;] = list() # 遍历索引中的每个条目，构建目录结构。 for entry in index.entries: dirname = os.path.dirname(entry.name) # 获取当前条目的目录名 # 遍历目录路径，直到根目录，确保每个目录都被创建 key = dirname while key != \u0026#34;\u0026#34;: if key not in contents: # 如果该目录尚未在 contents 中，创建一个空列表 contents[key] = list() key = os.path.dirname(key) # 将条目添加到对应目录的内容列表中 contents[dirname].append(entry) # 获取所有目录的路径并按路径长度从长到短排序 sorted_paths = sorted(contents.keys(), key=len, reverse=True) # 初始化树的 SHA-1 哈希（根树的哈希值将会保存在这里） sha = None # 遍历排序后的路径（目录），构建树对象 for path in sorted_paths: tree = GitTree() # 创建一个新的空树对象 # 遍历该目录下的条目，生成树叶并添加到树中 for entry in contents[path]: if isinstance(entry, GitIndexEntry): # 普通的文件条目 # 转换文件的权限模式，Git 使用十六进制表示，树对象需要的是八进制 ASCII 字符串 leaf_mode = f\u0026#34;{entry.mode_type:02o}{entry.mode_perms:04o}\u0026#34;.encode(\u0026#34;ascii\u0026#34;) leaf = GitTreeLeaf(mode=leaf_mode, path=os.path.basename(entry.name), sha=entry.sha) else: # 子目录条目（树） leaf = GitTreeLeaf(mode=b\u0026#34;040000\u0026#34;, path=entry[0], sha=entry[1]) tree.items.append(leaf) # 将叶子添加到树对象中 # 将生成的树对象写入对象存储，并获取其 SHA-1 哈希 sha = object_write(tree, repo) # 将树对象的哈希值添加到其父目录的内容列表中，作为一对 (文件名, SHA) parent = os.path.dirname(path) # 获取父目录路径 base = os.path.basename(path) # 获取当前目录的名称（例如 \u0026#34;main.go\u0026#34;） contents[parent].append((base, sha)) # 将父目录与新生成的树的哈希值关联 return sha # 返回根树的 SHA-1 哈希 def commit_create(repo, tree, parent, author, timestamp, message): commit = GitCommit() # 创建一个新的提交对象 # 设置提交对象的树字段为当前提交的树对象的 SHA-1 值 commit.kvlm[b\u0026#34;tree\u0026#34;] = tree.encode(\u0026#34;ascii\u0026#34;) # 如果有父提交，设置父提交字段 if parent: commit.kvlm[b\u0026#34;parent\u0026#34;] = parent.encode(\u0026#34;ascii\u0026#34;) # 清理提交信息，并在末尾加上换行符 message = message.strip() + \u0026#34;\\n\u0026#34; # 格式化时区偏移（例如 \u0026#34;+0200\u0026#34; 或 \u0026#34;-0700\u0026#34;） offset = int(timestamp.astimezone().utcoffset().total_seconds()) # 获取时区偏移（秒） hours = offset // 3600 # 计算小时 minutes = (offset % 3600) // 60 # 计算分钟 tz = \u0026#34;{}{:02}{:02}\u0026#34;.format(\u0026#34;+\u0026#34; if offset \u0026gt; 0 else \u0026#34;-\u0026#34;, hours, minutes) # 格式化时区字符串 # 将作者信息格式化为 \u0026#34;Author Name \u0026lt;email\u0026gt; timestamp timezone\u0026#34; author = author + timestamp.strftime(\u0026#34; %s \u0026#34;) + tz # 设置提交对象的作者和提交者字段为相同的值 commit.kvlm[b\u0026#34;author\u0026#34;] = author.encode(\u0026#34;utf8\u0026#34;) commit.kvlm[b\u0026#34;committer\u0026#34;] = author.encode(\u0026#34;utf8\u0026#34;) # 设置提交信息字段 commit.kvlm[None] = message.encode(\u0026#34;utf8\u0026#34;) # 将提交对象写入对象存储，并返回其 SHA-1 哈希 return object_write(commit, repo) Git二连击可视化 已经了解了上面的底层原理后，对Git两连击的的可视化也就十分简单了，详见下图，参考这才是真正的Git——Git内部原理揭秘！： 现在，😮‍💨，所有Git基础的内容的底层原理以及其代码形式差不多就讲解完了。还有一些比较高级的Git内容我们留待后文。\nGit常用命令进阶 我们已经可视化了Git两连击中细节，下面我们可以从高层次的视角（GitCommit）来对Git中的高阶常用命令进行可视化，可视化结果由Learn Git Branch提供。我们经过一系列的git add和git commit以及git checkout之后得到的初始的GitCommit的分布情况如图7所示。\n图7：初始GitCommit分布情况 接下来先介绍的4个命令的联系如图8所示：\n图8：git reset、git checkout、git add和 git commit的联系 git add和git commit 命令我们已经详细介绍过了，下面再简要对对这4个命令进行叙述。\ngit add files 把当前文件放入暂存区域。 git commit -m message 给暂存区域生成快照并提交，而git commit -a -m message自动将所有被跟踪的文件的更改暂存并提交，省略了git add的步骤。 git reset files 用来撤销最后一次git add files，你也可以用git reset 撤销所有暂存区域文件。 git checkout files 把文件从暂存区域复制到工作目录，用来丢弃本地修改，而git checkout HEAD files 用来将工作目录中指定文件恢复到当前分支最新一次提交时的状态（即 HEAD 指针指向的提交）。这相当于丢弃对这些文件的所有未提交修改，恢复到上一次提交的版本。 git checkout 分支参数 checkout命令用于从历史提交（或者暂存区域）中拷贝文件到工作目录，也可用于切换分支。当不指定文件名，而是给出一个（本地）分支时，那么HEAD标识会移动到那个分支（也就是说，我们“切换”到那个分支了），然后暂存区域和工作目录中的内容会和HEAD对应的提交节点一致。新提交节点（下图中的C1）中的所有文件都会被复制（到暂存区域和工作目录中）；只存在于老的提交节点（C5）中的文件会被删除；不属于上述两者的文件会被忽略，不受影响。(分支在.git文件夹中对应.git/refs/heads/中的文件，HEAD对应.git文件夹中的HEAD文件，git checkout stable将HEAD文件内容由ref: refs/heads/main改变成ref: refs/heads/stable同时暂存区和工作目录也会发生变化)\n图9：git checkout stable将分支从main转换到stable 被分离的HEAD标识 如果既没有指定文件名，也没有指定分支名，而是一个标签、远程分支、SHA-1值或者是像main~3类似的东西，就得到一个匿名分支，称作detached HEAD（被分离的HEAD标识），暂存区域和工作目录中的内容会和HEAD对应的提交节点一致。\n图10：git checkout main~3将HEAD分离出来 HEAD处于分离状态时，提交操作可以正常进行如图11所示，但是不会更新任何已命名的分支。(你可以认为这是在更新一个匿名分支。)一旦此后你切换到别的分支，比如说main，那么这个提交节点（可能）再也不会被引用到，然后就会被丢弃掉了，如图12所示。\n图11：HEAD标识处于分离状态时的提交操作 图12：git checkout main运行后之前提交节点的情况 但是，如果你想保存这个状态，可以用命令git checkout -b name来创建一个新的分支，如图13所示。\n图13：git checkout -b new运行后可以保存提交状态 git reset reset命令把当前分支指向另一个位置，并且有选择的变动工作目录和索引。也用来在从历史仓库中复制文件到索引，而不动工作目录。\n如果不给选项，移动HEAD到指定的提交，并且将更改从暂存区移除，但保留在工作目录中（需要git add和git commit）。如果用--hard选项，移动HEAD到指定的提交，并且重置暂存区和工作目录，如果用--soft选项，仅仅移动HEAD到指定的提交，但保留工作区和暂存区的更改（仅需要git commit）。\n图14：现将HEAD指向main分支再运行git reset main~3后的情况 如果没有给出提交点的版本号，那么默认用HEAD。这样，分支指向不变，但是索引会回滚到最后一次提交，如果用--hard选项，工作目录也同样。\ngit merge merge 命令把不同分支合并起来。合并前，索引必须和当前提交相同。如果另一个分支是当前提交的祖父节点，那么合并命令将什么也不做。 另一种情况是如果当前提交是另一个分支的祖父节点，就导致fast-forward合并。指向只是简单的移动，并生成一个新的提交。\n图14：运行git merge main前的情况 图15：运行git merge main后的情况，快速前进 否则就是一次真正的合并。默认把当前提交(C5 如下所示)和另一个提交(C7)以及他们的共同祖父节点(C2)进行一次三方合并。结果是先保存当前目录和索引，然后和父节点C7一起做一次新提交。\n图16：运行git merge main前的情况 图17：运行git merge main后的情况，正宗融合 git cherry-pick git cherry-pick命令\u0026quot;复制\u0026quot;一个提交节点并在当前分支做一次完全一样的新提交，暂存区和工作目录都发生改变。\n图18：运行git cherry-pick C4之前的情况 图19：运行git cherry-pick C4之后的情况，复制C4在当前main分支下做一次完全相同的提交 ### `git rebase` 衍合是合并命令的另一种选择。合并把两个父分支合并进行一次提交，提交历史不是线性的。衍合在当前分支上重演另一个分支的历史，提交历史是线性的。 本质上，这是线性化的自动的 cherry-pick。\n图20：运行git rebase bugFix之前的情况 图21：运行git rebase bugFix之后的情况 Git本地仓库连接并上传远程仓库 使用ssh密钥将本地git和远程GitHub配对 参考https://zhuanlan.zhihu.com/p/138305054\n本地上传远程6步走战略 git init：将文件夹设置为本地仓库，只有这样才可以把本地的文件传入github仓库。 git remote add origin git@github.com:yourusername/yourprojectname.git：将本地仓库与github仓库进行关联。 git pull origin main(or master)：将GitHub上仓库的内容pull到本地仓库，两者保持一致。 git add：需要上传的文件 添加文件到本地库。（再次上传就是3步走战略） git commit -m “information”：提交文件到本地库。（再次上传就是3步走战略） git push origin main(or master)：上传文件。（再次上传就是3步走战略） 参考网站 Write yourself a Git! 这才是真正的Git——Git内部原理揭秘！ Learn Git Branch ","permalink":"https://fordelkon.github.io/posts/git_intro/","summary":"\u003cp\u003e这篇博客主要自底向上地介绍Git命令行，有时甚至会使用一些\u003ccode\u003epython\u003c/code\u003e代码来对一些Git的功能进行更加详细的分析。我一直认为基础一旦打好，那么一些更高级的用法也可以循序渐进地了解，而且是更加透彻的了解。不是像博主一开始那样以为只要死记硬背\u003ccode\u003egit add\u003c/code\u003e，\u003ccode\u003egit commit\u003c/code\u003e,\u003ccode\u003egit pull\u003c/code\u003e，\u003ccode\u003egit clone\u003c/code\u003e等常见命令的一些用法就可以了😭（实际上网上大多数教程就是这样教的\u0026hellip;），在这上面走了不少弯路，所以从头开始打地基写作此文留以警示⚠️。\u003c/p\u003e\n\u003c!-- more --\u003e\n\u003ch2 id=\"git仓库git-repository\"\u003eGit仓库（Git Repository）\u003c/h2\u003e\n\u003cp\u003e要学习Git，首先我们要知道我们运行Git命令是对什么对象进行操作的，在Git的相关术语中，我们把这个对象叫做Git仓库（Git Repository），Git仓库实际上就是一个文件夹，在这个文件夹里我们通过.git文件夹（隐藏文件夹）对Git仓库中的工作区中的文件（非隐藏文件夹）内容的改变进行记录，当然并不是所有非隐藏文件夹中文件的改变都会被记录，被.gitingore文件所标识的文件被改变后.git文件夹不会对其进行记录。根据我上面所说，\u003cfont color=\"#c00000\"\u003eGit操作最隐晦的地方就在于对于.git文件夹中内容的修改来保证对于Git仓库非隐藏文件夹中文件内容修改的记录\u003c/font\u003e。\u003c/p\u003e\n\u003cp\u003e根据上面的描述，我们可以得到一下简略的公式：\u003c/p\u003e\n\u003cdiv\u003e\n$$\\mathrm{Git}\\ \\mathrm{Repository} = \\mathrm{.git}\\ \\mathrm{folder} + \\mathrm{worktree}\\ \\mathrm{folder}\\tag{1}$$\n\u003c/div\u003e\n\u003cp\u003e更加详尽的来说以\u003ccode\u003epython\u003c/code\u003e来构建Git仓库类：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eGitRepository\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eobject\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u0026#34;A git repository\u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eworktree\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003egitdir\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epath\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eworktree\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epath\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egitdir\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eos\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epath\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejoin\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epath\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;.git\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"git文件夹内部结构探究\"\u003e.git文件夹内部结构探究\u003c/h2\u003e\n\u003cp\u003e前面我们已经知道了\u003cfont color=\"#ff0000\"\u003eGit操作最隐晦的地方就在于对于.git文件夹中内容的修改来保证对于Git仓库非隐藏文件夹中文件内容修改的记录\u003c/font\u003e，那接下来我们就要对此进行脱贫攻坚了。由于.git是隐藏文件夹，所以我们要先对.git文件夹中的文件分布有一定的了解，\u003ccode\u003egit init\u003c/code\u003e初始化后的.git文件夹中的文件分布如图1所示，此时Git仓库内除了.git文件夹之外一片荒芜。\u003c/p\u003e\n\u003ccenter\u003e\n  \u003cimg src=\"./img/gitinit.png\" alt=\"图片1\" width=\"400\"\u003e\n\u003c/center\u003e\n\u003ccenter\u003e\n\u003cstrong\u003e图1：运行git init之后.git文件夹的文件分布结构\u003c/strong\u003e\n\u003c/center\u003e\n\u003cp\u003e然后我们再本地Git仓库中添加可见文件，添加后的结果如图2所示。\u003c/p\u003e\n\u003ccenter\u003e\n  \u003cimg src=\"./img/add.png\" alt=\"图片1\" width=\"400\"\u003e\n\u003c/center\u003e\n\u003ccenter\u003e\n\u003cstrong\u003e图2：Git仓库添加文件后的文件分布\u003c/strong\u003e\n\u003c/center\u003e\n\u003cp\u003e将上述所有文件运行\u003ccode\u003egit add\u003c/code\u003e之后在进行\u003ccode\u003egit commit\u003c/code\u003e观察.git文件夹中的文件分布，如图3所示。可以看到相较于最初的.git文件，我们在\u003ccode\u003egit add\u003c/code\u003e和\u003ccode\u003egit commit\u003c/code\u003e之后文件夹中多出了\u003ccode\u003eindex\u003c/code\u003e文件，\u003ccode\u003elog\u003c/code\u003e文件夹，\u003ccode\u003eobjects\u003c/code\u003e文件夹中的8个文件以及\u003ccode\u003erefs/heads\u003c/code\u003e下的\u003ccode\u003emain\u003c/code\u003e文件，其他的一些变化我们不做考虑。\u003cfont color=\"#ff0000\"\u003e有果导因我们可以知道.git文件夹内部的这些变化中有对于Git仓库非隐藏文件夹文件修改的记录。\u003c/font\u003e\u003c/p\u003e\n\u003ccenter\u003e\n  \u003cimg src=\"./img/gitaddcommit.png\" alt=\"图片1\" width=\"400\"\u003e\n\u003c/center\u003e\n\u003ccenter\u003e\n\u003cstrong\u003e图3：运行git add和git commit之后.git文件夹的文件分布结构\u003c/strong\u003e\n\u003c/center\u003e\n\u003ch2 id=\"git对象git-object\"\u003eGit对象（Git Object）\u003c/h2\u003e\n\u003cp\u003e上面的变化究竟是如何实现的呢？要知道Git中的几乎一切都被存储为Git对象！也就是说我们可以通过Git对象进行操作来完成上面的变化。说了这么多，让我们来为Git对象下一个比较官方的定义：\u003cfont color=\"#ff0000\"\u003eGit对象就是在 Git 仓库中的文件，它们的路径由它们的内容决定。\u003c/font\u003e\u003c/p\u003e\n\u003cp\u003eGit对象范性可以借由\u003ccode\u003epython\u003c/code\u003e来实现：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eGitObject\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eobject\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"o\"\u003e!=\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edeserialize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003einit\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eserialize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u0026#34;将对象转变为zip文件解压缩后的byte格式\u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eraise\u003c/span\u003e \u003cspan class=\"ne\"\u003eException\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Unimplemented!\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003edeserialize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\t\u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u0026#34;data通常为zip文件解压缩后的byte格式，根据类型解码\u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eraise\u003c/span\u003e \u003cspan class=\"ne\"\u003eException\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Unimplemented!\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003einit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003epass\u003c/span\u003e \u003cspan class=\"c1\"\u003e# Just do nothing. This is a reasonable default!\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eGit对象又细分为以下四种类型：GitBlob（Binary Large Object）对象， GitCommit对象， GitTree对象， GitTag对象，以下分别进行介绍。\u003c/p\u003e","title":"Git详解"},{"content":"在深度学习中我们通常使用具有良好数学性质的概率分布对已有数据分布进行建模，以便得到优美的损失函数形式方便模型进行反向传播，同时赋予模型实际的概率含义。在该章节中我们介绍深度学习中常用的概率分布以及不同概率分布之间的距离度量方法。假设我们已有数据集$ \\mathcal{D}=\\lbrace(\\mathbf{x}_{i}, y_{i})\\rbrace_{i=1}^{N} $或$ \\mathcal{D}=\\lbrace\\mathbf{x}_{i}\\rbrace_{i=1}^{N} $，主要区分于有标签和无标签的情况，$ z $或$ \\mathbf{z}$ 主要表示深度学习模型未经处理的输出。\n常用概率分布 连续随机变量分布 正态分布（单变量） $$ y\\sim\\mathcal{N}(z, \\sigma^2)\\tag{1-1} $$ $$ p(y\\mid z) = \\frac{1}{\\sqrt{ 2\\pi \\sigma^2 }}\\exp\\Big[ -\\frac{(y-z)^2}{2\\sigma^2}\\Big]\\tag{1-2} $$ 单变量正态分布概率密度函数曲线如图所示：\n上述条件概率经过$ \\log $化取负之后化简其对应的损失函数\n$$ \\begin{align} \\arg\\min -\\log p(y\\mid z) \u0026= \\arg\\min \\Big[\\frac{1}{2}\\log [ 2\\pi \\sigma^2] + \\frac{(y - z)^2}{2\\sigma^2}\\Big] \\\\ \u0026= \\arg\\min [(y - z)^2] \\quad (\\sigma\\: is \\: constant) \\end{align}\\tag{1-3} $$ 正态分布（多变量） $$ \\mathbf{y}\\sim \\mathcal{N}(\\mathbf{z}, \\Sigma)\\tag{2-1} $$ $$ p(\\mathbf{y}\\mid \\mathbf{z}) = \\frac{1}{(2\\pi)^{K/2}|\\Sigma|^{1/2}}\\exp\\Big[ -\\frac{(\\mathbf{y}-\\mathbf{z})^{\\mathrm{T}}\\Sigma^{-1}(\\mathbf{y}-\\mathbf{z})}{2}\\Big]\\tag{2-2} $$ 二维正态分布概率密度等高线如图所示\n同理，上述条件概率经过$ \\log $化取负之后化简得到其对应的损失函数\n$$ \\begin{align} \\arg\\min -\\log p(\\mathbf{y}\\mid \\mathbf{z}) \u0026= \\arg\\min \\left[\\frac{K}{2}\\log[2\\pi] + \\frac{1}{2}\\log |\\Sigma| + \\frac{1}{2}(\\mathbf{y} - \\mathbf{z})^\\mathrm{T}\\Sigma^{-1}(\\mathbf{y} - \\mathbf{z})\\right] \\\\ \u0026= \\arg\\min \\left[\\frac{K}{2}\\log[2\\pi \\sigma^2] + \\frac{1}{2\\sigma^2}\\lvert \\lvert \\mathbf{y} - \\mathbf{z} \\rvert \\rvert^2 \\right]\\quad (\\Sigma = \\sigma^2\\mathbf{I}) \\\\ \u0026= \\arg\\min \\left[\\lvert \\lvert \\mathbf{y} - \\mathbf{z} \\rvert \\rvert^2 \\right]\\quad (\\sigma\\:is\\: constant) \\end{align}\\tag{2-3} $$ 混合高斯分布 $$ y\\sim \\mathrm{GMM}(\\mathbf{z},\\boldsymbol{\\sigma}^2)\\quad\\mathbf{z}=[z_{1}, \\dots, z_{K}]^{\\mathrm{T}}\\tag{3-1} $$ $$ p(y\\mid\\mathbf{z}) = \\sum_{k=1}^{K}\\pi_{k}\\mathcal{N}(y\\mid z_{k}, \\sigma_{k}^2)\\tag{3-2} $$ 上述公式中$ \\pi_{k} $是第$ k $个高斯分布的权重，满足$ \\sum_{k=1}^{K}\\pi_{k}=1 $，$ \\mathcal{N}(y\\mid z_{k}, \\sigma_{k}^2) $是第$ k $个高斯分布的概率密度。\n混合高斯分布的概率分布密度如图所示。\n上述条件概率经过$ \\log $化之后取负得到的损失函数为\n$$ \\begin{align} \\arg\\min -\\log p(y\\mid \\mathbf{z}) \u0026= \\arg\\min -\\log \\left[\\sum_{k=1}^K\\pi_{k}\\frac{1}{\\sqrt{ 2\\pi \\sigma_{k}^2 }}\\exp\\left[-\\frac{(y - z_{k})^2}{2\\sigma_{k}^2}\\right]\\right]\\quad \\mathrm{log\\text{-}sum\\text{-}exp\\:construct} \\\\ \u0026= \\arg\\min -\\log \\sum_{k=1}^K\\exp[a_{k}]\\quad \\left( a_{k} = \\log \\pi_{k} - \\frac{1}{2}\\log[2\\pi \\sigma_{k}^2] - \\frac{(y - z_{k})^2}{2\\sigma_{k^2}} \\right) \\\\ \u0026= \\arg\\min -m -\\log \\sum_{k=1}^K\\exp[a_{k} - m]\\quad \\left(m = \\max_k a_{k}\\right) \\end{align}\\tag{3-3} $$ $ \\mathrm{Laplace} $分布 $$ y\\sim \\mathrm{Laplace}(z, b)\\tag{4-1} $$ $$ p(y\\mid z) = \\frac{1}{2b}\\exp\\Big[ -\\frac{|y - z|}{b}\\Big]\\tag{4-2} $$ $ \\mathrm{Laplace} $分布概率密度分度如图所示，$ \\mu $是位置参数控制分布中心，$ b $是尺度参数控制分布的宽度。\n上述条件概率分布经过$ \\log $化之后取负对数得到对应的损失函数为\n$$ \\begin{align} \\arg\\min -\\log p(y\\mid z) \u0026= \\arg\\min\\log(2b) + \\frac{\\lvert y - z \\rvert}{b} \\end{align}\\tag{4-3} $$ $ \\mathrm{t}分布 $ $$ y\\sim \\mathrm{t}(\\nu, \\mathbf{z})\\quad \\mathbf{z}=[z_{1}, z_{2}]^{\\mathrm{T}}\\tag{5-1} $$ $$ p(y \\mid \\mathbf{z}) = \\frac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\sqrt{\\nu \\pi}\\, \\sigma \\, \\Gamma\\left(\\frac{\\nu}{2}\\right)} \\left[ 1 + \\frac{1}{\\nu} \\left(\\frac{y-z_{1}}{\\exp[z_{2}]}\\right)^2 \\right]^{-\\frac{\\nu+1}{2}}\\tag{5-2} $$ $ \\mathrm{t} $分布概率密度如图所示，其中$ \\mu $依旧表示位置参数，$ \\sigma\u0026gt;0 $表示尺度参数，$ \\nu\u0026gt;0 $表示自由度\n`$ \\mathrm{t} $`分布和正态分布（单变量）的概率密度函数在不同自由度对比如下 上述条件分布`$ \\log $`化之后取负值得到对应的损失函数为 $$ \\begin{align} \\arg\\min -\\log p(y\\mid \\mathbf{z}) \u0026= \\arg\\min z_{2} + \\frac{\\nu + 1}{2}\\log \\left(1 + \\frac{1}{\\nu}\\frac{\\left(y - z_{1}\\right)^2}{\\exp[2z_{2}]}\\right) + C \\quad \\left(C = -\\log\\Gamma\\left(\\tfrac{\\nu+1}{2}\\right)+\\log\\Gamma\\left(\\tfrac{\\nu}{2}\\right)+\\frac{1}{2}\\log(\\nu\\pi)\\right) \\\\ \u0026= \\arg\\min z_{2} + \\frac{\\nu + 1}{2}\\log \\left(1 + \\frac{1}{\\nu}\\frac{\\left(y - z_{1}\\right)^2}{\\exp[2z_{2}]}\\right) \\end{align}\\tag{5-3} $$ 指数分布 $$ y\\sim \\mathrm{Exponential}\\left( \\frac{1}{\\exp[z]} \\right) \\tag{6-1} $$ $$ p(y\\mid z) = \\begin{cases} \\frac{1}{\\exp[z]} \\exp\\left[ -\\frac{y}{\\exp[z]} \\right], \u0026 y \\geq 0 \\\\ 0, \u0026 y \u003c 0 \\end{cases}\\tag{6-2} $$ 指数分布的概率密度如图所示\n上述条件分布`$ \\log $`化之后取负值得到对应的损失函数为 $$ \\begin{align} \\arg\\min -\\log p(y\\mid z) \u0026= \\arg\\min z + y\\exp[-z] \\quad (y \\geq 0) \\end{align}\\tag{6-3} $$ $ \\mathrm{gamma}分布 $ $$ y\\sim \\mathrm{Gamma}(\\mathbf{z})\\quad \\mathbf{z}=[z_{1}, z_{2}]^{\\mathrm{T}}\\tag{7-1} $$ $$ p(y\\mid \\mathbf{z}) = \\begin{cases} \\frac{1}{\\Gamma(\\exp(z_{1}))\\exp[z_{2}]^{\\exp[z_{1}]}}y^{\\exp[z_{1}] - 1}\\exp\\left[ -\\frac{y}{\\exp[z_{2}]} \\right]\u0026y \\geq 0\\\\ 0, \u0026y \u003c 0 \\end{cases} $$ $ \\mathrm{gamma} $分布的概率密度如图所示，其中$ k\u0026gt;0 $表示形状参数，$ \\theta\u0026gt;0 $表示尺度参数。\n上述条件分布`$ \\log $`化之后取负值得到对应的损失函数为 $$ \\begin{align} \\arg\\min -\\log p(y\\mid \\mathbf{z}) \u0026= \\arg\\min \\log \\Gamma(\\exp[z_{1}]) + \\exp[z_{1}]z_{2} - (\\exp[z_{1}] - 1)\\log y + y\\exp[-z_{2}] \\quad (y \\geq 0) \\end{align}\\tag{7-3} $$ $ \\mathrm{beta}分布 $ $$ y\\sim \\mathrm{Beta}(\\mathbf{z})\\quad \\mathbf{z}=[z_{1}, z_{2}]^{\\mathrm{T}}\\tag{8-1} $$ $$ p(y\\mid \\mathbf{z}) = \\frac{1}{\\mathrm{B}(\\exp[z_{1}], \\exp[z_{2}])}y^{\\exp[z_{1}] - 1}(1-y)^{\\exp[z_{2}] - 1}\\tag{8-2} $$ $ \\mathrm{beta} $分布的概率密度函数如下所示，其中$ \\alpha\u0026gt;0, \\beta\u0026gt;0 $都表示形状参数\n上述条件分布$ \\log $化之后取负值得到对应的损失函数为\n$$ \\begin{aligned} \\arg\\min -\\log p(y\\mid \\mathbf{z}) \u0026= \\arg\\min\\underbrace{\\log \\Gamma(\\exp[z_{1}]) + \\log \\Gamma(\\exp[z_{2}]) - \\log \\Gamma(\\exp[z_{1}] + \\exp[z_{2}])}_{\\log \\mathrm{B(\\exp[z_{1}], \\exp[z_{2}])}} - (\\exp[z_{1}] - 1)\\log y - (\\exp[z_{2}] - 1)\\log(1 - y) \\\\ \u0026= \\arg\\min\\log \\mathrm{B}(\\exp[z_{1}], \\exp[z_{2}]) - (\\exp[z_{1}] - 1)\\log y - (\\exp[z_{2}] - 1)\\log(1 - y) \\quad (y \\geq 0) \\end{aligned}\\tag{8-3} $$ 离散随机变量分布 $ \\mathrm{Possion} $分布 $$ y\\sim \\mathrm{Possion}(\\exp[z])\\tag{9-1} $$ $$ p(y|z) = \\frac{\\exp[z]^{y}\\exp[-\\exp[z]]}{y!}\\tag{9-2} $$ 上述条件分布$ \\log $化之后取负值得到对应的损失函数为\n$$ \\begin{align} \\arg\\min -\\log p(y\\mid z) \u0026= \\arg\\min\\exp[z] - z\\exp[z] + C \\quad (C = \\log[y!])\\\\ \u0026= \\arg\\min\\exp[z] - z\\exp[z] \\end{align}\\tag{9-3} $$ $ \\mathrm{Bernoulli} $分布 $$ y\\sim \\mathrm{Bernoulli}(\\mathrm{sigmoid}(z))\\tag{10-1} $$ $$ p(y\\mid z) = \\mathrm{sigmoid}(z)^{y}(1 - \\mathrm{sigmoid}(z))^{1-y}\\tag{10-2} $$ 分类分布 $$ p(y\\mid\\mathbf{z})=\\mathrm{softmax}_{y}(\\mathbf{z})=\\frac{\\exp[z_{y}]}{\\sum_{y'=1}^{K}\\exp[z_{y'}]}\\tag{11-1} $$ 不同概率之间的距离 $ \\mathrm{Kullback-Leibler} $散度（$ \\mathrm{KL} $散度） $ \\mathrm{KL} $散度是一种衡量两个概率分布差异的指标。概率分布$ p(y) $和概率分布$ q(y) $之间的距离可以用$ \\mathrm{KL} $散度来进行评估\n$$ \\mathrm{D}_{\\mathrm{KL}}[p(y)||q(y))] = \\int_{-\\infty}^{\\infty}p(y)\\log[p(y)]dy - \\int_{-\\infty}^{\\infty}p(y)\\log[q(y)]dy $$ 两个多维正态分布之间的$ \\mathrm{KL} $散度，其中$ D $表示多维正态分布的维度数量\n$$ \\mathrm{D}_{\\mathrm{KL}}[\\mathcal{N}(\\boldsymbol{\\mu}_{1}, \\boldsymbol{\\Sigma}_{1})||\\mathcal{N}(\\boldsymbol{\\mu}_{2}, \\boldsymbol{\\Sigma}_{2})] = \\frac{1}{2}\\left( \\log\\left[ \\frac{|\\boldsymbol{\\Sigma}_{2}|}{|\\boldsymbol{\\Sigma}_{1}|}\\right] - D + \\mathrm{tr}[\\boldsymbol{\\Sigma}_{2}^{-1}\\boldsymbol{\\Sigma}_{1}] + (\\boldsymbol{\\mu}_{2} - \\boldsymbol{\\mu}_{1})^{\\mathrm{T}}\\boldsymbol{\\Sigma}_{2}^{-1}(\\boldsymbol{\\mu}_{2} - \\boldsymbol{\\mu}_{1})\\right) $$ $ \\mathrm{Jensen-Shannon} $散度（$ \\mathrm{JS} $散度） $ \\mathrm{KL} $散度是反对称的($ \\mathrm{D}_{\\mathrm{KL}}[p(y)||q(y)]\\neq \\mathrm{D}_{\\mathrm{KL}}[q(y)||p(y)] $)，但是距离通常是对称的，因此通过$ \\mathrm{KL} $散度来构造一个对称化的距离度量$ \\mathrm{JS} $散度\n$$ \\mathrm{D}_{\\mathrm{JS}}[p(y)||q(y)] = \\frac{1}{2}\\mathrm{D}_{\\mathrm{KL}}\\left[ p(y)||\\frac{p(y) + q(y)}{2} \\right] + \\frac{1}{2}\\mathrm{D}_{\\mathrm{KL}}\\left[ q(y)||\\frac{p(y) + q(y)}{2} \\right] $$ 它的物理意义是$ p(y) $和$ q(y) $对两个分布平均值的平均散度。\n$ \\mathrm{Fréchet} $ 距离 两个概率分布$ p(y) $和$ q(y) $的$ \\mathrm{Fréchet} $ 距离的数学形式如下所示\n$$ \\mathrm{D}_{\\mathrm{Fr}}[p(x)||q(y)] = \\sqrt{ \\min_{\\pi(x,y)}\\left[\\int \\int \\pi(x, y)|x - y|^2dxdy \\right] } $$ 其中$ \\pi(x, y) $表示边缘分布$ p(x) $和$ q(y) $相容的联合分布集合。$ \\mathrm{Fréchet} $ 距离也可以被表述为累积分布曲线之间的最大距离的度量。\n两个多维正态分布之间的$ \\mathrm{Fréchet} $ 距离\n$$ \\mathrm{D}_{\\mathrm{Fr}/W_{2}}[\\mathcal{N}(\\boldsymbol{\\mu}_{1}, \\boldsymbol{\\Sigma}_{1})||\\mathcal{N}(\\boldsymbol{\\mu}_{2}, \\boldsymbol{\\Sigma}_{2})] = |\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{2}|^2 + \\mathrm{tr}[\\boldsymbol{\\Sigma}_{1} + \\boldsymbol{\\Sigma}_{2} - 2(\\boldsymbol{\\Sigma}_{2}\\boldsymbol{\\Sigma}_{1})^{1/2}] $$ ","permalink":"https://fordelkon.github.io/teaching/probdis/","summary":"\u003cp\u003e在深度学习中我们通常使用具有良好数学性质的概率分布对已有数据分布进行建模，以便得到优美的损失函数形式方便模型进行反向传播，同时赋予模型实际的概率含义。在该章节中我们介绍深度学习中常用的概率分布以及不同概率分布之间的距离度量方法。假设我们已有数据集\u003ccode\u003e$ \\mathcal{D}=\\lbrace(\\mathbf{x}_{i}, y_{i})\\rbrace_{i=1}^{N} $\u003c/code\u003e或\u003ccode\u003e$ \\mathcal{D}=\\lbrace\\mathbf{x}_{i}\\rbrace_{i=1}^{N} $\u003c/code\u003e，主要区分于有标签和无标签的情况，\u003ccode\u003e$ z $\u003c/code\u003e或\u003ccode\u003e$ \\mathbf{z}$ \u003c/code\u003e主要表示深度学习模型未经处理的输出。\u003c/p\u003e","title":"深度学习中常用的概率分布总结"},{"content":"上面我们实现了CMake的一套简要搭建流程，基本上简单的编译配置就靠上面的几个CMake命令就可以完成了。但一些大型项目的cmake的配置光靠上面的几个CMake命令是远远不够的，简单来说如何导入第三方库，嗯这就属于CMake进阶的内容了\u0026hellip;\nCMakeLists.txt语法 本地变量、缓存变量、环境变量（变量） 变量通常通过set()来进行声明，set()命令语法如下：\n# 声明本地变量 set(\u0026lt;variable\u0026gt; \u0026lt;values\u0026gt;) 参数： \u0026lt;variable\u0026gt; ：要设置的本地变量名称。 \u0026lt;values\u0026gt; ：变量的值（单个或多个），多个值时它们使用`;`拼接成一个字符串。 # 声明缓存变量 set(\u0026lt;variable\u0026gt; \u0026lt;value\u0026gt; CACHE \u0026lt;STRING|BOOL|PATH|FILEPATH\u0026gt; \u0026lt;description\u0026gt;) 参数： \u0026lt;variable\u0026gt; ：要设置的缓存变量名称。 \u0026lt;value\u0026gt; ：缓存变量的值（值的具体含义由后边的选择参数决定）。 \u0026lt;STRING|BOOL|PATH|FILEPATH\u0026gt; ： - STRING ：普通字符串变量。 - BOOL ：布尔类型变量，取值可以是 ON、OFF。 - PATH ：路径变量，用于存储目录路径。 - FILEPATH ：文件路径变量，用于存储文件的完整路径。 \u0026lt;description\u0026gt; ：该缓存变量的字符串描述。 # 声明环境变量 set(ENV{variable} value) # 最好不要乱设置 该测试对应的源代码所在目录详见https://github.com/fordelkon/cmake_tutorial/tree/main/advanced_process/cmake_var。测试的CMakeLists.txt内容如下：\n# 指定最小Cmake的版本要求 cmake_minimum_required(VERSION 3.9) # 设置项目名称 project(CMAKE_VARIABLES) # 本地变量 set(LOCAL_VAR \u0026#34;value\u0026#34;) set(LOCAL_LIST \u0026#34;value1\u0026#34; \u0026#34;value2\u0026#34;) message(\u0026#34;LOCAL_VAR is ${LOCAL_VAR}, LOCAL_LIST is ${LOCAL_LIST}\u0026#34;) # 缓存变量 set(CACHE_VAR_BOOL ON CACHE BOOL \u0026#34;this is a bool cache variable\u0026#34;) set(CACHE_VAR_STRING \u0026#34;cache value\u0026#34; CACHE STRING \u0026#34;this is a string variable\u0026#34;) message(\u0026#34;CACHE_VAR_BOOL is ${CACHE_VAR_BOOL}, CACHE_VAR_STRING is ${CACHE_VAR_STRING}\u0026#34;) # 环境变量 message(\u0026#34;My PC shell is $ENV{SHELL}\u0026#34;) 在CMakeLists.txt所在的目录下运行cmake -B build得到\n-- The C compiler identification is AppleClang 16.0.0.16000026 -- The CXX compiler identification is AppleClang 16.0.0.16000026 -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/cc - skipped -- Detecting C compile features -- Detecting C compile features - done -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/c++ - skipped -- Detecting CXX compile features -- Detecting CXX compile features - done LOCAL_VAR is value, LOCAL_LIST is value1;value2 CACHE_VAR_BOOL is ON, CACHE_VAR_STRING is cache value My PC shell is /bin/zsh -- Configuring done (0.4s) -- Generating done (0.0s) -- Build files have been written to: /Users/delkon/Desktop/UniversityWork/Year4/CMake_Art/advanced_process/cmake_var/build 修改LOCAL_VAR为changes value，CACHE_VAR_BOOL为OFF，再次运行cmake -B build得到\nLOCAL_VAR is changes value, LOCAL_LIST is value1;value2 CACHE_VAR_BOOL is ON, CACHE_VAR_STRING is cache value My PC shell is /bin/zsh -- Configuring done (0.0s) -- Generating done (0.0s) -- Build files have been written to: /Users/delkon/Desktop/UniversityWork/Year4/CMake_Art/advanced_process/cmake_var/build 可以看到LOCAL_VAR被改变了，但是CACHE_VAR_BOOL由于在./build/CMakeCache.txt被缓存所以没有发生改变。\nCMake运行其他的程序 find_package() find_package()是 CMake 中用于查找外部库或包的命令，有两种查找外部库或包的模式：\nConfig 模式：通过包自带的配置文件（如 \u0026lt;package_name\u0026gt;Config.cmake 或 \u0026lt;package_name\u0026gt;-config.cmake）查找库。现代 CMake 项目通常提供这些配置文件。 Module 模式：通过 CMake 自带的查找模块（如 Find\u0026lt;package_name\u0026gt;.cmake）来查找库。早期的 CMake 使用这种方式查找库。 find_package(\u0026lt;package_name\u0026gt; [version] [REQUIRED] [QUIET] [COMPONENTS components] [OPTIONAL_COMPONENTS components]) 参数： \u0026lt;package_name\u0026gt; ：要查找包的名称。 [version] ：指定包的最低版本号（可选）。如果不指定版本号，将查找任意版本的包。 [REQUIRED] ：如果包未找到，则立即停止并给出错误。如果不加 REQUIRED，则会继续执行脚本，即使找不到该包。 [QUIET] ：抑制输出，即使找不到包也不显示消息。 [COMPONENTS components] ：指定包的特定组件，只有这些组件会被查找。用于包含多个模块的包。 [OPTIONAL_COMPONENTS components] ：指定一些可选的组件，如果没有找到这些组件，不会影响主要构建过程。 -------------------------------------------------------------------------------- 查找结果： - \u0026lt;package_name\u0026gt;_FOUND：是否找到包。 - \u0026lt;package_name\u0026gt;_INCLUDE_DIRS：包的头文件路径。 - \u0026lt;package_name\u0026gt;_LIBRARIES：包的库文件路径。 - \u0026lt;package_name\u0026gt;_VERSION：找到的包的版本号。 - \u0026lt;package_name\u0026gt;_EXECUTABLE ：可执行文件的路径。 有时自己的笔记本上有好几个命名相同但版本不同的包，find_package()找到的包和自己预期的路径不太一样，这是我们可以显式地指定\u0026lt;package_name\u0026gt;_EXECUTABLE内容，这样就可以索引到我们想要的包啦。\n该测试对应的源代码所在目录详见https://github.com/fordelkon/cmake_tutorial/tree/main/advanced_process/third_package。相关的测试CMakeLists.txt文件如下：\n# 指定最小Cmake的版本要求 cmake_minimum_required(VERSION 3.9) # 设置项目名称 project(THIRD_PACKAGE) set(FLAG OFF) # or ON if(FLAG) find_package(Python REQUIRED COMPONENTS Interpreter Development) if(Python_FOUND) message(\u0026#34;Package include directory is ${Python_INCLUDE_DIRS}\u0026#34;) message(\u0026#34;Package library is ${Python_LIBRARIES}\u0026#34;) message(\u0026#34;Package version is ${Python_VERSION}\u0026#34;) message(\u0026#34;Package executable file path is ${Python_EXECUTABLE}\u0026#34;) endif() else() set(Python_EXECUTABLE \u0026#34;$ENV{CONDA_PYTHON_EXE}\u0026#34;) find_package(Python REQUIRED COMPONENTS Interpreter Development) if(Python_FOUND) message(\u0026#34;Package include directory is ${Python_INCLUDE_DIRS}\u0026#34;) message(\u0026#34;Package library is ${Python_LIBRARIES}\u0026#34;) message(\u0026#34;Package version is ${Python_VERSION}\u0026#34;) message(\u0026#34;Package executable file path is ${Python_EXECUTABLE}\u0026#34;) endif() endif() 当FLAG为ON时，得到\n....................................前面省略...................................... -- Found Python: /opt/homebrew/Frameworks/Python.framework/Versions/3.13/bin/python3.13 (found version \u0026#34;3.13.0\u0026#34;) found components: Interpreter Development Development.Module Development.Embed Package include directory is /opt/homebrew/opt/python@3.13/Frameworks/Python.framework/Versions/3.13/include/python3.13 Package library is /opt/homebrew/opt/python@3.13/Frameworks/Python.framework/Versions/3.13/lib/libpython3.13.dylib Package version is 3.13.0 Package executable file path is /opt/homebrew/Frameworks/Python.framework/Versions/3.13/bin/python3.13 ....................................后面省略...................................... 这并不是我们想要的包的路径，通过设定FLAG为OFF，显式地指定\u0026lt;package_name\u0026gt;_EXECUTABLE为我们所要的包的可执行文件的内容，运行结果如下：\n....................................前面省略...................................... -- Found Python: /Users/delkon/miniconda3/bin/python (found version \u0026#34;3.10.13\u0026#34;) found components: Interpreter Development Development.Module Development.Embed Package include directory is /Users/delkon/miniconda3/include/python3.10 Package library is /Users/delkon/miniconda3/lib/libpython3.10.dylib Package version is 3.10.13 Package executable file path is /Users/delkon/miniconda3/bin/python ....................................后面省略...................................... 达到了我们的目的。\n配置时运行：execute_process() execute_process( COMMAND \u0026lt;cmd\u0026gt; [args...] [WORKING_DIRECTORY \u0026lt;dir\u0026gt;] [TIMEOUT \u0026lt;seconds\u0026gt;] [RESULT_VARIABLE \u0026lt;var\u0026gt;] [OUTPUT_VARIABLE \u0026lt;var\u0026gt;] [ERROR_VARIABLE \u0026lt;var\u0026gt;] [INPUT_FILE \u0026lt;file\u0026gt;] [OUTPUT_FILE \u0026lt;file\u0026gt;] [ERROR_FILE \u0026lt;file\u0026gt;] [INPUT_FILE \u0026lt;file\u0026gt;] ) 参数： - COMMAND \u0026lt;cmd\u0026gt; [args...] ：指定要执行的命令及其参数。 - WORKING_DIRECTORY \u0026lt;dir\u0026gt; ：设置命令执行时的工作目录。 - TIMEOUT \u0026lt;seconds\u0026gt; ：设置命令执行的超时时间（秒）。 - RESULT_VARIABLE \u0026lt;var\u0026gt; ：命令执行后的返回值会被存储在 \u0026lt;var\u0026gt; 变量中。 - OUTPUT_VARIABLE \u0026lt;var\u0026gt; ：命令标准输出的内容会被存储在 \u0026lt;var\u0026gt; 变量中。 - ERROR_VARIABLE \u0026lt;var\u0026gt; ：命令标准错误的内容会被存储在 \u0026lt;var\u0026gt; 变量中。 - INPUT_FILE \u0026lt;file\u0026gt;：将文件的内容作为输入传递给命令。 - OUTPUT_FILE \u0026lt;file\u0026gt;：将命令的输出保存到指定的文件中。 - ERROR_FILE \u0026lt;file\u0026gt;：将命令的错误信息保存到指定的文件中。 execute_process()是 CMake 中的一个命令，通常用于在 CMake 配置期间调用外部程序或脚本。该测试对应的源代码所在目录详见https://github.com/fordelkon/cmake_tutorial/tree/main/advanced_process/run_cmd。其CMakeLists.txt测试文件如下：\n# 指定最小Cmake的版本要求 cmake_minimum_required(VERSION 3.9) # 设置项目名称 project(THIRD_PACKAGE) execute_process( COMMAND ls WORKING_DIRECTORY ${CMAKE_SOURCE_DIR} OUTPUT_VARIABLE ls_output ) message(\u0026#34;Directory ${CMAKE_SOURCE_DIR} listing: ${ls_output}\u0026#34;) 运行结果如下：\n....................................前面省略...................................... Directory /Users/delkon/Desktop/UniversityWork/Year4/CMake_Art/advanced_process/run_cmd listing: CMakeLists.txt build ....................................后面省略...................................... 构建时运行add_custom_command()（了解一下，不常用） 在构建时运行一条命令有点难。主要是目标系统（target system）使这变的很难，因此这条命令并不常用，所以我们了解该命令一下就可以了。\nadd_custom_command( OUTPUT \u0026lt;out1\u0026gt; [\u0026lt;out2\u0026gt; ...] COMMAND \u0026lt;cmd\u0026gt; [args...] [MAIN_DEPENDENCY \u0026lt;main_dep\u0026gt;] [DEPENDS [\u0026lt;dep\u0026gt; ...]] [BYPRODUCTS \u0026lt;bypro1\u0026gt; [\u0026lt;bypro2\u0026gt; ...]] [IMPLICIT_DEPENDS \u0026lt;lang1\u0026gt; \u0026lt;src1\u0026gt; ...] [WORKING_DIRECTORY \u0026lt;dir\u0026gt;] [COMMENT \u0026lt;comment\u0026gt;] [VERBATIM] [APPEND] [USES_TERMINAL] ) 参数： - OUTPUT \u0026lt;out1\u0026gt; [\u0026lt;out2\u0026gt; ...] ：指定自定义命令生成的文件或目标。这些文件将被 CMake 视为构建过程的输出，并且可以作为其他目标或命令的输入。 - COMMAND \u0026lt;cmd\u0026gt; [args...] ：指定执行的命令及其参数。在构建过程中，CMake 将执行此命令。 - [MAIN_DEPENDENCY \u0026lt;main_dep\u0026gt;] ：定义该命令的主要依赖文件，通常是触发自定义命令的源文件。如果这个文件发生变化，CMake 将重新执行命令。 - [DEPENDS [\u0026lt;dep\u0026gt; ...]] ： 列出该命令依赖的文件或目标。如果依赖项发生变化，CMake 会重新执行此命令。可以依赖于文件、库或其他目标。 - [BYPRODUCTS \u0026lt;bypro1\u0026gt; [\u0026lt;bypro2\u0026gt; ...]] ：指定该命令执行后生成的副产品文件，帮助 CMake 跟踪这些额外产生的文件。这些文件在命令执行过程中创建，但不会作为主要输出。 - [IMPLICIT_DEPENDS \u0026lt;lang1\u0026gt; \u0026lt;src1\u0026gt; ...] ：指定命令的隐式依赖关系，通常是源文件的语言和路径，CMake 可以自动追踪这些文件的依赖关系。 - [WORKING_DIRECTORY \u0026lt;dir\u0026gt;] ：指定命令执行时的工作目录。命令在这个目录中运行，适用于需要在特定目录下执行的命令。 - [COMMENT \u0026lt;comment\u0026gt;] ：在构建时，显示在命令执行之前的注释。可以用于提示用户正在执行的操作。 - [VERBATIM] ：确保命令的参数在生成的构建文件中被精确传递，而不会因为转义字符或特殊符号发生不必要的修改。通常推荐使用这个选项。 - [APPEND] ：将命令追加到已有的自定义命令中，而不是覆盖它。多个自定义命令可以依次执行。 - [USES_TERMINAL] ：指定命令需要在终端中执行。对于交互式命令（例如，需要用户输入的命令），这个选项很有用。 控制流 配置时评估的控制流：if()语句 if(variable) # 如果variable是`ON`, `YES`, `TRUE`, `Y`或者任意非零值 else() # 如果variable是`0`, `OFF`, `NO`, `FALSE`, `N`, `IGNORE`, `NOTFOUND`, `\u0026#34;\u0026#34;`或者以`-NOTFOUND`结尾 endif() # 如果variable没有扩展为上述之一，CMake 将扩展它，然后再次尝试。 这里可以设置一些关键字：\n分组 关键字 功能 一元运算符 NOT 取反运算，条件为假时返回真。 一元运算符 DEFINED 检查变量是否已经定义。 一元运算符 DEFINED 判断文件或目录是否存在。 一元运算符 COMMAND 判断命令是否存在。 一元运算符 POLICY 判断 CMake 策略是否定义。 一元运算符 TARGET 判断指定的目标是否存在。 二元运算符 AND 逻辑与运算，所有条件为真时结果才为真。 二元运算符 OR 逻辑或运算，只要有一个条件为真，结果就为真。 二元运算符 EQUAL 判断两个数值是否相等。 二元运算符 LESS 判断左侧数是否小于右侧数。 二元运算符 GREATER 判断左侧数是否大于右侧数。 二元运算符 LESS_EQUAL 判断左侧数是否小于等于右侧数。 二元运算符 GREATER_EQUAL 判断左侧数是否大于等于右侧数。 二元运算符 STREQUAL 判断两个字符串是否相等。 二元运算符 STRLESS 判断左侧字符串是否小于右侧字符串（字典序）。 二元运算符 STRGREATER 判断左侧字符串是否大于右侧字符串（字典序）。 二元运算符 MATCHES 判断字符串是否匹配指定的正则表达式。 二元运算符 VERSION_LESS 判断左侧版本号是否小于右侧版本号。 二元运算符 VERSION_EQUAL 判断两个版本号是否相等。 二元运算符 VERSION_GREATER 判断左侧版本号是否大于右侧版本号。 构建时评估的控制流：generator-expressions 生成器表达式（generator-expressions，简称为genex）是一种用于在构建生成阶段动态评估和控制行为的强大工具。generator-expression通常用于目标属性（例如编译选项、链接选项等），在项目的生成和构建阶段根据具体的构建配置（如 Debug 或 Release）动态调整行为。\ngenerator-expression基本语法\n$\u0026lt;CONDITION:arg1,arg2,...\u0026gt; # CONDITION 表示表达式类型，arg1, arg2, ... 是传递给条件的参数。 配置相关的generator-expression 表达式 说明 示例 $\u0026lt;CONFIG:config\u0026gt; 如果当前构建配置为 config，则返回真。 $\u0026lt;CONFIG:Debug\u0026gt;：在 Debug 配置中为真。 $\u0026lt;NOT:$\u0026lt;CONFIG:config\u0026gt;\u0026gt; 如果当前构建配置不是 config，则返回真。 $\u0026lt;NOT:$\u0026lt;CONFIG:Release\u0026gt;\u0026gt;：在 Release 配置中为假，其他配置为真。 $\u0026lt;CONFIGURATION\u0026gt; 返回当前的构建配置（Debug、Release、RelWithDebInfo 等）。 target_link_libraries(my_target PRIVATE $\u0026lt;CONFIGURATION\u0026gt;) 逻辑相关的generator-expression 表达式 说明 示例 $\u0026lt;AND:condition1,condition2\u0026gt; 如果 condition1 和 condition2 都为真，则返回真。 $\u0026lt;AND:$\u0026lt;CONFIG:Debug\u0026gt;,$\u0026lt;STREQUAL:WIN32\u0026gt;\u0026gt;：同时为 Debug 配置和 Windows 平台时为真。 $\u0026lt;OR:condition1,condition2\u0026gt; 如果 condition1 或 condition2 为真，则返回真。 $\u0026lt;OR:$\u0026lt;CONFIG:Debug\u0026gt;,$\u0026lt;STREQUAL:WIN32\u0026gt;\u0026gt;：是 Debug 或 Windows 时为真。 $\u0026lt;NOT:condition\u0026gt; 如果 condition 为假，则返回真。 $\u0026lt;NOT:$\u0026lt;CONFIG:Release\u0026gt;\u0026gt;：如果不是 Release 配置则为真。 $\u0026lt;BOOL:expression\u0026gt; 将表达式 expression 转换为布尔值，0 为假，其他为真。 $\u0026lt;BOOL:1\u0026gt;：返回真。 平台和编译器相关的generator-expression 表达式 说明 示例 $\u0026lt;PLATFORM_ID:platform\u0026gt; 如果当前平台是 platform，则返回真。 $\u0026lt;PLATFORM_ID:Windows\u0026gt;：当前平台为 Windows 时为真。 $\u0026lt;STREQUAL:string1,string2\u0026gt; 如果 string1 和 string2 相等，则返回真。 $\u0026lt;STREQUAL:APPLE,$\u0026lt;PLATFORM_ID:Darwin\u0026gt;\u0026gt;：苹果平台为真。 目标生成相关的generator-expression 表达式 说明 示例 $\u0026lt;TARGET_EXISTS:tgt\u0026gt; 如果目标 tgt 存在，返回真。 $\u0026lt;TARGET_EXISTS:my_target\u0026gt;：目标 my_target 存在时返回真。 $\u0026lt;TARGET_PROPERTY:tgt,prop\u0026gt; 返回目标 tgt 的属性 prop 的值。 $\u0026lt;TARGET_PROPERTY:my_target,INTERFACE_INCLUDE_DIRECTORIES\u0026gt;返回目标my_target的属性INTERFACE_INCLUDE_DIRECTORIES 的值。 版本相关的generator-expression 表达式 说明 示例 $\u0026lt;VERSION_GREATER:v1,v2\u0026gt; 如果版本 v1 大于 v2，则返回真。 $\u0026lt;VERSION_GREATER:3.20,3.10\u0026gt;：返回真，因为 3.20 \u0026gt; 3.10。 $\u0026lt;VERSION_EQUAL:v1,v2\u0026gt; 如果版本 v1 和 v2 相等，则返回真。 $\u0026lt;VERSION_EQUAL:3.10,3.10\u0026gt;：返回真。 文件和路径操作generator-expression 表达式 说明 示例 $\u0026lt;TARGET_FILE:tgt\u0026gt; 返回目标 tgt 的生成文件完整路径。 $\u0026lt;TARGET_FILE:my_target\u0026gt;：获取 my_target 目标的生成文件路径。 $\u0026lt;TARGET_LINKER_FILE:tgt\u0026gt; 返回目标 tgt 的链接器文件路径（通常是 .lib 或 .dll 文件）。 $\u0026lt;TARGET_LINKER_FILE:my_target\u0026gt;：获取 my_target 目标的链接文件。 CMake配置文件：config.h.in 生成供源文件读取的.h头文件：configure_file() 从源文件中读取一些变量：file() 整体性示例：C++代码迁移Python 该项目对应的源代码所在目录详见https://github.com/fordelkon/cmake_tutorial/tree/main/advanced_process/cxx_python。该项目的CMakeLists.txt内容如下：\ncmake_minimum_required(VERSION 3.9) project(CPy VERSION 0.1 DESCRIPTION \u0026#34;Little C to Python Program\u0026#34; LANGUAGES CXX) # 自定义我想要的包的路径：位于Conda环境下的Python可执行文件 set(Python_EXECUTABLE \u0026#34;$ENV{CONDA_PYTHON_EXE}\u0026#34;) # 查找Python解释器以及调试工具组件 find_package(Python REQUIRED COMPONENTS Interpreter Development) if(Python_FOUND) message(\u0026#34;Python Found at ${Python_INCLUDE_DIRS}\u0026#34;) # 从Conda环境下的Python查找pybind11路径 execute_process( COMMAND \u0026#34;${Python_EXECUTABLE}\u0026#34; -m pybind11 --cmakedir RESULT_VARIABLE __pybind_exit_code OUTPUT_VARIABLE __pybind_path OUTPUT_STRIP_TRAILING_WHITESPACE ) if(__pybind_exit_code EQUAL 0) set(pybind11_DIR ${__pybind_path}) find_package(pybind11 REQUIRED) message(\u0026#34;pybind11 Found at ${pybind11_INCLUDE_DIRS}\u0026#34;) # 创建编译选项接口库 add_library(compiler_flags INTERFACE) target_compile_features(compiler_flags INTERFACE cxx_std_11) # 添加优化选项 if(NOT MSVC) target_compile_options(compiler_flags INTERFACE -O2 -march=native ) else() target_compile_options(compiler_flags INTERFACE /O2 /arch:AVX2 # 对应于 -march=native ) endif() ################## #######CPU######## ################## add_library(ndarray_backend_cpu MODULE src/ndarray_backend_cpu.cc) target_include_directories(ndarray_backend_cpu PRIVATE ${Python_INCLUDE_DIRS} ${pybind11_INCLUDE_DIRS} ) target_link_libraries(ndarray_backend_cpu PUBLIC ${pybind11_LIBRARIES} compiler_flags # 链接编译选项接口库 ) pybind11_extension(ndarray_backend_cpu) pybind11_strip(ndarray_backend_cpu) # 输出编译文件 set_target_properties( ndarray_backend_cpu PROPERTIES LIBRARY_OUTPUT_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/needle/backend_ndarray CXX_VISIBILITY_PRESET \u0026#34;hidden\u0026#34; ) if(${CMAKE_SYSTEM_NAME} MATCHES \u0026#34;Darwin\u0026#34;) set_property(TARGET ndarray_backend_cpu PROPERTY LINK_OPTIONS -undefined dynamic_lookup) endif() else() message(FATAL_ERROR \u0026#34;Could not find pybind11 in the Python environment!!!\u0026#34;) endif() else() message(FATAL_ERROR \u0026#34;Could not find Python from Miniconda!!!\u0026#34;) endif() 我们可以看到CMakeLists.txt中的基本上与构建过程相关的任务皆为目标（Everything is a target)，接口库compiler_flags是目标（该目标被要求使用 C++11 标准，后面又为其设定了编译选项），编译src/ndarray_backend_cpu.cc而形成的库文件ndarray_backend_cpu也是目标，而这些变量都与构建过程高度相关。\nEverything is a target 目标类型 可执行文件：通常使用 add_executable 来创建。 库文件：通常使用 add_library 来创建，也可以从已有package中查找。 自定义命令：使用 add_custom_target 或 add_custom_command 创建。 目标依赖关系 指定依赖关系：使用target_link_library来制定依赖关系。 目标属性 设定目标属性：target_* 系列命令来为目标设置一系列的属性。常用的有target_compile_features，target_include_directories，target_compile_options\u0026hellip; 我们也可以配置Makefile文件来使得先cmake -B build生成构建系统文件然后再运行cmake --build build来执行构建操作（编译）使用make命令一步完成。\n.PHONY: lib, pybind, clean, format, all all: lib lib: cmake -B build cmake --build build format: python3 -m black . clang-format -i src/*.cc src/*.cu clean: rm -rf build needle/backend_ndarray/ndarray_backend*.so .PHONY是 Makefile 中的一个特殊目标，用来声明目标不生成与其名字相同的文件。 all目标表示一次性执行多个任务。在该文件中执行make all (make)和make lib等效 format目标目的是格式化代码。 clean目标用于清理构建生成的文件。 ","permalink":"https://fordelkon.github.io/posts/cmake_intro_2/","summary":"\u003cp\u003e上面我们实现了CMake的一套简要搭建流程，基本上简单的编译配置就靠上面的几个CMake命令就可以完成了。但一些大型项目的cmake的配置光靠上面的几个CMake命令是远远不够的，简单来说如何导入第三方库，嗯这就属于CMake进阶的内容了\u0026hellip;\u003c/p\u003e","title":"使用CMake的艺术2"},{"content":"还在使用vs code进行C++的环境的配置吗？想想对那些.vscode文件夹下的一系列文件进行单独配置就感到头大😭，那么是时候来使用CMake来进行自动化编译了，妈妈再也不用担心我的一个.cxx文件一个.vscode文件夹了。当然CMake的作用远不止此，举例来说，为了充分利用每种编程语言的特性，许多大型项目是需要针对不同的功能辅以不同的编程语言实现，这时候就要靠CMake来定制整个编译流程了\u0026hellip;\nCMake靠配置文件CMakeLists.txt来定制整个编译流程。 在CMakeLists.txt所在的目录下运行cmake -B build生成构建系统文件然后再运行cmake --build build来执行构建操作（编译）。 封装Makefile文件来进行定制化make命令。 CMakeLists.txt编写实现 一个目录下一个源文件 本节对应的源代码所在目录详见https://github.com/fordelkon/cmake_tutorial/tree/main/brief_process/Demo1。 编译一个main文件（这里就指定带有main函数的文件了），必要的三个命令cmake_minimum_required()、project()和add_executable()。\n// ./Demo1 // ├── CMakeLists.txt // └── main.cpp ✅ #include \u0026lt;iostream\u0026gt; using namespace std; // 查找字符串left索引以左，right索引以右连续对称可达索引 pair\u0026lt;int, int\u0026gt; expandAroundCenter(const string\u0026amp; s, int left, int right) { while (left \u0026gt;= 0 \u0026amp;\u0026amp; right \u0026lt; s.size() \u0026amp;\u0026amp; s[left] == s[right]) { left--; right++; } return {left + 1, right - 1}; } // 查找最长回文字符串 string longestPalindrome(string s) { int start = 0, end = 0; for (int i = 0; i \u0026lt; s.size(); i++) { pair\u0026lt;int, int\u0026gt; result = expandAroundCenter(s, i, i); int left1 = result.first; int right1 = result.second; result = expandAroundCenter(s, i, i + 1); int left2 = result.first; int right2 = result.second; if (right1 - left1 \u0026gt; end - start) { start = left1; end = right1; } if (right2 - left2 \u0026gt; end - start) { start = left2; end = right2; } } return s.substr(start, end - start + 1); } int main(int argc, char *argv[]) { if (argc \u0026lt; 2) { cout \u0026lt;\u0026lt; \u0026#34;Lack of raw string to find the longest palindrome!!!\u0026#34; \u0026lt;\u0026lt; endl; return 1; } string str = argv[1]; string res = longestPalindrome(str); cout \u0026lt;\u0026lt; \u0026#34;The longest palindrome of `\u0026#34; \u0026lt;\u0026lt; str \u0026lt;\u0026lt; \u0026#34;` is `\u0026#34; \u0026lt;\u0026lt; res \u0026lt;\u0026lt; \u0026#34;`\u0026#34; \u0026lt;\u0026lt; endl; return 0; } # ./Demo1 # ├── CMakeLists.txt ✅ # └── main.cpp # 指定最小Cmake的版本要求 cmake_minimum_required(VERSION 3.9) # important!!! # 设置项目名称 project(Demo1 C CXX) # important!!! # 启用 C++11 或更高标准 set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED ON) # 使用main.cpp构建一个名为Demo的可执行文件 add_executable(Demo main.cpp) # important!!! 上面的main.cpp主要实现了查找一个字符串中的最长回文字符串，CMakeLists.txt文件指定了我们的编译配置，在CMakeLists.txt所在的目录下运行cmake -B build和cmake --build build来进行编译然后得到了如下如下的目录树结构：\n./Demo1 ├── CMakeLists.txt ├── build ✅ └── main.cpp 我们生成的Demo可执行程序就在build目录下，如下：\n./build ├── CMakeCache.txt ├── CMakeFiles ├── Demo ✅ ├── Makefile └── cmake_install.cmake 在该目录下运行该可执行文件：\n./Demo iloveevolijupyter # The longest palindrome of `iloveevolijupyter` is `iloveevoli` 一个目录下多个源文件 本节对应的源代码所在目录详见https://github.com/fordelkon/cmake_tutorial/tree/main/brief_process/Demo2。 我们仍然可以使用上面必要的三个命令cmake_minimum_required()、project()和add_executable()。但是这次的源文件不止一个，而是有以下三个，因此第三个命令的传入的源文件参数需要调整\u0026hellip;我们可以修改成add_executable(Demo, main.cpp, strUtils.cpp, strUtils.hpp)，但是如果一个目录下的文件夹远远多于三个，我们还要这样傻傻的一个一个传入文件名称的参数吗？其实CMake的aux_source_directory()命令可以帮助我们得到指定目录下的所有的源文件。\naux_source_directory(\u0026lt;dir\u0026gt; \u0026lt;variable\u0026gt;) 参数： \u0026lt;dir\u0026gt; ：包含源文件的目录路径。 \u0026lt;variable\u0026gt; ：用于存储在该目录中找到的源文件的变量名称。 // ./Demo2 // ├── CMakeLists.txt // ├── main.cpp // ├── strUtils.cpp // └── strUtils.hpp ✅ #ifndef STRUTILS_H #define STRUTILS_H #include \u0026lt;iostream\u0026gt; using namespace std; // 查找最长回文字符串 string longestPalindrome(string s); #endif // ./Demo2 // ├── CMakeLists.txt // ├── main.cpp // ├── strUtils.cpp ✅ // └── strUtils.hpp #include \u0026lt;iostream\u0026gt; using namespace std; pair\u0026lt;int, int\u0026gt; expandAroundCenter(const string\u0026amp; s, int left, int right) { while (left \u0026gt;= 0 \u0026amp;\u0026amp; right \u0026lt; s.size() \u0026amp;\u0026amp; s[left] == s[right]) { left--; right++; } return {left + 1, right - 1}; } // 查找最长回文字符串 string longestPalindrome(string s) { int start = 0, end = 0; for (int i = 0; i \u0026lt; s.size(); i++) { pair\u0026lt;int, int\u0026gt; result = expandAroundCenter(s, i, i); int left1 = result.first; int right1 = result.second; result = expandAroundCenter(s, i, i + 1); int left2 = result.first; int right2 = result.second; if (right1 - left1 \u0026gt; end - start) { start = left1; end = right1; } if (right2 - left2 \u0026gt; end - start) { start = left2; end = right2; } } return s.substr(start, end - start + 1); } // ./Demo2 // ├── CMakeLists.txt // ├── main.cpp ✅ // ├── strUtils.cpp // └── strUtils.hpp #include \u0026lt;iostream\u0026gt; #include \u0026#34;strUtils.hpp\u0026#34; using namespace std; int main(int argc, char *argv[]) { if (argc \u0026lt; 2) { cout \u0026lt;\u0026lt; \u0026#34;Lack of raw string to find the longest palindrome!!!\u0026#34; \u0026lt;\u0026lt; endl; return 1; } string str = argv[1]; string res = longestPalindrome(str); cout \u0026lt;\u0026lt; \u0026#34;The longest palindrome of `\u0026#34; \u0026lt;\u0026lt; str \u0026lt;\u0026lt; \u0026#34;` is `\u0026#34; \u0026lt;\u0026lt; res \u0026lt;\u0026lt; \u0026#34;`\u0026#34; \u0026lt;\u0026lt; endl; return 0; } # ./Demo2 # ├── CMakeLists.txt ✅ # ├── main.cpp # ├── strUtils.cpp # └── strUtils.hpp # 指定最小Cmake的版本要求 cmake_minimum_required(VERSION 3.9) # 设置项目名称 project(Demo2 C CXX) # 启用 C++11 或更高标准 set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED ON) # 查找Demo2/目录下的所有源文件，然后将结果存进DIR_SRCS。 aux_source_directory(. DIR_SRCS) # important!!! # 使用main.cpp构建一个名为Demo的可执行文件 add_executable(Demo ${DIR_SRCS}) 多个目录下多个源文件 本节对应的源代码所在目录详见https://github.com/fordelkon/cmake_tutorial/tree/main/brief_process/Demo3。 现在我们进一步分配longestPalindrome和expandAroundCenter函数分别进入StrUtils文件夹和MyInclude文件夹。如下结构：\n./Demo3 ├── CMakeLists.txt ├── MyInclude │ ├── CMakeLists.txt │ ├── aroundCenter.cpp │ └── aroundCenter.hpp ├── StrUtils │ ├── CMakeLists.txt │ ├── palindrome.cpp │ └── palindrome.hpp └── main.cpp 我们希望在palindrome.cpp中引用#include \u0026quot;MyInclude/aroundCenter.hpp\u0026quot;，同时在main.cpp中引用#include \u0026quot;StrUtils/palindrome.hpp\u0026quot;。这时我们便需要使用add_library()、target_link_libraries()、target_include_directories()和add_subdirectory()这四个命令了。\nadd_library() add_library() 是 CMake 中用于定义和创建一个库（静态或动态）的命令。这个命令可以让你在构建系统中创建自己的库，并指定库的源文件。\nadd_library(\u0026lt;library_name\u0026gt; \u0026lt;STATIC|SHARED|MODULE\u0026gt; \u0026lt;source_files\u0026gt; ...) 参数： \u0026lt;library_name\u0026gt; ：指定要创建的库的名称。这个名字会成为你在项目中引用该库时使用的标识符。 \u0026lt;STATIC|SHARED|MODULE\u0026gt; ：指定库的类型。 - STATIC ：生成一个静态库，文件扩展名通常是 .a（类Unix） 或 .lib（Windows），它在被链接时被嵌入到目标中。（默认） - SHARED ：生成一个共享库（动态库），文件扩展名通常是 .so（Linux），.dylib（macOS），或 .dll（Windows）。共享库在运行时由操作系统加载。 - MODULE ：生成一个模块库，这种类型的库不会被链接到目标，而是通过操作系统的插件机制加载，通常用于插件架构（较少使用）。 \u0026lt;source_files\u0026gt; ：用于构建库的源文件列表，可以是一个或多个源文件（C++或C）。 target_link_libraries() target_link_libraries()是 CMake 中用于将库链接到另一个目标文件的命令。它用于指定某个目标（如可执行文件或库）所依赖的库，以便在构建时正确链接这些库。\ntarget_link_libraries(\u0026lt;target_name\u0026gt; \u0026lt;PRIVATE|PUBLIC|INTERFACE\u0026gt;\u0026lt;libraries\u0026gt; ...) 参数： \u0026lt;target_name\u0026gt; ：这是目标文件的名称（可以是可执行文件或库）。 \u0026lt;PRIVATE|PUBLIC|INTERFACE\u0026gt; ：指定库的链接方式。 - PRIVATE ：仅当前目标使用此库，其他依赖当前目标的目标不会受到影响。（默认） - PUBLIC ：当前目标和所有依赖当前目标的目标都会链接这个库。 - INTERFACE ：只有依赖当前目标的目标会链接此库，当前目标不会链接此库。 \u0026lt;libraries\u0026gt; ：你希望与目标文件链接的库，可以是一个或多个库。 target_include_directories() target_include_directories()是CMake中用于为特定目标（可以是可执行文件或库）指定头文件搜索路径的命令。这些路径会告知编译器在编译目标时到哪里去寻找头文件。\ntarget_include_directories(\u0026lt;target_name\u0026gt; \u0026lt;INTERFACE|PUBLIC|PRIVATE\u0026gt; \u0026lt;directories\u0026gt;) 参数： \u0026lt;target_name\u0026gt; ：你想要设置的搜索目录的目标文件（可以是可执行文件或库）。 \u0026lt;INTERFACE|PUBLIC|PRIVATE\u0026gt; ：指定目录对目标文件的可见性和链接方式 - INTERFACE ：目标本身不会使用这些目录，但依赖此目标的其他目标会使用这些目录。 - PUBLIC ：目标本身会使用这些目录，依赖此目标的其他目标也会使用这些目录。 - PRIVATE ：目标本身会使用这些目录，依赖于此目标的其他目标不会使用这些目录。（默认） \u0026lt;directories\u0026gt; ：要添加的搜索目录的路径，可以是绝对路径或相对路径。 add_subdirectory() add_subdirectory()是CMake中用于在构建树中包含一个子目录。这个命令将子目录中的 CMakeLists.txt 文件包含到主目录的构建过程中，并且子目录会作为独立的构建单元进行处理。\nadd_subdirectory(\u0026lt;source_dir\u0026gt; [binary_dir] [EXCLUDE_FROM_ALL]) 参数： \u0026lt;source_dir\u0026gt; ：要包含的子目录的路径。 [binary_dir] ：指定子目录的构建文件路径。如果未指定，则使用\u0026lt;souce_dir\u0026gt;中的CMakeLists.txt。 [EXCLUDE_FROM_ALL] ：指定此选项子目录的构建文件不会自动包含在默认构建的目标中。 # ./Demo3 # ├── CMakeLists.txt # ├── MyInclude # │ ├── CMakeLists.txt ✅ # │ ├── aroundCenter.cpp # │ └── aroundCenter.hpp # ├── StrUtils # │ ├── CMakeLists.txt # │ ├── palindrome.cpp # │ └── palindrome.hpp # └── main.cpp # 查找include目录下的所有源文件，然后将结果存进DIR_SRCS。 aux_source_directory(. DIR_SRCS) # 指定生成AroundCenter链接库 add_library(AroundCenter STATIC ${DIR_SRCS}) # 指定此链接库的包含目录 target_include_directories(AroundCenter INTERFACE ${CMAKE_SOURCE_DIR} # 添加这行，使得可以从项目根目录搜索头文件 ) # ./Demo3 # ├── CMakeLists.txt # ├── MyInclude # │ ├── CMakeLists.txt # │ ├── aroundCenter.cpp # │ └── aroundCenter.hpp # ├── StrUtils # │ ├── CMakeLists.txt ✅ # │ ├── palindrome.cpp # │ └── palindrome.hpp # └── main.cpp # 查找StrUtils目录下的所有源文件，然后将结果存进DIR_SRCS。 aux_source_directory(. DIR_SRCS) # 指定生成Palindrome链接库 add_library(Palindrome STATIC ${DIR_SRCS}) # 链接AroundCenter到Palindrome,往Palindrome被引用是AroundCenter会被自动引用，**当链接库文件时，不要省略 PUBLIC 或 PRIVATE 关键字** target_link_libraries(Palindrome PUBLIC AroundCenter) # 指定此链接库的包含目录 target_include_directories(Palindrome INTERFACE ${CMAKE_SOURCE_DIR} # 添加这行，使得可以从项目根目录搜索头文件 ) # ./Demo3 # ├── CMakeLists.txt ✅ # ├── MyInclude # │ ├── CMakeLists.txt # │ ├── aroundCenter.cpp # │ └── aroundCenter.hpp # ├── StrUtils # │ ├── CMakeLists.txt # │ ├── palindrome.cpp # │ └── palindrome.hpp # └── main.cpp # 指定最小Cmake的版本要求 cmake_minimum_required(VERSION 3.9) # 设置项目名称 project(Demo3 C CXX) # 启用 C++11 或更高标准 set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED ON) # 添加子目录include和StrUtils add_subdirectory(MyInclude) add_subdirectory(StrUtils) # 使用main.cpp构建一个名为Demo的可执行文件 add_executable(Demo main.cpp) # 链接Palindrome库到Demo，会自动链接到AroundCenter，**当链接库文件时，不要省略 PUBLIC 或 PRIVATE 关键字** target_link_libraries(Demo PRIVATE Palindrome) 下面让我详细解释一下可执行文件Demo的创建所需要的函数：\nadd_executable() 是创建可执行文件的必需命令 target_link_libraries() 是可选的，只在需要使用其他库时才需要 如果使用 target_link_libraries()，必须在 add_executable() 之后 它们是独立的命令，但在需要使用外部库时会配合使用 构建可执行文件的两阶段：\n编译阶段（Compile）：将源代码（如 .c 或 .cpp 文件）转换为目标代码（即 .o 文件或 .obj 文件）。在此阶段，编译器仅检查代码的语法、语义以及库中函数的声明（即头文件中的函数声明），但不会关心函数的实际定义是否存在。\n链接阶段（Link）：将各个编译好的目标文件和库文件链接在一起，形成最终的可执行文件。在这个阶段，所有函数的实际实现（定义）必须找到，链接器会将目标代码与库文件中的实现结合起来，确保可执行文件可以正常运行。\n","permalink":"https://fordelkon.github.io/posts/cmake_intro_1/","summary":"\u003cp\u003e还在使用\u003ccode\u003evs code\u003c/code\u003e进行C++的环境的配置吗？想想对那些\u003ccode\u003e.vscode\u003c/code\u003e文件夹下的一系列文件进行单独配置就感到头大😭，那么是时候来使用CMake来进行自动化编译了，妈妈再也不用担心我的一个\u003ccode\u003e.cxx\u003c/code\u003e文件一个\u003ccode\u003e.vscode\u003c/code\u003e文件夹了。当然CMake的作用远不止此，举例来说，为了充分利用每种编程语言的特性，许多大型项目是需要针对不同的功能辅以不同的编程语言实现，这时候就要靠CMake来定制整个编译流程了\u0026hellip;\u003c/p\u003e","title":"使用CMake的艺术1"},{"content":"本网站使用静态网站生成器 Hugo 创建，采用 PaperMod 主题，并托管在 Netlify。\n本网站使用 Google Analytics，它会使用 cookies。详情请参阅 Google 隐私政策、技术说明 以及 Google 如何使用 cookies。\n此外，本网站使用 giscus 提供评论功能。giscus 会使用 cookies：详情请参阅 giscus 隐私政策。\n最后，本网站会通过 cookie 记住你的主题偏好（亮色或暗色模式）。\nHugo、PaperMod 和 Netlify 可能会以我不知情的方式收集信息。除了这里描述的内容以及我未知的数据收集之外，本网站不会收集、存储或分析任何其他信息。\n","permalink":"https://fordelkon.github.io/privacy/","summary":"Privacy policy.","title":"Privacy Policy"},{"content":" 👋Hi! 我是DL Kong。\n我是在西安电子科技大学就读的人工智能方向研究生。\n我于2025年毕业于西安电子科技大学，获得人工智能工学学士学位。\n热爱漫画、小说、动漫，曾经尝试对Hassaku XL (Illustrious)模型使用dreambooth lora技术进行微调来学习自己喜欢的画师的作品风格。\n学习画师风格后生成的图片 在本科期间完成了搭建生态化调控装置系统网页、使用大语言模型进行笔录的信息检索与处理、公路道路裂纹检测等一系列项目，研究生将会持续丰富项目经历。\n","permalink":"https://fordelkon.github.io/about/","summary":"Information about me.","title":"关于我"},{"content":"我们可以从概率的角度去探讨深度学习任务，假设我们已有数据集$ \\mathcal{D}=\\lbrace(\\mathbf{x}_{i}, y_{i})\\rbrace_{i=1}^{N} $或$ \\mathcal{D}=\\lbrace\\mathbf{x}_{i}\\rbrace_{i=1}^{N} $，主要区分于有标签和无标签的情况。那么我们可以将常见深度学习任务中模型要建模的概率进行如下区分\n有监督判别：模型根据输入预测真实标签的概率分布$ p_{\\boldsymbol{\\theta}}(y\\mid\\mathbf{x}) $ 自监督判别：模型根据输入预测伪标签的概率分布$ p_{\\boldsymbol{\\theta}}(\\hat{y}\\mid\\mathbf{x}) $ 有监督生成：模型根据真实标签预测与标签对应的数据集的空间分布$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid y) $ 无监督生成：模型预测数据集的空间分布$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}) $ 其中$ \\mathbf{x} $和$ y $分别表示输入和标签的随机张量，$ \\boldsymbol{\\theta} $表示模型中可学习的参数。从概率角度探讨深度学习任务之前，我们应当明确如下假设：输入到模型的数据满足独立同分布(independent and identically distributed)。 不同深度学习任务所学习的概率分布总结 有监督判别 已有数据集$ \\mathcal{D}=\\lbrace(\\mathbf{x}_{i}, y_{i})\\rbrace_{i=1}^{N} $，我们应该使得数据集$ \\mathcal{D} $被观测到的概率尽可能大，也就是说给定输入$ \\mathbf{x}_{i} $，经过模型$ f(\\mathbf{x}, \\boldsymbol{\\theta}) $处理之后得到潜在空间$ \\mathbf{z}_{i} $或$ z_{i} $，其中$ \\mathbf{z}_{i}=f(\\mathbf{x}_{i}, \\boldsymbol{\\theta})\\in \\mathbb{R}^{K} $，在这个潜在空间中我们有最大的把握预测出$ y_{i} $。上述描述用数学形式表达如下：\n$$ \\begin{align} \\boldsymbol{\\theta}_{ML} \u0026= \\arg\\max_{\\boldsymbol{\\theta}} p_{\\boldsymbol{\\theta}}(\\mathcal{D}) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}} p_{\\boldsymbol{\\theta}}(y_{1}, y_{2}, \\dots, y_{N}\\mid\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\dots, \\mathbf{x}_{N}) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}} \\prod_{i=1}^{N} p_{\\boldsymbol{\\theta}}(y_{i}\\mid\\mathbf{x}_{i})\\quad (i.i.d.) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}} \\prod_{i=1}^{N}p(y_{i}\\mid\\mathbf{z}_{i}) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}}\\sum_{i=1}^{N}\\log p(y_{i}\\mid\\mathbf{z}_{i}) \\\\ \u0026= \\arg\\min_{\\boldsymbol{\\theta}}-\\sum_{i=1}^{N}\\log p(y_{i}\\mid\\mathbf{z}_{i}) \\end{align} $$ 常使用的$ y $分布有$ y\\sim \\mathcal{N}(z, \\sigma^2) $（回归问题），$ y\\sim \\mathrm{Bernoulli}(\\mathrm{sigmoid}(z)) $（二分类问题，使用$ \\mathrm{sigmoid} $函数使得最终的输出区间为$ [0, 1] $），$ p(y\\mid\\mathbf{z})=\\mathrm{softmax}_{y}(\\mathbf{z})=\\frac{\\exp[z_{y}]}{\\sum_{y'=1}^{K}\\exp[z_{y'}]} $（多分类问题，$ y\\in\\lbrace 1, 2, \\dots, K\\rbrace $，$ \\mathbf{z}=[z_{1}, z_{2}, \\dots, z_{K}] $）。更多相关的概率分布可以参见常用概率分布。\n无监督生成 已有数据集$ \\mathcal{D}=\\lbrace{\\mathbf{x}_{i}}\\rbrace_{i=1}^{N} $，无监督生成的任务就是使用模型学习出数据集的空间分布$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}) $。\n$ \\mathrm{GAN(Generative\\:Adversarial\\:Networks)} $ $ \\mathrm{GAN} $的思路是训练出一个生成器$ \\hat{\\mathbf{x}} = f_{g}(\\mathbf{v}, \\boldsymbol{\\theta}^{g}):\\mathcal{V}\\to \\mathcal{X} $将潜在空间$ \\mathcal{V} $很好地映射到样本空间$ \\mathcal{X} $。要训练出这样的生成器，$ \\mathrm{GAN} $额外训练了一个判别器$ z = f_{d}(\\mathbf{x}, \\boldsymbol{\\theta}^{d}):\\mathcal{X}\\to \\mathbb{R} $对生成的图像和真实的图像进行区分。对于生成器输入是潜在空间$ \\mathcal{V} $的采样，而对于判别器，我们就拥有数据集$ \\mathcal{D}_{union} = \\lbrace\\mathbf{x}_{i}, 1\\rbrace_{i=1}^N\\cup{\\lbrace\\hat{\\mathbf{x}}_{i}, 0\\rbrace}_{i=1}^{M} = \\lbrace\\tilde{\\mathbf{x}}_{i}, y_{i}\\rbrace_{i=1}^{N+M} $。在训练的过程中，针对生成器，我们要使其生成的图像更加真实（使得判别器判定高概率为真），针对判别器，我们要使判别器能够很好的区分生成器生成的伪造图像和真实图像。上面说法的数学形式如下\n对于生成器：\n$$ \\begin{align} \\boldsymbol{\\theta}_{ML}^{g} \u0026= \\arg\\max_{\\boldsymbol{\\theta}^g} p(y=1\\mid \\hat{z}) \\\\ \u0026= \\arg\\min_{\\boldsymbol{\\theta}^g}\\log p(y=0\\mid \\hat{z})\\quad(\\hat{z} = f_{d}(\\hat{\\mathbf{x}}, \\boldsymbol{\\theta}^d)) \\end{align} $$ 对于判别器\n$$ \\begin{align} \\boldsymbol{\\theta}_{ML}^{d} \u0026= \\arg\\max_{\\boldsymbol{\\theta}^d} p(y\\mid \\tilde{z}) \\\\ \u0026= \\arg\\min_{\\boldsymbol{\\theta}^d}-\\log p(y\\mid \\tilde{z})\\quad(\\tilde{z} = f_{d}(\\tilde{\\mathbf{x}}, \\boldsymbol{\\theta}^d))) \\end{align} $$ $ \\mathrm{VAE(Varitional\\:AutoEncoders)} $ $ \\mathrm{VAE} $的思路是也是训练一个解码器$ \\hat{\\mathbf{x}} = f_{d}(\\mathbf{v}, \\boldsymbol{\\theta}^{d}): \\mathcal{V}\\to \\mathcal{X} $将潜在空间$ \\mathcal{V} $中很好映射到样本空间$ \\mathcal{X} $。但是$ \\mathrm{VAE} $是通过最大化建模得到的$ p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}) $来实现训练该解码器的。表示成数学形式如下：\n$$ \\begin{align} \\boldsymbol{\\theta}_{ML}^d \u0026= \\arg\\max_{\\boldsymbol{\\theta}^d} p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}^d} \\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}, \\mathbf{v})d\\mathbf{v} \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}^d} \\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid \\mathbf{v})p(\\mathbf{v})d\\mathbf{v} \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}^d} \\log\\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid \\mathbf{v})p(\\mathbf{v})d\\mathbf{v}\\quad \\bigotimes \\quad ( not \\: intractable) \\end{align} $$ 由上式可知，直接求解$ \\boldsymbol{\\theta}^d $使得$ \\log\\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid \\mathbf{v})p(\\mathbf{v})d\\mathbf{v} $最大化往往不可能，我们应该找到$ \\log\\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid \\mathbf{v})p(\\mathbf{v})d\\mathbf{v} $的一个便于求解$ \\boldsymbol{\\theta}^d $的下界$ \\mathrm{ELBO}(\\boldsymbol{\\theta}^d)\\mathrm{\\:Evidence \\:Lower\\:BOund} $，使得更新$ \\boldsymbol{\\theta}^d $让下界$ \\mathrm{ELBO}(\\boldsymbol{\\theta}^d) $变大的同时，能够间接地使得$ \\log\\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid \\mathbf{v})p(\\mathbf{v})d\\mathbf{v} $增大。\n$$ \\begin{align} \\log p_{\\boldsymbol{\\theta}^d}(\\mathbf{x})\u0026=\\log\\int p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}, \\mathbf{v})d\\mathbf{v} \\\\ \u0026= \\log \\int q(\\mathbf{v})\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}, \\mathbf{v})}{q(\\mathbf{v})}d\\mathbf{v} \\\\ \u0026\\geq \\int q(\\mathbf{v})\\log\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}, \\mathbf{v})}{q(\\mathbf{v})}d\\mathbf{v} \\quad (\\mathrm{Jensen's\\:inequality}) \\end{align} $$ 因此，我们可以取下界为\n$$ \\mathrm{ELBO}(\\boldsymbol{\\theta}^d) = \\int q(\\mathbf{v})\\log\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}, \\mathbf{v})}{q(\\mathbf{v})}d\\mathbf{v} $$ 实际操作中$ \\mathbf{v} $的概率分布$ q(\\mathbf{v}) $通常也是由编码器模型生成，也就是说下界$ \\mathrm{ELBO}(\\boldsymbol{\\theta}^d) $更为规范的写法为$ \\mathrm{ELBO}(\\boldsymbol{\\theta}^e, \\boldsymbol{\\theta}^d) $\n$$ \\begin{align} \\mathrm{ELBO}(\\boldsymbol{\\theta}^e, \\boldsymbol{\\theta}^d) \u0026= \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}, \\mathbf{v})}{q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})}d\\mathbf{v} \\\\ \u0026= \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{v}\\mid\\mathbf{x})p_{\\boldsymbol{\\theta}^d}(\\mathbf{x})}{q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})}d\\mathbf{v} \\\\ \u0026= \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log p_{\\boldsymbol{\\theta}^d}(\\mathbf{x})d\\mathbf{v} + \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{v}\\mid\\mathbf{x})}{q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})}d\\mathbf{v} \\quad (one\\:perspective) \\\\ \u0026= \\log p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}) - \\mathrm{D}_{\\mathrm{KL}}\\Big[q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})||p_{\\boldsymbol{\\theta}^d}(\\mathbf{v}\\mid\\mathbf{x})\\Big] \\\\ \\\\ \u0026= \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log\\frac{p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid\\mathbf{v})p(\\mathbf{v})}{q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})}d\\mathbf{v} \\\\ \u0026= \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid\\mathbf{v})d\\mathbf{v} + \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log\\frac{p(\\mathbf{v})}{q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})}d\\mathbf{v}\\quad (another\\:perspective) \\\\ \u0026= \\int q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\log p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid\\mathbf{v})d\\mathbf{v} - \\mathrm{D}_{\\mathrm{KL}}\\Big[q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})||p(\\mathbf{v})\\Big] \\\\ \u0026\\approx \\log p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}\\mid\\mathbf{v}^*) - \\mathrm{D}_{\\mathrm{KL}}\\Big[q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})||p(\\mathbf{v})\\Big] \\quad (Monte\\:Carlo\\:estimate) \\end{align} $$ 上述公式中$ q_{\\boldsymbol{\\theta}^e}(\\mathbf{v})\\approx q_{\\boldsymbol{\\theta}^e}(\\mathbf{v}\\mid \\mathbf{x})=\\mathcal{N}(\\mathbf{v}\\mid f_{e}^{\\boldsymbol{\\mu}}(\\mathbf{x}, \\boldsymbol{\\theta}^e), f_{e}^{\\boldsymbol{\\Sigma}}(\\mathbf{x}, \\boldsymbol{\\theta}^e)) $，$ p(\\mathbf{v})=\\mathcal{N}(\\mathbf{v}|0, 1) $，$ \\mathbf{v}^* $也是从分布中$ q_{\\boldsymbol{\\theta}^e}(\\mathbf{v}\\mid \\mathbf{x}) $抽样得到。之后我们就可以通过最大化$ \\mathrm{ELBO}(\\boldsymbol{\\theta}^e, \\boldsymbol{\\theta}^d) $来进行优化模型从而对$ p_{\\boldsymbol{\\theta}^d}(\\mathbf{x}) $进行建模。\n$ \\mathrm{Diffusion\\:Models} $ $ \\mathrm{Diffusion\\:Models} $的目标也是训练出一个解码器$ \\hat{\\mathbf{x}} = f_{d}(\\mathbf{v}, \\boldsymbol{\\theta}): \\mathcal{V}\\to \\mathcal{X} $将潜在空间$ \\mathcal{V} $中很好映射到样本空间$ \\mathcal{X} $。和$ \\mathrm{VAE} $一样，$ \\mathrm{Diffusion\\:Models} $的目标也是最大化$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}) $来实现训练该解码器的，但是$ \\mathrm{Diffusion\\:Models} $的潜在变量$ \\mathbf{v} $通常是通过原始输入$ \\mathbf{x} $逐渐加噪得到的，而解码器学习从潜在变量$ \\mathbf{v} $一步步生成逼真的样本。这一过程的形式化表示如下所示，为了方便推导公式简化，令$ \\mathbf{v} = \\mathbf{z}_{T} $\n$$ \\mathrm{forward\\:process}: \\mathbf{x}\\to \\mathbf{z}_{1}\\to \\mathbf{z}_{2}\\to\\dots\\to \\mathbf{z}_{T-1}\\to\\mathbf{z}_{T}\\quad(\\mathbf{v}) $$ $$ \\mathrm{reverse\\:process}: (\\mathbf{v})\\quad\\mathbf{z}_{T}\\to \\mathbf{z}_{T-1}\\to \\mathbf{z}_{T-2}\\to\\dots\\to \\mathbf{z}_{1}\\to\\mathbf{x} $$ 根据上述框架，我们可以对$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}) $最大化求解$ \\boldsymbol{\\theta} $\n$$ \\begin{align} \\boldsymbol{\\theta}_{ML} \u0026= \\arg\\max_{\\boldsymbol{\\theta}}p_{\\boldsymbol{\\theta}}(\\mathbf{x}) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}}\\int p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})d\\mathbf{z}_{1\\dots T} \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}}\\log \\int p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})d\\mathbf{z}_{1\\dots T} \\quad \\bigotimes \\quad ( not \\: intractable) \\end{align} $$ 和$ \\mathrm{VAE} $一样，我们寻找$ \\log \\int p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1}, \\mathbf{z}_{2}, \\dots, \\mathbf{z}_{T-1}, \\mathbf{v})d\\mathbf{z}_{1}d\\mathbf{z}_{2}\\dots d\\mathbf{z}_{T-1}d\\mathbf{v} $的一个便于优化的下界$ \\mathrm{ELBO}(\\boldsymbol{\\theta})\\mathrm{\\:Evidence \\:Lower\\:BOund} $来对$ \\boldsymbol{\\theta} $进行优化求解\n$$ \\begin{align} \\log p_{\\boldsymbol{\\theta}}(\\mathbf{x}) \u0026= \\log \\int p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})d\\mathbf{z}_{1\\dots T}\\\\ \u0026= \\log\\left[ \\int q(\\mathbf{z}_{1\\dots T}\\mid \\mathbf{x}) \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})}{q(\\mathbf{z}_{1\\dots T}\\mid \\mathbf{x})}d\\mathbf{z}_{1\\dots T}\\right] \\\\ \u0026\\geq \\int q(\\mathbf{z}_{1\\dots T}\\mid \\mathbf{x}) \\log \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})}{q(\\mathbf{z}_{1\\dots T} \\mid \\mathbf{x})}d\\mathbf{z}_{1\\dots T} \\quad (\\mathrm{Jensen's\\:inequality}) \\end{align} $$ 也就是说我们可以取证据下界\n$$ \\mathrm{ELBO}(\\boldsymbol{\\theta}) = \\int q(\\mathbf{z}_{1\\dots T}\\mid \\mathbf{x}) \\log \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})}{q(\\mathbf{z}_{1\\dots T} \\mid \\mathbf{x})}d\\mathbf{z}_{1\\dots T} $$ 在$ \\mathrm{VAE} $中，编码器通过参数来学习给定输入下潜在变量的后验概率分布$ q_{\\boldsymbol{\\theta}^e}(\\mathbf{v}\\mid \\mathbf{x}) $，但是在$ \\mathrm{Diffusion\\:Models} $中的编码器是没有参数的，因此解码器的参数在更新时应当考虑使得无参数编码器尽可能近似后验概率分布$ p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{1}, \\mathbf{z}_{2}, \\dots, \\mathbf{z}_{T-1}, \\mathbf{v}\\mid \\mathbf{x}) $。\n下面对$ \\mathrm{ELBO}(\\boldsymbol{\\theta}) $中的$ \\log $项进行进一步的分析简化，\n$$ \\begin{align} \\log \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})}{q(\\mathbf{z}_{1\\dots T} \\mid \\mathbf{x})} \u0026= \\log\\left[ \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})\\prod_{t=2}^Tp_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})\\cdot p(\\mathbf{z}_{T})}{q(\\mathbf{z}_{1}\\mid\\mathbf{x})\\prod_{t=2}^Tq(\\mathbf{z}_{t}\\mid \\mathbf{z}_{t-1})} \\right]\\\\ \u0026= \\log\\left[ \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})}{q(\\mathbf{z}_{1}\\mid \\mathbf{x})} \\right] + \\log\\left[ \\frac{\\prod_{t=2}^Tp_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})}{\\prod_{t=2}^Tq(\\mathbf{z}_{t}\\mid \\mathbf{z}_{t-1})} \\right] + \\log[p(\\mathbf{z}_{T})] \\\\ \u0026= \\log\\left[ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})\\right] + \\log\\left[ \\frac{\\prod_{t=2}^Tp_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})}{\\prod_{t=2}^Tq(\\mathbf{z}_{t - 1}\\mid \\mathbf{z}_{t}, \\mathbf{x})} \\right] + \\log\\left[ \\frac{p(\\mathbf{z}_{T})}{q(\\mathbf{z}_{T}\\mid \\mathbf{x})} \\right]\\quad (Bayes'\\:rule) \\\\ \u0026\\approx \\log\\left[ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})\\right] + \\sum_{t=2}^{T}\\log\\left[ \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})}{q(\\mathbf{z}_{t - 1}\\mid \\mathbf{z}_{t}, \\mathbf{x})} \\right] \\end{align} $$ 所以$ \\mathrm{ELBO}(\\boldsymbol{\\theta}) $可以转变为\n$$ \\begin{align} \\mathrm{ELBO}(\\boldsymbol{\\theta}) \u0026= \\int q(\\mathbf{z}_{1\\dots T}\\mid \\mathbf{x}) \\log \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{z}_{1\\dots T})}{q(\\mathbf{z}_{1\\dots T} \\mid \\mathbf{x})}d\\mathbf{z}_{1\\dots T} \\\\ \u0026\\approx \\int q(\\mathbf{z}_{1\\dots T}\\mid \\mathbf{x})\\left(\\log\\left[ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})\\right] + \\sum_{t=2}^{T}\\log\\left[ \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})}{q(\\mathbf{z}_{t - 1}\\mid \\mathbf{z}_{t}, \\mathbf{x})} \\right]\\right)d\\mathbf{z}_{1\\dots T} \\\\ \u0026= \\int q(\\mathbf{z}_{1}\\mid \\mathbf{x})\\log\\left[ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})\\right]d\\mathbf{z}_{1} + \\sum_{t=2}^{T}\\int q(\\mathbf{z}_{t-1}, \\mathbf{z}_{t}\\mid \\mathbf{x})\\log\\left[ \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})}{q(\\mathbf{z}_{t - 1}\\mid \\mathbf{z}_{t}, \\mathbf{x})} \\right]d\\mathbf{z}_{t-1}d\\mathbf{z}_{t} \\\\ \u0026= \\int q(\\mathbf{z}_{1}\\mid \\mathbf{x})\\log\\left[ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})\\right]d\\mathbf{z}_{1} + \\sum_{t=2}^{T}\\int q(\\mathbf{z}_{t}\\mid\\mathbf{x})q(\\mathbf{z}_{t-1}\\mid \\mathbf{z}_{t}, \\mathbf{x})\\log\\left[ \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})}{q(\\mathbf{z}_{t - 1}\\mid \\mathbf{z}_{t}, \\mathbf{x})} \\right]d\\mathbf{z}_{t-1}d\\mathbf{z}_{t} \\quad (Bayes'\\:rule) \\\\ \u0026= \\int \\textcolor{blue}{q(\\mathbf{z}_{1}\\mid \\mathbf{x})}\\log\\left[ \\textcolor{green}{p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})}\\right]d\\mathbf{z}_{1} - \\sum_{t=2}^{T}\\int \\textcolor{red}{q(\\mathbf{z}_{t}\\mid\\mathbf{x})}\\mathrm{D}_{\\mathrm{KL}}(\\textcolor{purple}{q(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t}, \\mathbf{x})}||\\textcolor{pink}{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})})d\\mathbf{z}_{t} \\end{align} $$ 上述$ \\mathrm{ELBO}(\\boldsymbol{\\theta}) $的所有标明颜色的概率分布都可以通过正态分布建模出来\n$$ \\textcolor{green}{p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid\\mathbf{z}_{1})} = \\mathcal{N}\\left(\\mathbf{x}\\mid f_{d}(\\mathbf{z}_{1}, \\boldsymbol{\\theta}), \\sigma_{1}^2\\mathbf{I}\\right) $$ $$ \\textcolor{pink}{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})} = \\mathcal{N}\\left(\\mathbf{z}_{t-1}\\mid f_{d}(\\mathbf{z}_{t}, \\boldsymbol{\\theta}), \\sigma_{t}^2\\mathbf{I}\\right) $$ 前向过程($ \\mathrm{Forward\\:Process} $) $$ \\mathbf{z}_{1} = \\sqrt{ 1-\\beta_{1} }\\mathbf{x} + \\sqrt{ \\beta_{1} }\\boldsymbol{\\epsilon}_{1} $$ $$ \\mathbf{z}_{t} = \\sqrt{ 1-\\beta_{t} }\\mathbf{z}_{t-1} + \\sqrt{ \\beta_{t} }\\boldsymbol{\\epsilon}_{t}\\quad\\quad \\forall t\\in 2, \\dots, T $$ 其中$ \\boldsymbol{\\epsilon}_{t} $是从标准正态分布中抽取的噪声($ \\boldsymbol{\\epsilon}_{t}\\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}) $)，前向过程的第一项衰减了数据以及至今添加的任何噪声，第二项增加了更多的噪声。超参数$ \\beta_{t} $则决定了噪声的混合速度。方程形式转化成概率形式如下\n$$ \\textcolor{blue}{q(\\mathbf{z}_{1}\\mid\\mathbf{x})} = \\mathcal{N}(\\mathbf{z}_{1}|\\sqrt{ 1-\\beta_{1} }\\mathbf{x}, \\beta_{1}\\mathbf{I}) $$ $$ q(\\mathbf{z}_{t}\\mid\\mathbf{z}_{t-1}) = \\mathcal{N}(\\mathbf{z}_{t}|\\sqrt{ 1 - \\beta_{t} }\\mathbf{z}_{t-1}, \\beta_{t}\\mathbf{I}) $$ 上述过程形成了一个$ Markov $链，当$ T $足够大时，$ q(\\mathbf{z}_{T}|\\mathbf{x})=q(\\mathbf{z}_{T}) $就会成为标准正态分布。已知以上概率分布我们可以很方便地推导出$ \\textcolor{purple}{q(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t}, \\mathbf{x})} $\n$$ \\textcolor{purple}{q(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t}, \\mathbf{x})} = \\mathcal{N}\\left( \\mathbf{z}_{t-1}\\mid \\frac{1-\\alpha_{t-1}}{1-\\alpha_{t}}\\sqrt{ 1-\\beta_{t} }\\mathbf{z}_{t} + \\frac{\\sqrt{ \\alpha_{t-1} }\\beta_{t}}{1 - \\alpha_{t}}\\mathbf{x}, \\frac{\\beta_{t}(1 - \\alpha_{t-1})}{1 - \\alpha_{t}}\\mathbf{I} \\right) $$ 其中$ \\alpha_{t} = \\prod_{s=1}^{t}1 - \\beta_{s} $。\n扩散损失 原始扩散损失 经过正态分布建模后，原始扩散损失为\n$$ \\begin{align} -\\mathrm{ELBO}(\\boldsymbol{\\theta}) \u0026= \\sum_{n=1}^N\\Big( -\\log[\\mathcal{N}(\\mathbf{x}_{n}\\mid f_{d}(\\mathbf{z}_{n1}, \\boldsymbol{\\theta}), \\sigma_{1}^2\\mathbf{I})] \\\\ \u0026\\quad\\quad+ \\frac{1}{2\\sigma^2}\\sum_{t=2}^T\\Big\\lvert\\Big\\lvert \\frac{1 - \\alpha_{t-1}}{1 - \\alpha_{t}}\\sqrt{ 1 - \\beta_{t} } \\mathbf{z}_{nt} + \\frac{\\sqrt{ \\alpha_{t - 1} }\\beta_{t}}{1 - \\alpha_{t}}\\mathbf{x}_{n} - f_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta})\\Big\\rvert\\Big\\rvert^2 \\Big) \\end{align} $$ 重参数化扩散损失 由前向过程我们可以推导得到\n$$ \\mathbf{z}_{t} = \\sqrt{ \\alpha_{t} }\\cdot \\mathbf{x} + \\sqrt{ 1 - \\alpha_{t} }\\boldsymbol{\\epsilon} $$ $$ \\mathbf{x} = \\frac{1}{\\sqrt{ \\alpha_{t} }}\\cdot \\mathbf{z}_{t} - \\frac{\\sqrt{ 1 - \\alpha_{t} }}{\\sqrt{ \\alpha_{t} }}\\cdot\\boldsymbol{\\epsilon} $$ 将原始扩散损失中的$ \\mathbf{x} $替换成$ \\mathbf{z}_{t} $\n$$ \\begin{align} -\\mathrm{ELBO}(\\boldsymbol{\\theta}) \u0026= \\sum_{n=1}^N\\Big( -\\log[\\mathcal{N}(\\mathbf{x}_{n}\\mid f_{d}(\\mathbf{z}_{n1}, \\boldsymbol{\\theta}), \\sigma_{1}^2\\mathbf{I})] \\\\ \u0026\\quad\\quad+ \\sum_{t=2}^T\\frac{1}{2\\sigma_{t}^2}\\Big\\lvert \\Big\\lvert \\frac{1}{\\sqrt{ 1 - \\beta_{t} }} \\mathbf{z}_{nt} - \\frac{\\beta_{t}}{\\sqrt{ 1-\\alpha_{t} }\\sqrt{ 1-\\beta_{t} }}\\boldsymbol{\\epsilon}_{nt} - f_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta})\\Big\\rvert\\Big\\rvert^2 \\Big) \\\\ \u0026= \\sum_{n=1}^N \\Big(\\frac{1}{2\\sigma_{1}^2}\\Big\\lvert \\Big\\lvert \\mathbf{x}_{n} - f_{d}(\\mathbf{z}_{n1}, \\boldsymbol{\\theta})\\Big\\rvert\\Big\\rvert^2 + \\sum_{t=2}^T\\frac{\\beta_{t}^2}{(1 - \\alpha_{t})(1 - \\beta_{t})2\\sigma_{t}^2}\\Big\\lvert \\Big\\lvert g_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta}) - \\boldsymbol{\\epsilon}_{nt}\\Big\\rvert\\Big\\rvert^2 + C_{n}\\Big)\\quad(Reparameterization\\:of\\:network) \\\\ \\\\ \u0026= \\sum_{n=1}^N\\sum_{t=1}^T\\frac{\\beta_{t}^2}{(1 - \\alpha_{t})(1 - \\beta_{t})2\\sigma_{t}^2}\\Big\\lvert \\Big\\lvert g_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta}) - \\boldsymbol{\\epsilon}_{nt}\\Big\\rvert\\Big\\rvert^2 + C_{n} \\end{align} $$ 其中网络重参数化使用如下公式$ f_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta}) = \\frac{1}{\\sqrt{ 1 - \\beta_{t} }} \\mathbf{z}_{nt} - \\frac{\\beta_{t}}{\\sqrt{ 1-\\alpha_{t} }\\sqrt{ 1-\\beta_{t} }}g_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta}) $。有了上面的简约形式我们可以进一步对损失进行简化\n$$ \\begin{align} \\mathcal{L}(\\boldsymbol{\\theta}) \u0026= \\sum_{n=1}^N\\sum_{t=1}^T\\Big\\lvert \\Big\\lvert g_{d}(\\mathbf{z}_{nt}, \\boldsymbol{\\theta}) - \\boldsymbol{\\epsilon}_{nt}\\Big\\rvert\\Big\\rvert^2 \\\\ \u0026= \\sum_{n=1}^N\\sum_{t=1}^T\\Big\\lvert \\Big\\lvert g_{d}(\\sqrt{ \\alpha_{t} }\\mathbf{x}_{n} + \\sqrt{ 1-\\alpha_{t} }\\boldsymbol{\\epsilon}_{nt}, \\boldsymbol{\\theta}) - \\boldsymbol{\\epsilon}_{nt}\\Big\\rvert\\Big\\rvert^2 \\end{align} $$ 反向过程($ \\mathrm{Reverse\\:(Sampling)\\: Process} $) 由式子$ \\textcolor{pink}{p_{\\boldsymbol{\\theta}}(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t})} = \\mathcal{N}\\left(\\mathbf{z}_{t-1}\\mid f_{d}(\\mathbf{z}_{t}, \\boldsymbol{\\theta}), \\sigma_{t}^2\\mathbf{I}\\right) $可以将概率形式转化成如下方程形式\n$$ \\begin{align} \\mathbf{z}_{t-1} \u0026= f_{d}(\\mathbf{z}_{t}, \\boldsymbol{\\theta}) + \\sigma_{t}\\boldsymbol{\\epsilon}_{t} \\\\ \u0026= \\frac{1}{\\sqrt{ 1 - \\beta_{t} }} \\mathbf{z}_{t} - \\frac{\\beta_{t}}{\\sqrt{ 1-\\alpha_{t} }\\sqrt{ 1-\\beta_{t} }}g_{d}(\\mathbf{z}_{t}, \\boldsymbol{\\theta}) + \\sigma_{t}\\boldsymbol{\\epsilon}_{t} \\\\ \\end{align} $$ 再由式子$ \\textcolor{purple}{q(\\mathbf{z}_{t-1}\\mid\\mathbf{z}_{t}, \\mathbf{x})} = \\mathcal{N}\\left( \\mathbf{z}_{t-1}\\mid \\frac{1-\\alpha_{t-1}}{1-\\alpha_{t}}\\sqrt{ 1-\\beta_{t} }\\mathbf{z}_{t} + \\frac{\\sqrt{ \\alpha_{t-1} }\\beta_{t}}{1 - \\alpha_{t}}\\mathbf{x}, \\frac{\\beta_{t}(1 - \\alpha_{t-1})}{1 - \\alpha_{t}}\\mathbf{I} \\right) $，可以估计$ \\sigma_{t}^2\\approx\\frac{\\beta_{t}(1 - \\alpha_{t-1})}{1 - \\alpha_{t}}\\approx \\beta_{t} $，那么反向过程可以求得。\n自监督学习 已有数据集$ \\mathcal{D}=\\lbrace{\\mathbf{x}_{i}}\\rbrace_{i=1}^{N} $，通过数据集$ \\mathcal{D} $自身生成“伪标签”我们组成了新的带有伪标签的数据集$ \\mathcal{D}_{fake}=\\lbrace{\\mathbf{x}_{i}}, \\hat{y}_{i}\\rbrace_{i=1}^{N} $或$ \\mathcal{D}_{fake}=\\lbrace{\\mathbf{x}_{i}}, \\hat{\\mathbf{y}}_{i}\\rbrace_{i=1}^{N} $。自监督学习的思路是让学习过的模型$ \\mathbf{z} = f(\\mathbf{x}, \\boldsymbol{\\theta}) $将原始输入空间$ \\mathcal{X} $映射到潜在空间$ \\mathcal{Z} $，在该潜在空间上各个伪标签的区分度尽可能大。从这一方面来说，自监督学习可以看作在数据集$ D_{fake} $上进行有监督学习。但是伪标签毕竟不是真实标签，自监督学习主要是让模型通过学习$ p(\\hat{y}\\mid\\mathbf{x}) $或$ p(\\hat{\\mathbf{y}}\\mid\\mathbf{x}) $建立原始输入$ \\mathbf{x}_{i} $的潜在表示$ \\mathbf{z}_{i} $，然后再应用到一系列具有真实标签的下游任务。\n对比学习 对比学习作为当前自监督学习领域的热门研究方向，其目标是让模型不依赖人工标签自动学习到有区分力的特征表示。核心思想就是使得相似的样本经过模型映射后的特征尽可能靠近，不同的样本经过模型映射后的特征尽可能分开。\n也就是说，我们模型$ f(\\mathbf{x}, \\mathbf{x}^{'}, \\boldsymbol{\\theta}) $需要学习概率分布$ p(y\\mid \\mathbf{x}, \\mathcal{X}^{'}) $使之最大化，其中$ \\mathcal{X}^{'} = \\lbrace\\mathbf{x}_{1}^{'}, \\dots, \\mathbf{x}_{M}^{'}\\rbrace $，$ y $的定义为正样本的索引$ y = \\lbrace 1, \\dots, M\\rbrace $。由贝叶斯准则可知，$ p(y\\mid \\mathbf{x}, \\mathcal{X}^{'}) \\propto p(\\mathcal{X}^{'}\\mid\\mathbf{x}, y)p(y) $。假设正样本来自真实的条件分布$ p_{data}(\\mathbf{x}^{'}\\mid \\mathbf{x}) $，负样本来自噪声分布$ q(\\mathbf{x}^{'}) $，有条件独立性假设可得$ p(\\mathcal{X}^{'}\\mid\\mathbf{x}, y) = p_{data}(\\mathbf{x}^{'}_{y}\\mid\\mathbf{x})\\prod_{j\\neq y}q(\\mathbf{x}_{j}^{'}) $。那么经过归一化之后$ p(y\\mid \\mathbf{x}, \\mathcal{X}^{'}) = \\dfrac{\\frac{p_{data}(\\mathbf{x}^{'}_{y}\\mid\\mathbf{x})}{q(\\mathbf{x}_{y}^{'})}}{\\sum_{k=1}^{M}\\dfrac{p_{data}(\\mathbf{x}^{'}_{k}\\mid\\mathbf{x})}{q(\\mathbf{x}_{k}^{'})}} $。由上述公式的形式，我们可以直接参数化密度比$ f(\\mathbf{x}, \\mathbf{x}^{'}, \\boldsymbol{\\theta})\\approx\\frac{p_{data}(\\mathbf{x}^{'}\\mid\\mathbf{x})}{q(\\mathbf{x}^{'})} $，所以$ p_{\\boldsymbol{\\theta}}(y\\mid \\mathbf{x}, \\mathcal{X}^{'})=\\frac{f(\\mathbf{x}, \\mathbf{x}_{y}^{'}, \\boldsymbol{\\theta})}{\\sum_{k=1}^Mf(\\mathbf{x}, \\mathbf{x}_{k}^{'}, \\boldsymbol{\\theta})} $。\n上述表述的数学形式如下\n$$ \\begin{align} \\boldsymbol{\\theta}_{ML} \u0026= \\arg\\max_{\\boldsymbol{\\theta}} \\prod_{i=1}^{N} p_{\\boldsymbol{\\theta}}(y_{i}\\mid\\mathbf{x}_{i}, \\mathcal{X}^{'})\\quad (i.i.d.) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}}\\sum_{i=1}^{N}\\log p_{\\boldsymbol{\\theta}}(y_{i}\\mid\\mathbf{x}_{i}, \\mathcal{X}^{'}) \\\\ \u0026= \\arg\\max_{\\boldsymbol{\\theta}}\\sum_{i=1}^{N}\\log \\frac{f(\\mathbf{x}_{i}, \\mathbf{x}_{y_{i}}^{'}, \\boldsymbol{\\theta})}{\\sum_{k=1}^Mf(\\mathbf{x}_{i}, \\mathbf{x}_{k}^{'}, \\boldsymbol{\\theta})} \\\\ \u0026= \\arg\\min_{\\boldsymbol{\\theta}}-\\frac{1}{N}\\sum_{i=1}^{N}\\log \\frac{f(\\mathbf{x}_{i}, \\mathbf{x}_{y_{i}}^{'}, \\boldsymbol{\\theta})}{\\sum_{k=1}^Mf(\\mathbf{x}_{i}, \\mathbf{x}_{k}^{'}, \\boldsymbol{\\theta})} \\\\ \u0026= \\arg\\min_{\\boldsymbol{\\theta}}\\frac{1}{N}\\sum_{i=1}^N\\log\\left[ 1 + \\frac{\\sum_{k\\neq y_{i}}f(\\mathbf{x}_{i}, \\mathbf{x}_{k}', \\boldsymbol{\\theta})}{f(\\mathbf{x}_{i}, \\mathbf{x}_{y_{i}}',\\boldsymbol{\\theta})} \\right] \\\\ \u0026= \\arg\\min \\mathbb{E}_{\\mathbf{x}}\\left[\\log\\left[1 + \\frac{q(\\mathbf{x}_{y_{i}}^{'})}{p_{data}(\\mathbf{x}_{y_{i}}^{'}\\mid\\mathbf{x})}\\sum_{k\\neq y_{i}}\\frac{p_{data}(\\mathbf{x}_{k}^{'}\\mid\\mathbf{x})}{q(\\mathbf{x}_{k}^{'})}\\right]\\right] \\\\ \u0026\\approx \\arg\\min \\mathbb{E}_{\\mathbf{x}}\\left[\\log\\left[1 + \\frac{q(\\mathbf{x}_{y_{i}}^{'})}{p_{data}(\\mathbf{x}_{y_{i}}^{'}\\mid\\mathbf{x})}(M-1)\\sum_{k\\neq y_{i}}q(\\mathbf{x}_{k}')\\frac{p_{data}(\\mathbf{x}_{k}^{'}\\mid\\mathbf{x})}{q(\\mathbf{x}_{k}^{'})}\\right]\\right] \\\\ \u0026= \\arg\\min \\mathbb{E}_{\\mathbf{x}}\\left[\\log\\left[1 + \\frac{q(\\mathbf{x}_{y_{i}}^{'})}{p_{data}(\\mathbf{x}_{y_{i}}^{'}\\mid\\mathbf{x})}(M-1)\\right]\\right] \\\\ \u0026\\geq \\arg\\min \\mathbb{E}_{\\mathbf{x}}\\left[\\log \\left[\\frac{q(\\mathbf{x}_{y_{i}}^{'})}{p_{data}(\\mathbf{x}_{y_{i}}^{'}\\mid\\mathbf{x})}M\\right]\\right] \\\\ \u0026= \\arg\\min \\mathbb{E}_{\\mathbf{x}} \\left[\\log \\left[\\frac{q(\\mathbf{x}_{y_{i}}^{'})}{p_{data}(\\mathbf{x}_{y_{i}}^{'}\\mid\\mathbf{x})}M\\right]\\right] \\\\ \u0026= \\arg\\min -I(\\mathcal{X}', \\mathbf{x}) + \\log M \\end{align} $$ 也就是说，最大化$ p(y\\mid \\mathbf{x}, \\mathcal{X}^{'}) $同时也等价于最大化$ \\mathcal{X}' $和$ \\mathbf{x} $的互信息，在优化损失函数的过程中使得随机变量$ \\mathbf{x} $和对应的正样本$ \\mathcal{X}' $的耦合程度尽可能大，也就是尽可能保持正样本对齐。\n","permalink":"https://fordelkon.github.io/posts/prob_dl/","summary":"\u003cp\u003e我们可以从概率的角度去探讨深度学习任务，假设我们已有数据集\u003ccode\u003e$ \\mathcal{D}=\\lbrace(\\mathbf{x}_{i}, y_{i})\\rbrace_{i=1}^{N} $\u003c/code\u003e或\u003ccode\u003e$ \\mathcal{D}=\\lbrace\\mathbf{x}_{i}\\rbrace_{i=1}^{N} $\u003c/code\u003e，主要区分于有标签和无标签的情况。那么我们可以将常见深度学习任务中模型要建模的概率进行如下区分\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e有监督判别：模型根据输入预测真实标签的概率分布\u003ccode\u003e$ p_{\\boldsymbol{\\theta}}(y\\mid\\mathbf{x}) $\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e自监督判别：模型根据输入预测伪标签的概率分布\u003ccode\u003e$ p_{\\boldsymbol{\\theta}}(\\hat{y}\\mid\\mathbf{x}) $\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e有监督生成：模型根据真实标签预测与标签对应的数据集的空间分布\u003ccode\u003e$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\mid y) $\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e无监督生成：模型预测数据集的空间分布\u003ccode\u003e$ p_{\\boldsymbol{\\theta}}(\\mathbf{x}) $\u003c/code\u003e\n其中\u003ccode\u003e$ \\mathbf{x} $\u003c/code\u003e和\u003ccode\u003e$ y $\u003c/code\u003e分别表示输入和标签的随机张量，\u003ccode\u003e$ \\boldsymbol{\\theta} $\u003c/code\u003e表示模型中可学习的参数。从概率角度探讨深度学习任务之前，我们应当明确如下假设：\u003cfont color=\"#c00000\"\u003e输入到模型的数据满足独立同分布(independent and identically distributed)\u003c/font\u003e。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ccenter\u003e\n  \u003cimg src=\"./img/prob_dl_summary.png\" alt=\"图片1\" width=\"400\"\u003e\n\u003c/center\u003e\n\u003ccenter\u003e\u003cstrong\u003e不同深度学习任务所学习的概率分布总结\u003c/strong\u003e\u003c/center\u003e","title":"概率视角中的深度学习"}]